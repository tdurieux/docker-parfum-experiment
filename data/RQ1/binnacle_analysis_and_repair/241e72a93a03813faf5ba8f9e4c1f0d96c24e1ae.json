{
  "startTime": 1674234581826,
  "endTime": 1674234581927,
  "originalSmells": [
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 16,
        "lineEnd": 16,
        "columnStart": 49,
        "columnEnd": 67
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 11,
        "lineEnd": 11,
        "columnStart": 22,
        "columnEnd": 57
      }
    },
    {
      "rule": "aptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 11,
        "lineEnd": 11,
        "columnStart": 22,
        "columnEnd": 57
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# Spark docker image.\n#\n# VERSION 0.0.1\n\nFROM debian:jessie\n\nMAINTAINER Nicolas Carlier <https://github.com/ncarlier>\n\nENV DEBIAN_FRONTEND noninteractive\n\n# Install packages\nRUN apt-get update && apt-get install --no-install-recommends -y wget default-jdk && rm -rf /var/lib/apt/lists/*;\n\n# Install cwspark binaries\nENV SPARK_URL http://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz\nENV SPARK_HOME /opt/spark\nRUN ( cd /tmp && wget $SPARK_URL -O pkg.tar.gz && tar zxf pkg.tar.gz && mv spark-* $SPARK_HOME && rm -rf /tmp/*) && rm pkg.tar.gz\n\n# Create user\nRUN adduser --disabled-password spark\n\n# Create working directory\nRUN mkdir -p /var/lib/spark && chown spark.spark /var/lib/spark\n\n# Set user\nUSER spark\n\n# Setup working directory\nWORKDIR /var/lib/spark\n\nCMD [\"/opt/spark/bin/spark-shell\"]\n"
}