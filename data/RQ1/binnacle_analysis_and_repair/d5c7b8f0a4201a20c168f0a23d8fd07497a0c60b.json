{
  "startTime": 1674250414044,
  "endTime": 1674250414487,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 144
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 26,
        "lineEnd": 26,
        "columnStart": 4,
        "columnEnd": 105
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 30,
        "lineEnd": 30,
        "columnStart": 4,
        "columnEnd": 92
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 26,
        "lineEnd": 26,
        "columnStart": 4,
        "columnEnd": 105
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 30,
        "lineEnd": 30,
        "columnStart": 4,
        "columnEnd": 92
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 33,
        "lineEnd": 33,
        "columnStart": 4,
        "columnEnd": 103
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 2,
        "lineEnd": 2,
        "columnStart": 4,
        "columnEnd": 83
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 5,
        "lineEnd": 5,
        "columnStart": 4,
        "columnEnd": 73
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 22,
        "lineEnd": 22,
        "columnStart": 4,
        "columnEnd": 49
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 32,
        "lineEnd": 32,
        "columnStart": 4,
        "columnEnd": 65
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM centos\n# install dev tools\nRUN yum install -y curl which tar sudo openssh-server openssh-clients rsync bunzip2 && rm -rf /var/cache/yum\n\n# install hadoop nativelins tools\nRUN yum install -y gcc gcc-c++ autoconf automake libtool zlib-devel cmake && rm -rf /var/cache/yum\n\n# passwordless ssh\nRUN ssh-keygen -q -N \"\" -t dsa -f /etc/ssh/ssh_host_dsa_key\nRUN ssh-keygen -q -N \"\" -t rsa -f /etc/ssh/ssh_host_rsa_key\nRUN ssh-keygen -q -N \"\" -t rsa -f /root/.ssh/id_rsa\nRUN cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys\n\nRUN curl -f -LO 'http://download.oracle.com/otn-pub/java/jdk/7u51-b13/jdk-7u51-linux-x64.rpm' -H 'Cookie: oraclelicense=accept-securebackup-cookie' && \\\n    rpm -i jdk-7u51-linux-x64.rpm && \\\n    rm jdk-7u51-linux-x64.rpm\n\nENV JAVA_HOME /usr/java/default\nENV PATH $PATH:$JAVA_HOME/bin\n\n# devel tools\nRUN yum groupinstall \"Development Tools\" -y\nRUN yum install -y cmake zlib-devel openssl-devel && rm -rf /var/cache/yum\n\n# maven\nENV M2_VER=3.3.9\nRUN curl -f https://www.eu.apache.org/dist/maven/maven-3/${M2_VER}/binaries/apache-maven-${M2_VER}-bin.tar.gz | tar xz  -C /usr/share\nENV M2_HOME /usr/share/apache-maven-${M2_VER}\nENV PATH $PATH:$M2_HOME/bin\n\nRUN curl -f -s https://www.eu.apache.org/dist/hadoop/common/hadoop-2.7.2/hadoop-2.7.2-src.tar.gz | tar -xz -C /tmp/\n\nRUN yum install -y protobuf protobuf-c-devel fuse-devel fuse wget && rm -rf /var/cache/yum\nRUN wget https://packages.psychotic.ninja/6/base/x86_64/RPMS//uncrustify-0.60-8.el6.psychotic.x86_64.rpm\nRUN rpm -ivh uncrustify-0.60-8.el6.psychotic.x86_64.rpm\nRUN wget https://github.com/remis-thoughts/native-hdfs-fuse/archive/master.zip\nRUN unzip master.zip\nRUN cd native-hdfs-fuse-master/ && sed -i \"s#-Werror -Wall##g\" Makefile && make && make install\nRUN cd /tmp/hadoop-2.7.2-src && mvn package -Pdist,native -DskipTests -Dtar\n\nRUN mv /tmp/hadoop-2.7.2-src/hadoop-dist/target/hadoop-2.7.2 /hadoop\n\nENV LD_LIBRARY_PATH /usr/local/lib\nENV export LD_RUN_PATH /usr/local/lib\n\n\nRUN ln -s /usr/java/jdk1.7.0_51/jre/lib/amd64/server/libjvm.so /usr/local/lib/\nRUN ln -s /tmp/hadoop-2.7.2-src/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-2.7.2/lib/native/* /usr/local/lib/\nRUN ln -s /tmp/hadoop-2.7.2-src/hadoop-hdfs-project/hadoop-hdfs/target/native/main/native/fuse-dfs/fuse_dfs /usr/bin\nRUN ln -s /tmp/hadoop-2.7.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/native/fuse-dfs/fuse_dfs_wrapper.sh /usr/bin/\n\nRUN echo \"export LD_LIBRARY_PATH=/usr/java/jdk1.7.0_51/jre/lib/amd64/server:/usr/local/lib\" > /etc/profile\nRUN echo \"/usr/java/jdk1.7.0_51/jre/lib/amd64/server\" >> /etc/ld.so.conf\nRUN echo \"/tmp/hadoop-2.7.2-src/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-2.7.2/lib/native\" >> /etc/ld.so.conf\nRUN /sbin/ldconfig -v\n\nRUN mkdir /mnt/hdfs\n#RUN echo \"fuse_dfs_wrapper.sh dfs://192.168.1.11:54310 /mnt/hdfs    fuse rw,auto 0 0\" >> /etc/fstab\n#RUN modprobe fuse\nRUN echo \"fuse_dfs#dfs://coreos-test:9000 /mnt/hdfs fuse usetrash,rw 0 0\" >> /etc/fstab\nRUN ln -s /hadoop /usr/local/hadoop\nRUN ln -s /usr/java/jdk1.7.0_51/ /opt/jdk\nENV JAVA_HOME /opt/jdk\n\nENV JAVA_HOME=/opt/jdk \\\n    HADOOP_VERSION=2.7.2 \\\n    HADOOP_PREFIX=/usr/local/hadoop \\\n    HADOOP_COMMON_HOME=/usr/local/hadoop \\\n    HADOOP_HDFS_HOME=/usr/local/hadoop \\\n    HADOOP_MAPRED_HOME=/usr/local/hadoop \\\n    HADOOP_YARN_HOME=/usr/local/hadoop \\\n    HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop \\\n    YARN_CONF_DIR=$HADOOP_PREFIX/etc/hadoop \\\n    YARN_IDENT_STRING=root \\\n    HADOOP_SSH_OPTS=\"-F /root/.ssh/config\" \\\n    HADOOP_CLUSTERNAME=syracuse \\\n    HADOOP_ROLE=STANDALONE \\\n    HADOOP_HOME=/hadoop \\\n    CATALINA_OUT=/dev/stdout\n\n#RUN wget https://github.com/google/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz\n#RUN mv protobuf-2.5.0.tar.gz /tmp\n#RUN cd /tmp && tar zxvf protobuf-2.5.0.tar.gz\n#RUN cd /tmp/protobuf-2.5.0/ && ./configure\n#RUN cd /tmp/protobuf-2.5.0/ && make && make install\n#ENV LD_LIBRARY_PATH /usr/local/lib\n#ENV export LD_RUN_PATH /usr/local/lib\n\n#RUN wget https://github.com/protobuf-c/protobuf-c/releases/download/v1.0.0/protobuf-c-1.0.0.tar.gz\n#RUN tar zxvf protobuf-c-1.0.0.tar.gz\n#RUN cd protobuf-c-1.0.0 && protobuf_LIBS=$(l=libprotobuf.a; for i in /opt/local/lib /usr/local/lib; do  if [ -f $i/$l ]; then echo $i/$l; fi; done) && \\\n#export protobuf_LIBS && \\\n#./configure && make && make install\n\n\n#RUN tar -cv -C /tmp/hadoop-2.7.0-src/hadoop-dist/target/hadoop-2.7.0/lib/native/ .\n\n"
}