{
  "startTime": 1674240961342,
  "endTime": 1674240961445,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 7,
        "lineEnd": 7,
        "columnStart": 4,
        "columnEnd": 97
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 17,
        "lineEnd": 17,
        "columnStart": 4,
        "columnEnd": 36
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 2,
        "lineEnd": 4,
        "columnStart": 22,
        "columnEnd": 15
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 22,
        "columnEnd": 64
      }
    },
    {
      "rule": "aptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 2,
        "lineEnd": 4,
        "columnStart": 22,
        "columnEnd": 15
      }
    },
    {
      "rule": "aptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 22,
        "columnEnd": 64
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM ubuntu:16.04\n\nRUN apt-get update && apt-get install --no-install-recommends -y \\\n    curl \\\n    python3-pip && rm -rf /var/lib/apt/lists/*;\n\nRUN echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list\nRUN curl -f https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\nRUN apt-get update && apt-get install --no-install-recommends -y tensorflow-model-server && rm -rf /var/lib/apt/lists/*;\n\nARG MODEL_NAME=identity\nENV MODEL_PATH=/root/models\nARG SERVING_PORT=8500\n\nWORKDIR /\n\nCOPY requirements.txt .\nRUN pip3 install --no-cache-dir -r requirements.txt && rm requirements.txt\n\nCOPY create_model.py .\nRUN python3 create_model.py $MODEL_PATH/$MODEL_NAME && rm create_model.py\n\nEXPOSE $SERVING_PORT\n\nCMD tensorflow_model_server --port=$SERVING_PORT --model_name=$MODEL_NAME --model_base_path=$MODEL_PATH/$MODEL_NAME --enable_batching=true\n"
}