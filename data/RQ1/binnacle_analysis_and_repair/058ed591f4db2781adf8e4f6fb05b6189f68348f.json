{
  "startTime": 1674239080799,
  "endTime": 1674239080957,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 35,
        "lineEnd": 39,
        "columnStart": 4,
        "columnEnd": 17
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "ARG base_image=resin/raspberrypi3-alpine-python:3.6-slim-20180120\n# Use this for local development on intel machines\n# FROM resin/amd64-alpine-python:3.6-slim-20180123\n\n\n# Use this for running on a robot\nFROM $base_image\n\n# See compute/README.md for details. Make sure to keep them in sync\nRUN apk add --update \\\n      util-linux \\\n      vim \\\n      dropbear \\\n      dropbear-scp \\\n      gnupg \\\n      openjdk8 \\\n      nginx \\\n      libstdc++ \\\n      g++ \\\n      networkmanager \\\n      py3-zmq \\\n      py3-urwid \\\n      py3-numpy \\\n      avrdude \\\n      ffmpeg \\\n      mpg123 \\\n      && rm -rf /var/cache/apk/*\n\n# Resin's python base container compiles python from scratch and doesn't have\n# it installed as apk package. This results in py3- dependencies installing\n# python3 package without being able to remove it (because py3- depend on it).\n# To avoid ambiguity, we are copying all installed dependencies into original\n# site-packages and cleaning up the one created by python3 package.\nRUN cp -r /usr/lib/python3.6/site-packages /usr/local/lib/python3.6/ && \\\n    rm -rf /usr/lib/python3.6\nRUN pip install --no-cache-dir --force-reinstall \\\n    pipenv==9.0.3 \\\n    jupyter==1.0.0 \\\n    tornado==4.5.1 \\\n    pyzmq==16.0.2\n\n# Copy server files and data into the container. Note: any directories that\n# you wish to copy into the container must be excluded from the .dockerignore\n# file, or you will encounter a copy error\n\nCOPY ./compute/container_setup.sh /usr/local/bin/container_setup.sh\nCOPY ./audio/ /etc/audio\nCOPY ./shared-data/module /etc/module\nCOPY ./shared-data/pipette /etc/pipette\nCOPY ./shared-data/definitions /etc/labware\nCOPY ./api /tmp/api\n# Make our shared data available for the api setup.py\nCOPY ./shared-data /tmp/shared-data\nCOPY ./update-server /tmp/update-server\nCOPY ./compute/avahi_tools /tmp/avahi_tools\n\n# When adding more python packages make sure to use setuptools to keep\n# packaging consistent across environments\nENV PIPENV_VENV_IN_PROJECT=true\nRUN pipenv install /tmp/api --system && \\\n    pipenv install /tmp/update-server --system && \\\n    pip install /tmp/avahi_tools && \\\n    echo \"export OT_SYSTEM_VERSION=`python -c \\\"import json; print(json.load(open('/tmp/api/opentrons/package.json'))['version'])\\\"`\" | tee -a /etc/profile.d/opentrons.sh && \\\n    rm -rf /tmp/api && \\\n    rm -rf /tmp/update-server && \\\n    rm -rf /tmp/shared-data && \\\n    rm -rf /tmp/avahi_tools\n\n# Redirect nginx logs to stdout and stderr\nRUN ln -sf /dev/stdout /var/log/nginx/access.log && \\\n    ln -sf /dev/stderr /var/log/nginx/error.log\n\n# Use udev rules file from opentrons_data\nRUN ln -sf /data/user_storage/opentrons_data/95-opentrons-modules.rules /etc/udev/rules.d/95-opentrons-modules.rules\n\n# Logo for login shell\nCOPY ./compute/opentrons.motd /etc/motd\n\n# Generate keys for dropbear\nCOPY ./compute/ssh_key_gen.sh /tmp/\nRUN /tmp/ssh_key_gen.sh\n\n# Updates, HTTPS (for future use), API, SSH for link-local over USB\nEXPOSE 80 443 31950\n\nSTOPSIGNAL SIGTERM\n\n# For backward compatibility, udev is enabled by default\nENV UDEV on\n\n# The one link we have to make in the dockerfile still to make sure we get our\n# environment variables\nCOPY ./compute/find_python_module_path.py /usr/local/bin/\nCOPY ./compute/find_ot_resources.py /usr/local/bin\nRUN ln -sf /data/system/ot-environ.sh /etc/profile.d/00-persistent-ot-environ.sh &&\\\n    ln -sf `find_ot_resources.py`/ot-environ.sh /etc/profile.d/01-builtin-ot-environ.sh\n\n# This configuration is used both by both the build and runtime so it has to\n# be here. When building a container for local use, set this to 0. If set to\n# 0, ENABLE_VIRTUAL_SMOOTHIE will be set at runtime automatically\nARG running_on_pi='export RUNNING_ON_PI=1'\n\n# Note: the quoting that defines the PATH echo is very specifically set up to\n# get $PATH in the script literally so it is evaluated at container runtime.\nRUN echo \"export CONTAINER_ID=$(uuidgen)\" | tee -a /etc/profile.d/opentrons.sh\\\n    && echo 'export PATH=$PATH:'\"`find_ot_resources.py`/scripts\" | tee -a /etc/profile.d/opentrons.sh\\\n    && echo $running_on_pi | tee -a /etc/profile.d/opentrons.sh\n\n\nARG data_mkdir_path_slash_if_none=/\nRUN mkdir -p $data_mkdir_path_slash_if_none\n\n# For interactive one-off use:\n#   docker run --name opentrons -it opentrons /bin/sh\n# or uncomment:\n# CMD [\"python\", \"-c\", \"while True: pass\"]\nCMD [\"bash\", \"-lc\", \"container_setup.sh && setup.sh && exec start.sh\"]\n\n# Using Resin base image's default entrypoint and init system- tini\n"
}