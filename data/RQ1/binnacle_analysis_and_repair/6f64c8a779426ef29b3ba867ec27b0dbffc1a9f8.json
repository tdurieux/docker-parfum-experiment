{
  "startTime": 1674241245387,
  "endTime": 1674241245662,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 18,
        "lineEnd": 18,
        "columnStart": 4,
        "columnEnd": 85
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 26,
        "lineEnd": 26,
        "columnStart": 4,
        "columnEnd": 71
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 33,
        "lineEnd": 33,
        "columnStart": 4,
        "columnEnd": 80
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 50,
        "lineEnd": 50,
        "columnStart": 4,
        "columnEnd": 112
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 19,
        "lineEnd": 19,
        "columnStart": 4,
        "columnEnd": 48
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 27,
        "lineEnd": 27,
        "columnStart": 4,
        "columnEnd": 46
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 34,
        "lineEnd": 34,
        "columnStart": 4,
        "columnEnd": 63
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 51,
        "lineEnd": 51,
        "columnStart": 4,
        "columnEnd": 59
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 6,
        "lineEnd": 6,
        "columnStart": 22,
        "columnEnd": 103
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 43,
        "lineEnd": 43,
        "columnStart": 4,
        "columnEnd": 86
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 43,
        "lineEnd": 43,
        "columnStart": 4,
        "columnEnd": 86
      }
    },
    {
      "rule": "aptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 6,
        "lineEnd": 6,
        "columnStart": 22,
        "columnEnd": 103
      }
    },
    {
      "rule": "aptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 43,
        "lineEnd": 43,
        "columnStart": 4,
        "columnEnd": 86
      }
    }
  ],
  "repairedSmells": [
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 43,
        "lineEnd": 43,
        "columnStart": 4,
        "columnEnd": 110
      }
    }
  ],
  "repairedDockerfile": "FROM isuper/java-oracle:jdk_8\n\nMAINTAINER Segence <segence@segence.com>\n\nWORKDIR /tmp\n\nRUN apt-get update && apt-get install --no-install-recommends -y openssh-server wget vim iputils-ping telnet dnsutils bzip2 ntp && rm -rf /var/lib/apt/lists/*;\nRUN update-rc.d ntp defaults\n\nRUN groupadd hadoop\nRUN useradd -d /home/hadoop -g hadoop -m hadoop\n\n# SSH without key\nRUN mkdir /home/hadoop/.ssh\nRUN ssh-keygen -t rsa -f /home/hadoop/.ssh/id_rsa -P '' && \\\n    cat /home/hadoop/.ssh/id_rsa.pub >> /home/hadoop/.ssh/authorized_keys\n\n# Installing Hadoop\nRUN wget https://apache.mirror.anlx.net/hadoop/common/hadoop-2.9.0/hadoop-2.9.0.tar.gz\nRUN tar -xzvf hadoop-2.9.0.tar.gz -C /usr/local/ && rm hadoop-2.9.0.tar.gz\nRUN mv /usr/local/hadoop-2.9.0 /usr/local/hadoop\nENV HADOOP_HOME=/usr/local/hadoop\nENV HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\nENV YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop\n\n# Installing Scala\nRUN wget https://downloads.lightbend.com/scala/2.11.11/scala-2.11.11.tgz\nRUN tar -xzvf scala-2.11.11.tgz -C /usr/local/ && rm scala-2.11.11.tgz\nRUN mv /usr/local/scala-2.11.11 /usr/local/scala\nRUN chown -R root:root /usr/local/scala\nENV SCALA_HOME=/usr/local/scala\n\n# Installing Spark\nRUN wget https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-without-hadoop.tgz\nRUN tar -xzvf spark-2.2.0-bin-without-hadoop.tgz -C /usr/local/ && rm spark-2.2.0-bin-without-hadoop.tgz\nRUN mv /usr/local/spark-2.2.0-bin-without-hadoop /usr/local/spark\nENV SPARK_HOME=/usr/local/spark\nENV LD_LIBRARY_PATH=$HADOOP_HOME/lib/native/:$LD_LIBRARY_PATH\n\n# Configuring Hadoop classpath for Spark\nRUN echo \"export SPARK_DIST_CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath)\" > /usr/local/spark/conf/spark-env.sh\n\n# Installing the R language\nRUN apt-get install --no-install-recommends -y libssl-dev libssh2-1-dev libcurl4-openssl-dev libssl-dev r-base && rm -rf /var/lib/apt/lists/*;\nRUN R -e \"install.packages('devtools', repos = 'http://cran.us.r-project.org')\"\nRUN R -e \"install.packages('knitr', repos = 'http://cran.us.r-project.org')\"\nRUN R -e \"install.packages('ggplot2', repos = 'http://cran.us.r-project.org')\"\nRUN R -e \"install.packages(c('devtools','mplot', 'googleVis'), repos = 'http://cran.us.r-project.org'); require(devtools); install_github('ramnathv/rCharts')\"\n\n# Installing Zeppelin\nRUN wget https://mirrors.ukfast.co.uk/sites/ftp.apache.org/zeppelin/zeppelin-0.7.3/zeppelin-0.7.3-bin-netinst.tgz\nRUN tar -xzvf zeppelin-0.7.3-bin-netinst.tgz -C /usr/local/ && rm zeppelin-0.7.3-bin-netinst.tgz\nRUN mv /usr/local/zeppelin-0.7.3-bin-netinst /usr/local/zeppelin\n\nENV ZEPPELIN_HOME=/usr/local/zeppelin\nCOPY config/zeppelin-env.sh $ZEPPELIN_HOME/conf/zeppelin-env.sh\nCOPY config/zeppelin-site.xml $ZEPPELIN_HOME/conf/zeppelin-site.xml\n\nRUN chown -R hadoop:hadoop $ZEPPELIN_HOME\n\n# Setting the PATH environment variable globally and for the Hadoop user\nENV PATH=$PATH:$JAVA_HOME/bin:/usr/local/hadoop/bin:/usr/local/hadoop/sbin:$SCALA_HOME/bin:$SPARK_HOME/bin:$ZEPPELIN_HOME/bin\nRUN echo \"PATH=$PATH:$JAVA_HOME/bin:/usr/local/hadoop/bin:/usr/local/hadoop/sbin:$SCALA_HOME/bin:$SPARK_HOME/bin\" >> /home/hadoop/.bashrc\n\n# Hadoop configuration\nCOPY config/sshd_config /etc/ssh/sshd_config\nCOPY config/ssh_config /home/hadoop/.ssh/config\nCOPY config/hadoop-env.sh config/hdfs-site.xml config/hdfs-site.xml config/core-site.xml \\\n     config/core-site.xml config/mapred-site.xml config/yarn-site.xml config/yarn-site.xml \\\n     $HADOOP_CONF_DIR/\n\n# Adding initialisation scripts\nRUN mkdir $HADOOP_HOME/bin/init\nCOPY init-scripts/init-hadoop.sh $HADOOP_HOME/bin/init/\nCOPY init-scripts/start-hadoop.sh init-scripts/stop-hadoop.sh $HADOOP_HOME/bin/init/\nCOPY init-scripts/hadoop /etc/init.d/\n\n# Adding utilities\nRUN mkdir -p /home/hadoop/utils\nCOPY utils/run-wordcount.sh utils/format-namenode.sh /home/hadoop/utils/\n\n# Replacing Hadoop slave file with provided one and changing logs directory\nRUN rm $HADOOP_CONF_DIR/slaves\nRUN ln -s /config/slaves $HADOOP_CONF_DIR/slaves\n\n# Setting up log directories\nRUN ln -s /data/logs/hadoop $HADOOP_HOME/logs\nRUN ln -s $HADOOP_HOME/logs /var/log/hadoop\nRUN ln -s $ZEPPELIN_HOME/logs /var/log/zeppelin\n\n# Set permissions on Hadoop home\nRUN chown -R hadoop:hadoop $HADOOP_HOME\nRUN chown -R hadoop:hadoop /home/hadoop\n\n# Cleanup\nRUN rm -rf /tmp/*\n\nWORKDIR /root\n\nEXPOSE  2222 4040 8020 8030 8031 8032 8033 8042 8088 9001 50010 50020 50070 50075 50090 50100\n\nVOLUME /data\nVOLUME /config\nVOLUME /deployments\n\nENTRYPOINT [ \"sh\", \"-c\", \"service ntp start; $HADOOP_HOME/bin/init/init-hadoop.sh; service ssh start; bash\"]\n"
}