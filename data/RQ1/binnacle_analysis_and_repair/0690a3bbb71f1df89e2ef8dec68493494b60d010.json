{
  "startTime": 1674244696440,
  "endTime": 1674244696629,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 28,
        "lineEnd": 28,
        "columnStart": 2,
        "columnEnd": 98
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 38,
        "lineEnd": 38,
        "columnStart": 2,
        "columnEnd": 134
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 28,
        "lineEnd": 28,
        "columnStart": 2,
        "columnEnd": 98
      }
    },
    {
      "rule": "apkAddUseNoCache",
      "position": {
        "lineStart": 27,
        "lineEnd": 27,
        "columnStart": 2,
        "columnEnd": 42
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "#\n# Spark Standalone Container\n# Apache Spark 2.3.1\n#\n# Runs a super-tiny, Spark standalone cluster in a container\n# Suitable for building test/development containers for spark apps\n#\n# Usage:\n# $ docker build -t uncharted/sparklet:2.3.1 .\n# $ docker run -p 8080:8080 -it uncharted/sparklet:2.3.1\n\nFROM anapsix/alpine-java:latest\nLABEL author=\"Sean McIntyre <smcintyre@uncharted.software>\"\n\n# spark web admin ports\nEXPOSE 4040\nEXPOSE 8080\n\n# spark debugging port\nEXPOSE 9999\n\nWORKDIR /opt\n\nRUN \\\n\n  apk update --update && \\\n  # grab curl and ssh\n  apk add --no-cache --update openssh vim curl procps && \\\n  curl -f https://apache.mirror.gtcomm.net/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.6.tgz > spark.tgz && \\\n  # generate a keypair and authorize it\n  mkdir -p /root/.ssh && \\\n  ssh-keygen -f /root/.ssh/id_rsa -N \"\" && \\\n  cat /root/.ssh/id_rsa.pub > /root/.ssh/authorized_keys && \\\n  # extract spark\n  tar -xzf spark.tgz && \\\n  # cleanup spark tarball\n  rm spark.tgz && \\\n  # s6 overlay\n  curl -f -LS https://github.com/just-containers/s6-overlay/releases/download/v1.17.2.0/s6-overlay-amd64.tar.gz -o /tmp/s6-overlay.tar.gz && \\\n  tar xvfz /tmp/s6-overlay.tar.gz -C / && \\\n  rm -f /tmp/s6-overlay.tar.gz\n\n\n# upload init scripts\nADD services/spark-master-run /etc/services.d/spark-master/run\nADD services/spark-slave-run /etc/services.d/spark-slave/run\nADD services/spark-slave2-run /etc/services.d/spark-slave2/run\n\nENV PATH /opt/spark-2.3.1-bin-hadoop2.6/bin:$PATH\n\nENTRYPOINT [ \"/init\" ]\n\nCMD [\"spark-shell\"]\n"
}