{
  "startTime": 1674246053254,
  "endTime": 1674246053341,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 4,
        "columnEnd": 95
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 14,
        "lineEnd": 14,
        "columnStart": 4,
        "columnEnd": 29
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 14,
        "lineEnd": 14,
        "columnStart": 4,
        "columnEnd": 29
      }
    },
    {
      "rule": "aptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 14,
        "lineEnd": 14,
        "columnStart": 4,
        "columnEnd": 29
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM openjdk:8-jre\n\nENV SPARK_VERSION      2.0.0\nENV SPARK_BIN_VERSION  $SPARK_VERSION-bin-hadoop2.7\nENV SPARK_HOME         /opt/spark\nENV PATH               $PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin\n\n# Installing Spark for Hadoop\nRUN wget https://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_BIN_VERSION.tgz && \\\n    tar -zxf /spark-$SPARK_BIN_VERSION.tgz && \\\n    mv spark-$SPARK_BIN_VERSION $SPARK_HOME && \\\n    rm /spark-$SPARK_BIN_VERSION.tgz\n\nRUN apt-get update && apt-get -y --no-install-recommends install python && rm -rf /var/lib/apt/lists/*;\n\nRUN useradd -u 9000 -m spark\n\nCOPY spark-daemon.sh $SPARK_HOME/sbin/\nCOPY startspark.sh $SPARK_HOME/sbin/\n\nRUN chown -R  spark $SPARK_HOME\n\nUSER spark\n\nENV SPARK_MASTER_OPTS=\"-Dspark.driver.port=7001 -Dspark.fileserver.port=7002 -Dspark.broadcast.port=7003 -Dspark.replClassServer.port=7004 -Dspark.blockManager.port=7005 -Dspark.executor.port=7006 -Dspark.ui.port=4040 -Dspark.broadcast.factory=org.apache.spark.broadcast.HttpBroadcastFactory\"\n\nENV SPARK_WORKER_OPTS=\"-Dspark.driver.port=7001 -Dspark.fileserver.port=7002 -Dspark.broadcast.port=7003 -Dspark.replClassServer.port=7004 -Dspark.blockManager.port=7005 -Dspark.executor.port=7006 -Dspark.ui.port=4040 -Dspark.broadcast.factory=org.apache.spark.broadcast.HttpBroadcastFactory\"\n\nCMD [\"startspark.sh\"]\n"
}