{
  "startTime": 1674234346062,
  "endTime": 1674234346131,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 34,
        "lineEnd": 34,
        "columnStart": 4,
        "columnEnd": 40
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\nARG base_img\n\nFROM $base_img\nWORKDIR /\n\n# Reset to root to run installation tasks\nUSER 0\n\nRUN mkdir ${SPARK_HOME}/python\n# TODO: Investigate running both pip and pip3 via virtualenvs\nRUN apk add --no-cache python && \\\n    apk add --no-cache python3 && \\\n    python -m ensurepip && \\\n    python3 -m ensurepip && \\\n    # We remove ensurepip since it adds no functionality since pip is\n    # installed on the image and it just takes up 1.6MB on the image\n    rm -r /usr/lib/python*/ensurepip && \\\n    pip install --no-cache-dir --upgrade pip setuptools && \\\n    # You may install with python3 packages by using pip3.6\n    # Removed the .cache to save space\n    rm -r /root/.cache\n\nCOPY python/pyspark ${SPARK_HOME}/python/pyspark\nCOPY python/lib ${SPARK_HOME}/python/lib\nENV PYTHONPATH ${SPARK_HOME}/python/lib/pyspark.zip:${SPARK_HOME}/python/lib/py4j-*.zip\n\nWORKDIR /opt/spark/work-dir\nENTRYPOINT [ \"/opt/entrypoint.sh\" ]\n\n# Specify the User that the actual main process will run as\nARG spark_uid=185\nUSER ${spark_uid}\n"
}