{
  "startTime": 1674252291877,
  "endTime": 1674252292362,
  "originalSmells": [
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 44,
        "lineEnd": 44,
        "columnStart": 4,
        "columnEnd": 111
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 21,
        "lineEnd": 21,
        "columnStart": 4,
        "columnEnd": 78
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 60,
        "lineEnd": 60,
        "columnStart": 4,
        "columnEnd": 79
      }
    },
    {
      "rule": "configureShouldUseBuildFlag",
      "position": {
        "lineStart": 87,
        "lineEnd": 87,
        "columnStart": 4,
        "columnEnd": 15
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 74
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 14,
        "lineEnd": 14,
        "columnStart": 4,
        "columnEnd": 47
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 16,
        "lineEnd": 16,
        "columnStart": 4,
        "columnEnd": 104
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 26,
        "lineEnd": 26,
        "columnStart": 4,
        "columnEnd": 25
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 61,
        "lineEnd": 61,
        "columnStart": 4,
        "columnEnd": 31
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM nvidia/cuda:8.0-devel-centos7\n\n# MKL\nRUN mkdir -p /opt/intel/lib\nCOPY mkl_libs/libmkl_core.a /opt/intel/lib/libmkl_core.a\nCOPY mkl_libs/libmkl_gnu_thread.a /opt/intel/lib/libmkl_gnu_thread.a\nCOPY mkl_libs/libmkl_intel_lp64.a /opt/intel/lib/libmkl_intel_lp64.a\nCOPY mkl_libs/include /opt/intel/\n\nENV LC_ALL en_US.UTF-8\nENV LANG en_US.UTF-8\nENV LANGUAGE en_US.UTF-8\n\nRUN yum install -y wget curl perl util-linux xz bzip2 git patch which perl && rm -rf /var/cache/yum\nRUN yum install -y yum-utils centos-release-scl && rm -rf /var/cache/yum\nRUN yum-config-manager --enable rhel-server-rhscl-7-rpms\nRUN yum install -y devtoolset-3-gcc devtoolset-3-gcc-c++ devtoolset-3-gcc-gfortran devtoolset-3-binutils && rm -rf /var/cache/yum\nENV PATH=/opt/rh/devtoolset-3/root/usr/bin:$PATH\nENV LD_LIBRARY_PATH=/opt/rh/devtoolset-3/root/usr/lib64:/opt/rh/devtoolset-3/root/usr/lib:$LD_LIBRARY_PATH\n\n# EPEL for cmake\nRUN wget https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm && \\\n    rpm -ivh epel-release-latest-7.noarch.rpm && \\\n    rm -f epel-release-latest-7.noarch.rpm\n\n# cmake\nRUN yum install -y cmake3 && \\\n    ln -s /usr/bin/cmake3 /usr/bin/cmake && rm -rf /var/cache/yum\n\n# build python\nCOPY build_scripts /build_scripts\nRUN bash build_scripts/build.sh && rm -r build_scripts\n\nENV SSL_CERT_FILE=/opt/_internal/certs.pem\n\nRUN wget -q https://developer.nvidia.com/compute/cuda/8.0/Prod2/patches/2/cuda_8.0.61.2_linux-run && \\\n    chmod +x cuda_8.0.61.2_linux-run && \\\n    cp /usr/local/cuda/version.txt /tmp/ && \\\n    ./cuda_8.0.61.2_linux-run --silent --accept-eula --installdir=/tmp && \\\n    yes | cp -P /tmp/lib64/* /usr/local/cuda/lib64/ && \\\n    rm -rf /usr/local/cuda/lib64/lib*blas.so.8.0.61 && \\\n    rm -r cuda_8.0.61.2_linux-run\n\n# cuDNN license: https://developer.nvidia.com/cudnn/license_agreement\nRUN curl -fsSL https://developer.download.nvidia.com/compute/redist/cudnn/v7.1.2/cudnn-8.0-linux-x64-v7.1.tgz -O && \\\n    tar --no-same-owner -xzf cudnn-8.0-linux-x64-v7.1.tgz -C /usr/local && \\\n    rm cudnn-8.0-linux-x64-v7.1.tgz && \\\n    ldconfig\n\n# NCCL2 license: https://docs.nvidia.com/deeplearning/sdk/nccl-sla/index.html\nRUN wget -q https://s3.amazonaws.com/pytorch/nccl_2.2.13-1%2Bcuda8.0_x86_64.txz && \\\n    ls && \\\n    ls -alh nccl_2.2.13-1+cuda8.0_x86_64.txz && \\\n    tar --no-same-owner -xvf nccl_2.2.13-1+cuda8.0_x86_64.txz && \\\n    mv nccl_2.2.13-1+cuda8.0_x86_64/include/* /usr/local/cuda/include/ && \\\n    cp -P nccl_2.2.13-1+cuda8.0_x86_64/lib/libnccl* /usr/local/cuda/lib64/ && \\\n    rm -rf nccl_2.2.13-1+cuda8.0_x86_64* && \\\n    ldconfig\n\n# magma\nRUN wget https://icl.cs.utk.edu/projectsfiles/magma/downloads/magma-2.3.0.tar.gz && \\\n    tar -xvf magma-2.3.0.tar.gz && \\\n    cd magma-2.3.0 && \\\n    wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/cmakelists.patch && \\\n    wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/thread_queue.patch && \\\n    wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_cparict_tools.patch && \\\n    wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_dparict_tools.patch && \\\n    wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_sparict_tools.patch && \\\n    wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_zparict_tools.patch && \\\n    patch <cmakelists.patch && \\\n    patch -p0 <thread_queue.patch && \\\n    patch -p0 <magma_cparict_tools.patch && \\\n    patch -p0 <magma_dparict_tools.patch && \\\n    patch -p0 <magma_sparict_tools.patch && \\\n    patch -p0 <magma_zparict_tools.patch && \\\n    mkdir build && \\\n    cd build && \\\n    cmake .. -DUSE_FORTRAN=OFF -DGPU_TARGET=\"All\" -DCMAKE_INSTALL_PREFIX=$PREFIX && \\\n    make -j$(getconf _NPROCESSORS_CONF) && \\\n    make install && \\\n    cd .. && rm magma-2.3.0.tar.gz\n\nRUN rm -f /usr/local/bin/patchelf\nRUN git clone https://github.com/NixOS/patchelf && \\\n    cd patchelf && \\\n    sed -i 's/serial/parallel/g' configure.ac && \\\n    ./bootstrap.sh && \\\n    ./configure --build=\"$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)\" && \\\n    make && \\\n    make install && \\\n    cd .. && \\\n    rm -rf patchelf\n\n#####################################################################################\n# CUDA 8.0 prune static libs\n#####################################################################################\nARG NVPRUNE=\"/usr/local/cuda-8.0/bin/nvprune\"\nARG CUDA_LIB_DIR=\"/usr/local/cuda-8.0/lib64\"\n\nARG GENCODE=\"-gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61\"\nARG GENCODE_CUDNN=\"-gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61\"\n\n# all CUDA libs except CuDNN and CuBLAS (cudnn and cublas need arch 3.7 included)\nRUN ls $CUDA_LIB_DIR/ | grep \"\\.a\" | grep -v \"culibos\" | grep -v \"cudart\" | grep -v \"cudnn\" | grep -v \"cublas\" \\\n    | xargs -I {} bash -c \\\n    \"echo {} && $NVPRUNE $GENCODE $CUDA_LIB_DIR/{} -o $CUDA_LIB_DIR/{}\"\n\n# prune CuDNN and CuBLAS\nRUN $NVPRUNE $GENCODE_CUDNN $CUDA_LIB_DIR/libcudnn_static.a -o $CUDA_LIB_DIR/libcudnn_static.a\nRUN $NVPRUNE $GENCODE_CUDNN $CUDA_LIB_DIR/libcublas_static.a -o $CUDA_LIB_DIR/libcublas_static.a\nRUN $NVPRUNE $GENCODE_CUDNN $CUDA_LIB_DIR/libcublas_device.a -o $CUDA_LIB_DIR/libcublas_device.a\n"
}