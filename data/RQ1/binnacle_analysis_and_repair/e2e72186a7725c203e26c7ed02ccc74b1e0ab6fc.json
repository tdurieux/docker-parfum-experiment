{
  "startTime": 1674252710203,
  "endTime": 1674252710503,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 78
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 26,
        "lineEnd": 26,
        "columnStart": 4,
        "columnEnd": 22
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 29,
        "lineEnd": 29,
        "columnStart": 4,
        "columnEnd": 17
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 40,
        "lineEnd": 40,
        "columnStart": 4,
        "columnEnd": 35
      }
    },
    {
      "rule": "apkAddUseNoCache",
      "position": {
        "lineStart": 7,
        "lineEnd": 7,
        "columnStart": 4,
        "columnEnd": 33
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# Use a base image that comes with NumPy and SciPy pre-installed\nFROM publysher/alpine-scipy:1.0.0-numpy1.14.0-python3.6-alpine3.7\n# Because of the image, our versions differ from those in the requirements.txt:\n#   numpy==1.14.0 (instead of 1.13.1)\n#   scipy==1.0.0 (instead of 0.19.1)\n\n# Install Java for Stanford Tagger\nRUN apk --update --no-cache add openjdk8-jre\n# Set environment\nENV JAVA_HOME /opt/jdk\nENV PATH ${PATH}:${JAVA_HOME}/bin\n\n# Download CoreNLP full Stanford Tagger for English\nRUN wget https://nlp.stanford.edu/software/stanford-corenlp-full-2018-02-27.zip && \\\n    unzip stanford-corenlp-full-*.zip && \\\n    rm stanford-corenlp-full-*.zip && \\\n    mv stanford-corenlp-full-* stanford-corenlp\n\n# Install sent2vec\nRUN apk add --update git g++ make && \\\n    git clone https://github.com/epfml/sent2vec && \\\n    cd sent2vec && \\\n    git checkout f827d014a473aa22b2fef28d9e29211d50808d48 && \\\n    make && \\\n    apk del git make && \\\n    rm -rf /var/cache/apk/* && \\\n    pip install --no-cache-dir cython && \\\n    cd src && \\\n    python setup.py build_ext && \\\n    pip install --no-cache-dir .\n\n\n\n# Install requirements\nWORKDIR /app\nADD requirements.txt .\n# Remove NumPy and SciPy from the requirements before installing the rest\nRUN cd /app && \\\n    sed -i '/^numpy.*$/d' requirements.txt && \\\n    sed -i '/^scipy.*$/d' requirements.txt && \\\n    pip install --no-cache-dir -r requirements.txt\n\n# Download NLTK data\nRUN python -c \"import nltk; nltk.download('punkt')\"\n\n# Set the paths in config.ini\nADD config.ini.template config.ini\nRUN sed -i '6 c\\host = localhost' config.ini && \\\n    sed -i '7 c\\port = 9000' config.ini && \\\n    sed -i '10 c\\model_path = /sent2vec/pretrained_model.bin' config.ini\n\n# Add actual source code\nADD swisscom_ai swisscom_ai/\nADD launch.py .\n\nENTRYPOINT [\"/bin/sh\"]"
}