{
  "startTime": 1674239842923,
  "endTime": 1674239843003,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 32,
        "lineEnd": 32,
        "columnStart": 4,
        "columnEnd": 91
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 6,
        "lineEnd": 9,
        "columnStart": 22,
        "columnEnd": 15
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 34,
        "lineEnd": 34,
        "columnStart": 4,
        "columnEnd": 29
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 34,
        "lineEnd": 34,
        "columnStart": 4,
        "columnEnd": 29
      }
    },
    {
      "rule": "aptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 6,
        "lineEnd": 9,
        "columnStart": 22,
        "columnEnd": 15
      }
    },
    {
      "rule": "aptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 34,
        "lineEnd": 34,
        "columnStart": 4,
        "columnEnd": 29
      }
    }
  ],
  "repairedSmells": [
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 34,
        "lineEnd": 34,
        "columnStart": 4,
        "columnEnd": 53
      }
    }
  ],
  "repairedDockerfile": "FROM ubuntu:16.04 AS base\n\nARG PYTHON_VERSION=3.6\n\nENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64\n\nRUN apt-get update && apt-get install --no-install-recommends -y \\\n    openjdk-8-jdk \\\n    wget bzip2 \\\n    python3-pip && rm -rf /var/lib/apt/lists/*;\n\nENV PYTHON_VERSION $PYTHON_VERSION\nENV SCALA_VERSION 2.11.8\nENV SPARK_VERSION 2.4.0\nENV SPARK_BUILD \"spark-${SPARK_VERSION}-bin-hadoop2.7\"\nENV SPARK_BUILD_URL \"https://dist.apache.org/repos/dist/release/spark/spark-2.4.0/${SPARK_BUILD}.tgz\"\nRUN wget $SPARK_BUILD_URL -O /tmp/spark.tgz && \\\n    tar -C /opt -xf /tmp/spark.tgz && \\\n    mv /opt/$SPARK_BUILD /opt/spark && \\\n    rm /tmp/spark.tgz\nENV SPARK_HOME /opt/spark\nENV PATH $SPARK_HOME/bin:$PATH\nENV PYTHONPATH /opt/spark/python/lib/py4j-0.10.7-src.zip:/opt/spark/python/lib/pyspark.zip:$PYTHONPATH\nENV PYSPARK_PYTHON python\n\nWORKDIR /app\n\nCOPY . /app\n\nENV LC_ALL C.UTF-8\nENV LANG C.UTF-8\n\nRUN pip3 install --no-cache-dir tensorflow pandas numpy matplotlib seaborn scipy jupyter pyspark sparkflow\n\nRUN apt install --no-install-recommends -y supervisor && rm -rf /var/lib/apt/lists/*;\n\nENV PYSPARK_PYTHON python3\nENV PYSPARK_DRIVER_PYTHON python3\n"
}