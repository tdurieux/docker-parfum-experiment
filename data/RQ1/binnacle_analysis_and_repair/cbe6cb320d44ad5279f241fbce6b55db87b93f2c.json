{
  "startTime": 1674252782122,
  "endTime": 1674252782221,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 28,
        "lineEnd": 28,
        "columnStart": 5,
        "columnEnd": 142
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 23,
        "lineEnd": 23,
        "columnStart": 5,
        "columnEnd": 79
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# HELK script: HELK Spark Base Dockerfile\n# HELK build Stage: Alpha\n# Author: Roberto Rodriguez (@Cyb3rWard0g)\n# License: GPL-3.0\n\nFROM cyb3rward0g/helk-base:0.0.3\nLABEL maintainer=\"Roberto Rodriguez @Cyb3rWard0g\"\nLABEL description=\"Dockerfile base for HELK Spark.\"\n\nENV DEBIAN_FRONTEND noninteractive\n\n# *********** Spark Env Variables ***************\nENV SPARK_VERSION=2.4.3 \\\n  APACHE_HADOOP_VERSION=2.7 \\\n  SPARK_HOME=/opt/helk/spark \\\n  SPARK_LOGS=$SPARK_HOME/logs \\\n  SPARK_GID=710 \\\n  SPARK_UID=710 \\\n  SPARK_USER=sparkuser\n\n# *********** Installing Prerequisites ***************\n# -qq : No output except for errors\nRUN apt-get update -qq \\\n  && apt-get install --no-install-recommends -qqy openjdk-8-jre-headless ca-certificates-java python3.7 \\\n  && apt-get -qy clean autoremove \\\n  && rm -rf /var/lib/apt/lists/* \\\n  # *********** Installing Spark and creating user ***************\n  && bash -c 'mkdir -pv /opt/helk/spark' \\\n  && wget -qO- https://mirror.reverse.net/pub/apache/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${APACHE_HADOOP_VERSION}.tgz | sudo tar xvz -C /opt/helk/spark --strip-components=1 \\\n  && mkdir -p $SPARK_LOGS \\\n  && groupadd -g ${SPARK_GID} ${SPARK_USER} \\\n  && useradd -u ${SPARK_UID} -g ${SPARK_GID} -d ${SPARK_HOME} --no-create-home ${SPARK_USER} \\\n  && chown -R ${SPARK_USER}:${SPARK_USER} ${SPARK_HOME}"
}