{
  "startTime": 1674239513483,
  "endTime": 1674239513576,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 26,
        "lineEnd": 26,
        "columnStart": 4,
        "columnEnd": 104
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 10,
        "lineEnd": 10,
        "columnStart": 4,
        "columnEnd": 67
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 25,
        "lineEnd": 25,
        "columnStart": 4,
        "columnEnd": 88
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM ubuntu:14.04\n\n\n####################\n# JAVA\n####################\n\nENV JAVA_HOME\t\t/usr/lib/jvm/java-7-openjdk-amd64\n\nRUN apt-get update && \\\n    DEBIAN_FRONTEND=noninteractive apt-get --no-install-recommends install -y openjdk-7-jdk && \\\n    rm -rf /var/lib/apt/lists/*\n\n\n\n####################\n# HADOOP\n####################\n\nENV HADOOP_VERSION\t2.6.0\nENV HADOOP_HOME\t\t/usr/local/hadoop\nENV HADOOP_OPTS\t\t-Djava.library.path=/usr/local/hadoop/lib/native\nENV PATH\t\t$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n\nRUN apt-get update && \\\n    DEBIAN_FRONTEND=noninteractive apt-get --no-install-recommends install -y wget libzip2 libsnappy1 libssl-dev && \\\n    wget https://archive.apache.org/dist/hadoop/core/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz && \\\n    apt-get remove -y wget && \\\n    rm -rf /var/lib/apt/lists/* && \\\n    tar -zxf /hadoop-$HADOOP_VERSION.tar.gz && \\\n    rm /hadoop-$HADOOP_VERSION.tar.gz && \\\n    mv hadoop-$HADOOP_VERSION /usr/local/hadoop && \\\n    mkdir -p /usr/local/hadoop/logs\n\n\n# Overwrite default HADOOP configuration files with our config files\nCOPY conf  $HADOOP_HOME/etc/hadoop/\n\n# Formatting HDFS\nRUN mkdir -p /data/dfs/data /data/dfs/name /data/dfs/namesecondary && \\\n    hdfs namenode -format\nVOLUME /data\n\n\n# Helper script for starting YARN\nADD start-yarn.sh /usr/local/bin/start-yarn.sh\n\n\n\n####################\n# PORTS\n####################\n#\n# http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.3.0/bk_HDP_Reference_Guide/content/reference_chap2.html\n# http://www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/cdh_ig_ports_cdh5.html\n# http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/core-default.xml\n# http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml\n\n# HDFS: NameNode (NN):\n#\t 8020 = fs.defaultFS\t\t\t(IPC / File system metadata operations)\n#\t\t\t\t\t\t(9000 is also frequently used alternatively)\n#\t 8022 = dfs.namenode.servicerpc-address\t(optional port used by HDFS daemons to avoid sharing RPC port)\n#       50070 = dfs.namenode.http-address\t(HTTP  / NN Web UI)\n#\t50470 = dfs.namenode.https-address\t(HTTPS / Secure UI)\n# HDFS: DataNode (DN):\n#\t50010 = dfs.datanode.address\t\t(Data transfer)\n#\t50020 = dfs.datanode.ipc.address\t(IPC / metadata operations)\n#\t50075 = dfs.datanode.http.address\t(HTTP  / DN Web UI)\n#\t50475 = dfs.datanode.https.address\t(HTTPS / Secure UI)\n# HDFS: Secondary NameNode (SNN)\n#\t50090 = dfs.secondary.http.address\t(HTTP / Checkpoint for NameNode metadata)\nEXPOSE 9000 50070 50010 50020 50075 50090\n\n\n\nCMD [\"hdfs\"]\n"
}