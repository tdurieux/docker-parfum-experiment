{
  "startTime": 1674253045775,
  "endTime": 1674253045856,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 4,
        "columnEnd": 87
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 3,
        "lineEnd": 3,
        "columnStart": 4,
        "columnEnd": 28
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 3,
        "lineEnd": 3,
        "columnStart": 4,
        "columnEnd": 28
      }
    },
    {
      "rule": "aptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 3,
        "lineEnd": 3,
        "columnStart": 4,
        "columnEnd": 28
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM java:latest\n\nRUN apt-get update -y && apt-get install --no-install-recommends -y scala && rm -rf /var/lib/apt/lists/*;\n\n# Get Spark from some apache mirror.\nRUN mkdir -p /opt && \\\n    cd /opt && \\\n    wget https://apache.mirrors.pair.com/spark/spark-1.4.0/spark-1.4.0-bin-hadoop2.6.tgz && \\\n    tar -zvxf spark-1.4.0-bin-hadoop2.6.tgz && \\\n    rm spark-1.4.0-bin-hadoop2.6.tgz && \\\n    ln -s spark-1.4.0-bin-hadoop2.6 spark && \\\n    echo Spark installed in /opt\n\nADD log4j.properties /opt/spark/conf/log4j.properties\nADD setup_client.sh /\nENV PATH $PATH:/opt/spark/bin\n"
}