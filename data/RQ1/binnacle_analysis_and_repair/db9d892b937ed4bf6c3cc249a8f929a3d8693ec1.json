{
  "startTime": 1674236148554,
  "endTime": 1674236148780,
  "originalSmells": [
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 20,
        "lineEnd": 20,
        "columnStart": 4,
        "columnEnd": 30
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 7,
        "lineEnd": 7,
        "columnStart": 4,
        "columnEnd": 71
      }
    },
    {
      "rule": "aptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 7,
        "lineEnd": 7,
        "columnStart": 4,
        "columnEnd": 71
      }
    },
    {
      "rule": "aptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 20,
        "lineEnd": 20,
        "columnStart": 4,
        "columnEnd": 30
      }
    }
  ],
  "repairedSmells": [
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 7,
        "lineEnd": 7,
        "columnStart": 4,
        "columnEnd": 71
      }
    }
  ],
  "repairedDockerfile": "FROM java:openjdk-8\n\n# install cassandra\nENV CASSANDRA_HOME=\"/opt/cassandra\"\nARG CASSANDRA_VERSION=\"3.11.0\"\nARG CASSANDRA_ARTIFACT=\"apache-cassandra-${CASSANDRA_VERSION}\"\nARG CASSANDRA_URL=\"http://archive.apache.org/dist/cassandra/${CASSANDRA_VERSION}/${CASSANDRA_ARTIFACT}-bin.tar.gz\"\nRUN apt-get -qq install -y --no-install-recommends wget ca-certificates && \\\n    wget -qO - ${CASSANDRA_URL} | tar -xzC /opt && \\\n    ln -s /opt/${CASSANDRA_ARTIFACT} ${CASSANDRA_HOME} && rm -rf /var/lib/apt/lists/*;\n\n# install sbt and scala\nARG SCALA_VERSION=\"2.11.7\"\nARG SBT_VERSION=\"0.13.13\"\nARG SBT_ARTIFACT=\"sbt-${SBT_VERSION}.deb\"\nARG SBT_URL=\"https://dl.bintray.com/sbt/debian/${SBT_ARTIFACT}\"\nRUN wget -q ${SBT_URL} && \\\n    dpkg -i ${SBT_ARTIFACT} && \\\n    rm ${SBT_ARTIFACT} && \\\n    apt-get -qq update && \\\n    apt-get -qq --no-install-recommends install -y sbt && \\\n    sbt ++${SCALA_VERSION} sbtVersion && rm -rf /var/lib/apt/lists/*;\n\n# install spark\nENV SPARK_HOME=\"/opt/spark\"\nARG SPARK_VERSION=\"2.2.0\"\nARG SPARK_ARTIFACT=\"spark-${SPARK_VERSION}-bin-hadoop2.7\"\nARG SPARK_URL=\"http://d3kbcqa49mib13.cloudfront.net/${SPARK_ARTIFACT}.tgz\"\nRUN wget -qO - ${SPARK_URL} | tar -xzC /opt && \\\n    ln -s /opt/${SPARK_ARTIFACT} ${SPARK_HOME} && \\\n    cp ${SPARK_HOME}/conf/log4j.properties.template ${SPARK_HOME}/conf/log4j.properties\n\nENV PATH=\"$JAVA_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin:$PATH\"\nUSER root\nWORKDIR /root\n\n# install streaming job\nADD src /app/src\nADD lib /app/lib\nADD project /app/project\nADD build.sbt /app/build.sbt\nRUN cd /app && \\\n    echo 'version := \"0.0.0\"' > version.sbt && \\\n    FORTIS_INTEGRATION_TESTS=\"true\" JAVA_OPTS=\"-Xmx4096M\" sbt ++${SCALA_VERSION} assembly && \\\n    find /app/target -name '*-assembly-0.0.0.jar' -exec mv {} /app/job.jar \\; -quit && \\\n    rm -rf /app/target && \\\n    rm -rf $HOME/.ivy2 && \\\n    cd -\n\n# install tools\nADD docker/run-spark.sh /app/spark\nADD docker/run-cqlsh.sh /app/cqlsh\nCMD /app/spark\n\n# access keys for azure resources\nENV APPINSIGHTS_INSTRUMENTATIONKEY=\"\"\nENV APPLICATION_INSIGHTS_IKEY=\"\"\nENV FORTIS_SB_CONN_STR=\"\"\n\n# these settings need to be in sync with project-fortis-services\nENV FORTIS_SB_CONFIG_QUEUE=\"configuration\"\nENV FORTIS_SB_COMMAND_QUEUE=\"command\"\n\n# root url for downloading opener model files\nENV FORTIS_CENTRAL_ASSETS_HOST=\"https://fortiscentral.blob.core.windows.net\"\n\n# a one-node local cassandra is set up via docker-compose, if you wish to use a\n# larger cluster (e.g. hosted in Azure), just override this variable with the\n# hostname of your cluster\nENV FORTIS_CASSANDRA_HOST=\"cassandra\"\nENV FORTIS_CASSANDRA_PORT=\"9042\"\nENV FORTIS_CASSANDRA_USERNAME=\"cassandra\"\nENV FORTIS_CASSANDRA_PASSWORD=\"cassandra\"\n\n# configuration for the aggregations to cassandra\n# setting higher values for these will exponentially increase the write load to\n# the database since there's a combinatorial explosion happening under the hood\nENV FORTIS_EVENT_MAX_KEYWORDS=\"5\"\nENV FORTIS_EVENT_MAX_LOCATIONS=\"4\"\n\n# deployment of https://github.com/CatalystCode/featureService\n# a local instance backed by Azure PostgreSQL DB gets set up via docker-compose\nENV FORTIS_FEATURE_SERVICE_HOST=\"http://featureservice\"\n\n# configuration for spark and monitoring web interfaces\n# - spark-context 4040\n# - spark-master on 8080\n# - spark-worker on 8081\nENV SPARK_MAINCLASS=\"com.microsoft.partnercatalyst.fortis.spark.ProjectFortis\"\nENV SPARK_DRIVER_MEMORY=\"4g\"\nENV HA_PROGRESS_DIR=\"\"\nENV FORTIS_STREAMING_DURATION_IN_SECONDS=\"30\"\nENV FORTIS_SSC_INIT_RETRY_AFTER_MILLIS=\"60000\"\nENV FORTIS_SSC_SHUTDOWN_DELAY_MILLIS=\"60000\"\nEXPOSE 4040 8080 8081\n"
}