{
  "startTime": 1674240616845,
  "endTime": 1674240616938,
  "originalSmells": [
    {
      "rule": "mkdirUsrSrcThenRemove",
      "position": {
        "lineStart": 9,
        "lineEnd": 9,
        "columnStart": 4,
        "columnEnd": 25
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM python:2.7.12-alpine\nMAINTAINER Madison Bahmer <madison.bahmer@istresearch.com>\n\n\n# copy crawler own requirements.txt with its dependencies\nCOPY crawler/requirements.txt /usr/src/app/\n\n# Combine run command to create single intermeiate image layer\n# This MANDATORY because developments dependencies are huge.\nRUN mkdir -p /usr/src/app \\\n && cd /usr/src/app \\\n# Installing runtime dependencies\n && apk --no-cache add \\\n      curl \\\n      openssl \\\n      libffi \\\n      libxml2 \\\n      libxslt \\\n# Installing buildtime dependencies. They will be removed at end of this\n# commands sequence.\n && apk --no-cache add --virtual build-dependencies \\\n      build-base \\\n      openssl-dev \\\n      libffi-dev \\\n      libxml2-dev \\\n      libxslt-dev \\\n# Updating pip itself before installing packages from requirements.txt\n && pip install --no-cache-dir pip setuptools \\\n# Installing pip packages from requirements.txt\n && pip install --no-cache-dir -r requirements.txt \\\n# Removing build dependencies leaving image layer clean and neat \\\n && apk del build-dependencies && rm -rf /usr/src/app\n\n# move codebase over\nCOPY crawler /usr/src/app\n\nWORKDIR /usr/src/app\n\n# override settings via localsettings.py\nCOPY docker/crawler/settings.py /usr/src/app/crawling/localsettings.py\n\n# copy testing script into container\nCOPY docker/run_docker_tests.sh /usr/src/app/run_docker_tests.sh\n\n# set up environment variables\n\n# run command\nCMD [\"scrapy\", \"runspider\", \"crawling/spiders/link_spider.py\"]\n"
}