{
  "startTime": 1674248880455,
  "endTime": 1674248881014,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 126,
        "lineEnd": 126,
        "columnStart": 8,
        "columnEnd": 70
      }
    },
    {
      "rule": "configureShouldUseBuildFlag",
      "position": {
        "lineStart": 91,
        "lineEnd": 91,
        "columnStart": 7,
        "columnEnd": 124
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM alpine:3.5\nMAINTAINER smizy\n\nARG BUILD_DATE\nARG VCS_REF\nARG VERSION\n\nLABEL \\\n    org.label-schema.build-date=$BUILD_DATE \\\n    org.label-schema.docker.dockerfile=\"/Dockerfile\" \\\n    org.label-schema.license=\"Apache License 2.0\" \\\n    org.label-schema.name=\"smizy/hadoop-base\" \\\n    org.label-schema.url=\"https://github.com/smizy\" \\\n    org.label-schema.vcs-ref=$VCS_REF \\\n    org.label-schema.vcs-type=\"Git\" \\\n    org.label-schema.vcs-url=\"https://github.com/smizy/docker-hadoop-base\"\n\nENV HADOOP_VERSION      $VERSION\nENV HADOOP_HOME         /usr/local/hadoop-${HADOOP_VERSION}\nENV HADOOP_COMMON_HOME  ${HADOOP_HOME}\nENV HADOOP_HDFS_HOME    ${HADOOP_HOME}\nENV HADOOP_MAPRED_HOME  ${HADOOP_HOME}\nENV HADOOP_YARN_HOME    ${HADOOP_HOME}\nENV HADOOP_CONF_DIR     ${HADOOP_HOME}/etc/hadoop\nENV HADOOP_LOG_DIR      /var/log/hdfs\nENV HADOOP_TMP_DIR      /hadoop\nENV YARN_CONF_DIR       ${HADOOP_HOME}/etc/hadoop\nENV YARN_HOME           ${HADOOP_HOME}\nENV YARN_LOG_DIR        /var/log/yarn\n\nENV JAVA_HOME   /usr/lib/jvm/default-jvm\nENV PATH        $PATH:${JAVA_HOME}/bin:${HADOOP_HOME}/sbin:${HADOOP_HOME}/bin\n\nENV HADOOP_CLUSTER_NAME       hadoop\nENV HADOOP_ZOOKEEPER_QUORUM   zookeeper-1.vnet:2181,zookeeper-2.vnet:2181,zookeeper-3.vnet:2181\nENV HADOOP_NAMENODE1_HOSTNAME namenode-1.vnet\nENV HADOOP_NAMENODE2_HOSTNAME namenode-2.vnet\nENV HADOOP_QJOURNAL_ADDRESS   journalnode-1.vnet:8485;journalnode-2.vnet:8485;journalnode-3.vnet:8485\nENV HADOOP_DFS_REPLICATION    3\nENV YARN_RESOURCEMANAGER_HOSTNAME resourcemanager-1.vnet\nENV MAPRED_JOBHISTORY_HOSTNAME    historyserver-1.vnet\n\n# [Java 8] Over usage of virtual memory(https://issues.apache.org/jira/browse/YARN-4714)\n# ENV MAPRED_CHILD_JAVA_OPTS \"-XX:ReservedCodeCacheSize=100M -XX:MaxMetaspaceSize=256m -XX:CompressedClassSpaceSize=256m\"\n\n## default memory/cpu setting\nENV HADOOP_HEAPSIZE              1000\nENV YARN_HEAPSIZE                1000\nENV YARN_NODEMANAGER_MEMORY_MB   8192\nENV YARN_NODEMANAGER_CPU_VCORES  8\nENV YARN_NODEMANAGER_VMEM_CHECK  true\nENV YARN_SCHEDULER_MIN_ALLOC_MB  1024\nENV YARN_APPMASTER_MEMORY_MB     1536\nENV YARN_APPMASTER_COMMAND_OPTS  -Xmx1024m\nENV MAPRED_MAP_MEMORY_MB         1024\nENV MAPRED_REDUCE_MEMORY_MB      1024\n\n## HDFS path\nENV YARN_REMOTE_APP_LOG_DIR      /tmp/logs\nENV YARN_APP_MAPRED_STAGING_DIR  /tmp/hadoop-yarn/staging\n\nENV PROTOBUF_VERSION     2.5.0\nENV GOOGLETEST_VERSION   1.5.0   \n\nRUN set -x \\\n    && apk --no-cache add \\\n        bash \\\n        openjdk8-jre \\\n        su-exec \\\n        tar \\\n        wget \\\n    ## Build Protobuf\n    ## - dependency lib\n    && apk --no-cache add \\\n        zlib \\\n    && apk --no-cache add --virtual .builddeps \\\n        autoconf \\\n        automake \\\n        build-base \\\n        libtool \\\n        zlib-dev \\\n    # - protobuf src\n    && wget -q -O - https://github.com/google/protobuf/archive/v${PROTOBUF_VERSION}.tar.gz \\\n        | tar -xzf - -C /tmp \\\n    && cd /tmp/protobuf-* \\\n    # - gtest src\n    && wget -q -O - https://github.com/google/googletest/archive/release-${GOOGLETEST_VERSION}.tar.gz \\\n        | tar -xzf - \\\n    && mv googletest-* gtest \\\n    # - build\n    && ./autogen.sh \\\n    && CXXFLAGS=\"$CXXFLAGS -fno-delete-null-pointer-checks\" ./configure --build=\"$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)\" --prefix=/usr --sysconfdir=/etc --localstatedir=/var \\\n    && make \\\n    && make check \\\n    && make install \\\n    && rm -rf /tmp/protobuf-* \\\n\n    ## Build Hadoop\n    ## - dependency lib\n    && apk --no-cache add \\\n        bash \\\n        bzip2 \\\n        fts \\\n        fuse \\\n        libressl-dev \\\n        libtirpc \\\n        snappy \\\n        zlib \\\n    && apk --no-cache add --virtual .builddeps.1 \\\n        autoconf \\\n        automake \\\n        build-base \\\n        bzip2-dev \\\n        cmake \\\n        curl \\\n        fts-dev \\\n        fuse-dev \\\n        git \\\n        libtirpc-dev \\\n        libtool \\\n        maven \\\n        openjdk8 \\\n        snappy-dev \\\n        zlib-dev \\\n    ## - hadoop src\n    && mirror_url=$( wget -q -O - \"https://www.apache.org/dyn/closer.cgi/?as_json=1\" \\\n        | grep \"preferred\" \\\n        | sed -n 's#.*\"\\(http://*[^\"]*\\)\".*#\\1#p') \\\n\n    && wget -q -O - ${mirror_url}/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}-src.tar.gz \\\n        | tar -xzf - -C /tmp \\\n\n    && cd /tmp/hadoop-* \\\n    ## - bad substitution at line 11\n    && sed -ri 's/executable=\"sh\"/executable=\"bash\"/g' hadoop-project-dist/pom.xml \\\n    ## - error: 'sys_nerr' undeclared (first use in this function)\n    && sed -ri 's/^#if defined\\(__sun\\)/#if 1/g' hadoop-common-project/hadoop-common/src/main/native/src/exception.c \\\n    ## - error: undefined reference to fts_*\n    && sed -ri 's/^( *container)/\\1\\n    fts/g' hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/CMakeLists.txt \\\n    ## - warning: implicit declaration of function 'setnetgrent'\n    && sed -ri 's/^(.*JniBasedUnixGroupsNetgroupMapping.c)/#\\1/g' hadoop-common-project/hadoop-common/src/CMakeLists.txt \\\n    ## - fatal error: rpc/types.h: No such file or directory\n    && sed -ri 's#^(include_directories.*)#\\1\\n    /usr/include/tirpc#' hadoop-tools/hadoop-pipes/src/CMakeLists.txt \\\n    && sed -ri 's/^( *pthread)/\\1\\n    tirpc/g' hadoop-tools/hadoop-pipes/src/CMakeLists.txt \\\n    ## - build\n    && mvn package -Pdist,native -DskipTests -DskipDocs -Dtar \\\n#    && mv hadoop-dist/target/hadoop-${HADOOP_VERSION} /usr/local/ \\\n    && mv hadoop-dist/target/hadoop-${HADOOP_VERSION}.tar.gz / \\\n    && tar -xzf /hadoop-${HADOOP_VERSION}.tar.gz -C /usr/local \\\n    && rm -rf /tmp/hadoop-* \\\n    && cd / \\\n\n    # # download hadoop-bin\n    # && set -x \\\n    # && mirror_url=$( \\\n    #     wget -q -O - http://www.apache.org/dyn/closer.cgi/hadoop/common/ \\\n    #     | sed -n 's#.*href=\"\\(http://ftp.[^\"]*\\)\".*#\\1#p' \\\n    #     | head -n 1 \\\n    # ) \\\n    # && wget -q -O - ${mirror_url}/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz \\\n    #    | tar -xzf - -C /usr/local \\\n    && ln -s /usr/local/hadoop-${HADOOP_VERSION} /usr/local/hadoop-${HADOOP_VERSION%.*} \\\n    && env \\\n       | grep -E '^(JAVA|HADOOP|PATH|YARN)' \\\n       | sed 's/^/export /g' \\\n       > ~/.profile \\\n    && cp ~/.profile /etc/profile.d/hadoop \\\n    && sed -i 's@${JAVA_HOME}@'${JAVA_HOME}'@g' ${HADOOP_CONF_DIR}/hadoop-env.sh \\\n    # user/dir/permission\n    && adduser -D -g '' -s /sbin/nologin -u 1000 docker \\\n    && for user in hadoop hdfs yarn mapred hbase; do \\\n         adduser -D -g '' -s /sbin/nologin ${user}; \\\n       done \\\n    && for user in root hdfs yarn mapred hbase docker; do \\\n         adduser ${user} hadoop; \\\n       done \\\n    && mkdir -p \\\n        ${HADOOP_TMP_DIR}/dfs \\\n        ${HADOOP_TMP_DIR}/yarn \\\n        ${HADOOP_TMP_DIR}/mapred \\\n        ${HADOOP_TMP_DIR}/nm-local-dir \\\n        ${HADOOP_TMP_DIR}/yarn-nm-recovery \\\n        ${HADOOP_LOG_DIR} \\\n        ${YARN_LOG_DIR} \\\n    && chmod -R 775 \\\n        ${HADOOP_LOG_DIR} \\\n        ${YARN_LOG_DIR} \\\n    && chmod -R 700 ${HADOOP_TMP_DIR}/dfs \\\n    && chown -R hdfs:hadoop \\\n        ${HADOOP_TMP_DIR}/dfs \\\n        ${HADOOP_LOG_DIR} \\\n    && chown -R yarn:hadoop \\\n        ${HADOOP_TMP_DIR}/yarn \\\n        ${HADOOP_TMP_DIR}/nm-local-dir \\\n        ${HADOOP_TMP_DIR}/yarn-nm-recovery \\\n        ${YARN_LOG_DIR} \\\n    && chown -R mapred:hadoop \\\n        ${HADOOP_TMP_DIR}/mapred \\\n    # cleanup\n    # - remove unnecessary doc/src files\n    && rm -rf ${HADOOP_HOME}/share/doc \\\n    && for dir in common hdfs mapreduce tools yarn; do \\\n         rm -rf ${HADOOP_HOME}/share/hadoop/${dir}/sources; \\\n       done \\\n    && rm -rf ${HADOOP_HOME}/share/hadoop/common/jdiff \\\n    && rm -rf ${HADOOP_HOME}/share/hadoop/mapreduce/lib-examples \\\n    && rm -rf ${HADOOP_HOME}/share/hadoop/yarn/test \\\n    && find ${HADOOP_HOME}/share/hadoop -name *test*.jar | xargs rm -rf \\\n#    && rm -rf ${HADOOP_HOME}/lib/native \\\n    && rm /hadoop-${HADOOP_VERSION}.tar.gz \\\n    && rm -rf /root/.m2 \\\n    && apk del \\\n        .builddeps \\\n        .builddeps.1 \\\n    && echo\n\n\nCOPY etc/*  ${HADOOP_CONF_DIR}/\nCOPY bin/*  /usr/local/bin/\nCOPY lib/*  /usr/local/lib/\n\nWORKDIR ${HADOOP_HOME}\n\nVOLUME [\"${HADOOP_TMP_DIR}\", \"${HADOOP_LOG_DIR}\", \"${YARN_LOG_DIR}\", \"${HADOOP_HOME}\"]\n\nENTRYPOINT [\"entrypoint.sh\"]"
}