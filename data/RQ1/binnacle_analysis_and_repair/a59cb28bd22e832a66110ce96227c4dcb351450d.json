{
  "startTime": 1674245758769,
  "endTime": 1674245759364,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 45,
        "lineEnd": 46,
        "columnStart": 4,
        "columnEnd": 101
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 58,
        "lineEnd": 59,
        "columnStart": 4,
        "columnEnd": 61
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 72,
        "lineEnd": 72,
        "columnStart": 4,
        "columnEnd": 102
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 45,
        "lineEnd": 46,
        "columnStart": 4,
        "columnEnd": 101
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 58,
        "lineEnd": 59,
        "columnStart": 4,
        "columnEnd": 61
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 72,
        "lineEnd": 72,
        "columnStart": 4,
        "columnEnd": 102
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 35,
        "lineEnd": 35,
        "columnStart": 7,
        "columnEnd": 29
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 84,
        "lineEnd": 84,
        "columnStart": 4,
        "columnEnd": 84
      }
    },
    {
      "rule": "apkAddUseNoCache",
      "position": {
        "lineStart": 23,
        "lineEnd": 23,
        "columnStart": 4,
        "columnEnd": 100
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM frolvlad/alpine-oraclejdk8:slim\n\n# adapted from https://github.com/P7h/docker-spark/blob/master/Dockerfile\n\n# Scala related variables.\nARG SCALA_VERSION=2.11.8\nARG SCALA_BINARY_ARCHIVE_NAME=scala-${SCALA_VERSION}\nARG SCALA_BINARY_DOWNLOAD_URL=https://downloads.lightbend.com/scala/${SCALA_VERSION}/${SCALA_BINARY_ARCHIVE_NAME}.tgz\n\n# SBT related variables.\nARG SBT_VERSION=0.13.15\nARG SBT_BINARY_ARCHIVE_NAME=sbt-$SBT_VERSION\nARG SBT_BINARY_DOWNLOAD_URL=https://dl.bintray.com/sbt/native-packages/sbt/${SBT_VERSION}/${SBT_BINARY_ARCHIVE_NAME}.tgz\n\n# Configure env variables for Scala, SBT and Spark.\n# Also configure PATH env variable to include binary folders of Java, Scala, SBT and Spark.\nENV SCALA_HOME  /usr/local/scala\nENV SBT_HOME    /usr/local/sbt\nENV SPARK_HOME  /usr/local/spark\nENV PATH        $JAVA_HOME/bin:$SCALA_HOME/bin:$SBT_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin:$PATH\n\n# Download, uncompress and move all the required packages and libraries to their corresponding directories in /usr/local/ folder.\nRUN apk update && \\\n    apk add --no-cache build-base nodejs nodejs-npm lapack-dev python3-dev git bzip2 openssl gfortran curl bash && \\\n    rm -rf /var/lib/apt/lists/* && \\\n    rm -rf /tmp/* && \\\n    wget -qO - ${SCALA_BINARY_DOWNLOAD_URL} | tar -xz -C /usr/local/ && \\\n    wget -qO - ${SBT_BINARY_DOWNLOAD_URL} | tar -xz -C /usr/local/ && \\\n    cd /usr/local/ && \\\n    ln -s ${SCALA_BINARY_ARCHIVE_NAME} scala \\\n    && packages=' \\\n        numpy \\\n        scipy \\\n        simplejson \\\n     ' \\\n    && pip3 install --no-cache-dir $packages\n#    cp spark/conf/log4j.properties.template spark/conf/log4j.properties && \\\n#    sed -i -e s/WARN/ERROR/g spark/conf/log4j.properties && \\\n#    sed -i -e s/INFO/ERROR/g spark/conf/log4j.properties \\\n\n# HADOOP\nENV HADOOP_VERSION 2.7.3\nENV HADOOP_HOME /usr/hadoop-$HADOOP_VERSION\nENV HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\nENV PATH $PATH:$HADOOP_HOME/bin\nRUN curl -f -sL --retry 3 \\\n  \"https://archive.apache.org/dist/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz\" \\\n  | gunzip \\\n  | tar -x -C /usr/ \\\n && rm -rf $HADOOP_HOME/share/doc \\\n && chown -R root:root $HADOOP_HOME\n\n# SPARK\nENV SPARK_VERSION 2.1.0\nENV SPARK_PACKAGE spark-${SPARK_VERSION}-bin-without-hadoop\nENV SPARK_HOME /usr/spark-${SPARK_VERSION}\nENV SPARK_DIST_CLASSPATH=\"$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*\"\nENV PATH $PATH:${SPARK_HOME}/bin\nRUN curl -f -sL --retry 3 \\\n  \"https://d3kbcqa49mib13.cloudfront.net/${SPARK_PACKAGE}.tgz\" \\\n  | gunzip \\\n  | tar x -C /usr/ \\\n && mv /usr/$SPARK_PACKAGE $SPARK_HOME \\\n && chown -R root:root $SPARK_HOME\n\n# Zeppelin\nENV ZEPPELIN_PORT 8080\nENV ZEPPELIN_HOME /usr/zeppelin\nENV ZEPPELIN_CONF_DIR $ZEPPELIN_HOME/conf\nENV ZEPPELIN_NOTEBOOK_DIR $ZEPPELIN_HOME/notebook\nRUN echo '{ \"allow_root\": true }' > /root/.bowerrc\nRUN set -ex \\\n && curl -f -sL https://archive.apache.org/dist/maven/maven-3/3.5.0/binaries/apache-maven-3.5.0-bin.tar.gz \\\n   | gunzip \\\n   | tar x -C /tmp/\n\nRUN git clone https://github.com/ShamsUlAzeem/zeppelin.git /usr/src/zeppelin\n\nRUN cd /usr/src/zeppelin && git init && git fetch && git checkout 'ipynb-export/import'\n\nRUN cd /usr/src/zeppelin \\\n && MAVEN_OPTS=\"-Xmx2g -XX:MaxPermSize=1024m\" /tmp/apache-maven-3.5.0/bin/mvn package -Pbuild-distr -DskipTests \\\n -Pspark-1.6 \\\n# -Pspark-2.1 \\\n && tar xvf /usr/src/zeppelin/zeppelin-distribution/target/zeppelin*.tar.gz -C /usr/ \\\n && mv /usr/zeppelin* $ZEPPELIN_HOME \\\n && mkdir -p $ZEPPELIN_HOME/logs \\\n && mkdir -p $ZEPPELIN_HOME/run \\\n && rm -rf /var/lib/apt/lists/* \\\n && rm -rf /usr/src/zeppelin \\\n && rm -rf /root/.m2 \\\n && rm -rf /root/.npm \\\n && find /tmp -maxdepth 1 -not -name 'apache-maven-3.5.0' -not -name \".\" -exec rm -rf {} \\; \\\n # Removing extra interpreter folders \\\n && find $ZEPPELIN_HOME/interpreter -maxdepth 1 -type d -not -name 'spark' -not -name 'md' -not -name \".\" -exec rm -rf {} \\; && rm /usr/src/zeppelin/zeppelin-distribution/target/zeppelin*.tar.gz\n\nRUN ln -s -f /usr/bin/pip3 /usr/bin/pip \\\n && ln -s -f /usr/bin/python3 /usr/bin/python\n\n# moves all additional zeppelin files to their respective locations\n# remaining files are notebooks, we move those once everything else is gone\nRUN mkdir -p $ZEPPELIN_HOME/otherpoms \\\n    && mkdir -p $ZEPPELIN_HOME/conf \\\n    && mkdir -p $ZEPPELIN_HOME/dockerfiles\nCOPY . $ZEPPELIN_HOME/dockerfiles/.\n\n# switch lines if building for cuda or cpu\nRUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-native_spark_2.xml $ZEPPELIN_HOME/otherpoms/pom.xml\n#RUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-native_spark_1.xml $ZEPPELIN_HOME/otherpoms/pom.xml\n#RUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-cuda-8.0_spark_2.xml $ZEPPELIN_HOME/otherpoms/pom.xml\n#RUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-cuda-8.0_spark_1.xml $ZEPPELIN_HOME/otherpoms/pom.xml\n\nRUN ls $ZEPPELIN_HOME/bin/ \\\n    && cp -a $ZEPPELIN_HOME/dockerfiles/docker/conf/. $ZEPPELIN_HOME/conf/ \\\n    && cp -a $ZEPPELIN_HOME/dockerfiles/. $ZEPPELIN_HOME/notebook_json \\\n    && rm -rf $ZEPPELIN_HOME/notebook_json/docker/ \\\n    && find $ZEPPELIN_HOME/notebook_json/ -type f -not -name '*.json' -delete \\\n    && dos2unix $ZEPPELIN_HOME/conf/zeppelin-env.sh \\\n    && dos2unix $ZEPPELIN_HOME/bin/zeppelin.sh \\\n    && cd $ZEPPELIN_HOME \\\n    && mv $ZEPPELIN_HOME/dockerfiles/docker/json-folder-ids.py $ZEPPELIN_HOME \\\n    && python json-folder-ids.py \\\n    && cd $ZEPPELIN_HOME/otherpoms \\\n    && /tmp/apache-maven-3.5.0/bin/mvn package \\\n    && rm -rf $ZEPPELIN_HOME/dockerfiles/\n\nEXPOSE 8080 4040\n\nWORKDIR $ZEPPELIN_HOME\nCMD [\"/bin/bash\",\"bin/zeppelin.sh\"]"
}