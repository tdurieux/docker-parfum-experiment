{
  "startTime": 1674245128542,
  "endTime": 1674245128830,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 42,
        "lineEnd": 44,
        "columnStart": 4,
        "columnEnd": 220
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 57,
        "lineEnd": 58,
        "columnStart": 4,
        "columnEnd": 103
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 70,
        "lineEnd": 71,
        "columnStart": 4,
        "columnEnd": 125
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 42,
        "lineEnd": 44,
        "columnStart": 4,
        "columnEnd": 220
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 57,
        "lineEnd": 58,
        "columnStart": 4,
        "columnEnd": 103
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 4,
        "columnEnd": 30
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 23,
        "lineEnd": 24,
        "columnStart": 4,
        "columnEnd": 30
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM debian:stretch\nMAINTAINER Jim Harner <ejharner@gmail.com>\n\nARG hadoopversion=2.9.1\nARG sparkversion=2.4.3\nARG hiveversion=2.1.1\n\nRUN apt-get update \\\n && apt-get install --no-install-recommends -y locales \\\n && dpkg-reconfigure -f noninteractive locales \\\n && locale-gen C.UTF-8 \\\n && /usr/sbin/update-locale LANG=C.UTF-8 \\\n && echo \"en_US.UTF-8 UTF-8\" >> /etc/locale.gen \\\n && locale-gen \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n\n# Users with other locales should set this in their derivative image\nENV LANG en_US.UTF-8\nENV LANGUAGE en_US:en\nENV LC_ALL en_US.UTF-8\n\nRUN apt-get update \\\n && apt-get install --no-install-recommends -y curl unzip \\\n    python3 python3-setuptools \\\n && ln -s /usr/bin/python3 /usr/bin/python \\\n && easy_install3 pip py4j \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n\n# http://blog.stuart.axelbrooke.com/python-3-on-spark-return-of-the-pythonhashseed\nENV PYTHONHASHSEED 0\nENV PYTHONIOENCODING UTF-8\nENV PIP_DISABLE_PIP_VERSION_CHECK 1\n\n# JAVA\nARG JAVA_MAJOR_VERSION=8\nARG JAVA_UPDATE_VERSION=131\nARG JAVA_BUILD_NUMBER=11\nENV JAVA_HOME /usr/jdk1.${JAVA_MAJOR_VERSION}.0_${JAVA_UPDATE_VERSION}\n\nENV PATH $PATH:$JAVA_HOME/bin\nRUN curl -f -sL --retry 3 --insecure \\\n  --header \"Cookie: oraclelicense=accept-securebackup-cookie;\" \\\n  \"https://download.oracle.com/otn-pub/java/jdk/${JAVA_MAJOR_VERSION}u${JAVA_UPDATE_VERSION}-b${JAVA_BUILD_NUMBER}/d54c1d3a095b4ff2b6607d096fa80163/server-jre-${JAVA_MAJOR_VERSION}u${JAVA_UPDATE_VERSION}-linux-x64.tar.gz\" \\\n  | gunzip \\\n  | tar x -C /usr/ \\\n  && ln -s $JAVA_HOME /usr/java \\\n  && rm -rf $JAVA_HOME/man\n\n####################\n# HADOOP\n####################\nENV HADOOP_VERSION 2.9.1\nENV HADOOP_HOME /usr/hadoop-$HADOOP_VERSION\nENV HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\nENV PATH $PATH:$HADOOP_HOME/bin\nRUN curl -f -sL --retry 3 \\\n\"https://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz\" \\\n  | gunzip \\\n  | tar -x -C /usr/ \\\n && rm -rf $HADOOP_HOME/share/doc \\\n && chown -R root:root $HADOOP_HOME\n\n# SPARK\nENV SPARK_VERSION 2.4.3\nENV SPARK_PACKAGE spark-${SPARK_VERSION}-bin-without-hadoop\nENV SPARK_HOME /usr/spark-${SPARK_VERSION}\nENV SPARK_DIST_CLASSPATH=\"$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*\"\nENV PATH $PATH:${SPARK_HOME}/bin\nRUN curl -f -sL --retry 3 \\\n  \"https://www.apache.org/dyn/mirrors/mirrors.cgi?action=download&filename=spark/spark-${SPARK_VERSION}/${SPARK_PACKAGE}.tgz\" \\\n  | gunzip \\\n  | tar x -C /usr/ \\\n && mv /usr/$SPARK_PACKAGE $SPARK_HOME \\\n && chown -R root:root $SPARK_HOME\n\n## Use Debian unstable via pinning -- new style via APT::Default-Release\nRUN echo \"deb http://http.debian.net/debian sid main\" > /etc/apt/sources.list.d/debian-unstable.list \\\n    && echo 'APT::Default-Release \"testing\";' > /etc/apt/apt.conf.d/default\nENV R_BASE_VERSION 3.5.3\n\n## Now install R and littler, and create a link for littler in /usr/local/bin\n## Also set a default CRAN repo, and make sure littler knows about it too\nRUN apt-get update \\\n  && apt-get install -t unstable -y --no-install-recommends \\\n    littler \\\n                r-cran-littler \\\n    r-base=${R_BASE_VERSION}* \\\n    r-base-dev=${R_BASE_VERSION}* \\\n    r-recommended=${R_BASE_VERSION}* \\\n        && echo 'options(repos = c(CRAN = \"https://cran.rstudio.com/\"), download.file.method = \"libcurl\")' >> /etc/R/Rprofile.site \\\n        && echo 'source(\"/etc/R/Rprofile.site\")' >> /etc/littler.r \\\n  && ln -s /usr/share/doc/littler/examples/install.r /usr/local/bin/install.r \\\n  && ln -s /usr/share/doc/littler/examples/install2.r /usr/local/bin/install2.r \\\n  && ln -s /usr/share/doc/littler/examples/installGithub.r /usr/local/bin/installGithub.r \\\n  && ln -s /usr/share/doc/littler/examples/testInstalled.r /usr/local/bin/testInstalled.r \\\n  && install.r docopt \\\n  && rm -rf /tmp/downloaded_packages/ /tmp/*.rds \\\n  && rm -rf /var/lib/apt/lists/*\n#RUN rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n#RUN yum -y install R\n\nWORKDIR $SPARK_HOME\nCMD [\"bin/spark-class\", \"org.apache.spark.deploy.master.Master\"]\n\n#RUN mkdir /scripts\n#ADD start.sh /scripts/start.sh\n\n#CMD [\"/scripts/start.sh\"]"
}