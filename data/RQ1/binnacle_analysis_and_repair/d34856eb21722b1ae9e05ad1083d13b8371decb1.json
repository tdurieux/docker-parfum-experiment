{
  "startTime": 1674251380515,
  "endTime": 1674251380606,
  "originalSmells": [
    {
      "rule": "aptGetInstallUseY",
      "position": {
        "lineStart": 51,
        "lineEnd": 52,
        "columnStart": 4,
        "columnEnd": 78
      }
    },
    {
      "rule": "aptGetInstallUseY",
      "position": {
        "lineStart": 54,
        "lineEnd": 55,
        "columnStart": 4,
        "columnEnd": 53
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# Copyright 2018 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nARG TF_SERVING_VERSION=latest\nARG TF_SERVING_BUILD_IMAGE=tensorflow/serving:${TF_SERVING_VERSION}-devel-gpu\n\nFROM ${TF_SERVING_BUILD_IMAGE} as build_image\nFROM nvidia/cuda:10.0-base-ubuntu16.04\n\nARG TF_SERVING_VERSION_GIT_BRANCH=master\nARG TF_SERVING_VERSION_GIT_COMMIT=head\n\nLABEL maintainer=\"gvasudevan@google.com\"\nLABEL tensorflow_serving_github_branchtag=${TF_SERVING_VERSION_GIT_BRANCH}\nLABEL tensorflow_serving_github_commit=${TF_SERVING_VERSION_GIT_COMMIT}\n\nENV CUDNN_VERSION=7.4.1.5\nENV TF_TENSORRT_VERSION=5.0.2\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n        ca-certificates \\\n        cuda-command-line-tools-10-0 \\\n        cuda-command-line-tools-10-0 \\\n        cuda-cublas-10-0 \\\n        cuda-cufft-10-0 \\\n        cuda-curand-10-0 \\\n        cuda-cusolver-10-0 \\\n        cuda-cusparse-10-0 \\\n        libcudnn7=${CUDNN_VERSION}-1+cuda10.0 \\\n        libgomp1 \\\n        && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\n# The 'apt-get install' of nvinfer-runtime-trt-repo-* library adds a new list\n# which contains libnvinfer library, so it needs another 'apt-get update' to\n# retrieve that list before it can actually install the library.\n#\n# We don't install libnvinfer-dev since we don't need to build against TensorRT.\nRUN apt-get update && \\\n    apt-get install -y --no-install-recommends \\\n        nvinfer-runtime-trt-repo-ubuntu1604-${TF_TENSORRT_VERSION}-ga-cuda10.0 && \\\n    apt-get update && \\\n    apt-get install -y --no-install-recommends \\\n        libnvinfer5=${TF_TENSORRT_VERSION}-1+cuda10.0 && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/* && \\\n    rm /usr/lib/x86_64-linux-gnu/libnvcaffe_parser* && \\\n    rm /usr/lib/x86_64-linux-gnu/libnvparsers*\n\n# Install TF Serving GPU pkg\nCOPY --from=build_image /usr/local/bin/tensorflow_model_server /usr/bin/tensorflow_model_server\n\n# Expose ports\n# gRPC\nEXPOSE 8500\n\n# REST\nEXPOSE 8501\n\n# Set where models should be stored in the container\nENV MODEL_BASE_PATH=/models\nRUN mkdir -p ${MODEL_BASE_PATH}\n\n# The only required piece is the model name in order to differentiate endpoints\nENV MODEL_NAME=model\n\n# Create a script that runs the model server so we can use environment variables\n# while also passing in arguments from the docker command line\nRUN echo '#!/bin/bash \\n\\n\\\ntensorflow_model_server --port=8500 --rest_api_port=8501 \\\n--model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \\\n\"$@\"' > /usr/bin/tf_serving_entrypoint.sh \\\n&& chmod +x /usr/bin/tf_serving_entrypoint.sh\n\nENTRYPOINT [\"/usr/bin/tf_serving_entrypoint.sh\"]\n"
}