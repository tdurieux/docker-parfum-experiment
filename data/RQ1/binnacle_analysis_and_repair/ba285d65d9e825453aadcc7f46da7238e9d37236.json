{
  "startTime": 1674236786605,
  "endTime": 1674236786676,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 23,
        "lineEnd": 23,
        "columnStart": 4,
        "columnEnd": 26
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 5,
        "lineEnd": 5,
        "columnStart": 22,
        "columnEnd": 63
      }
    },
    {
      "rule": "aptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 5,
        "lineEnd": 5,
        "columnStart": 22,
        "columnEnd": 63
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# ********************************** STAGE 2 **********************************************\n# later we will use the remote ones\nFROM mlbench/mlbench_worker:mlbench-worker-base\n\n# -------------------- Debug --------------------\nRUN apt-get update && apt-get install --no-install-recommends -y vim net-tools iproute2 && rm -rf /var/lib/apt/lists/*;\n\nADD ./mlbench/worker/ /app/\n\n# The reference implementation and user defined implementations are placed here.\nRUN mkdir /codes\nADD ./mlbench/refimpls/pytorch /codes\n\nENV PYTHONPATH /codes\n\nADD ./compose/worker/requirements.txt /requirements.txt\nRUN pip install --no-cache-dir -r /requirements.txt\n\n# To find `libnvidia-ml.so` on google cloud.\n# ENV LD_LIBRARY_PATH=\"/usr/local/nvidia/lib64:$LD_LIBRARY_PATH\"\n\n# Remove empty ld\nRUN rm $(ldconfig 2>&1 | grep 'is empty, not checked' | awk '{print $3}') 2> /dev/null || true\nRUN pip install --no-cache-dir tensorpack"
}