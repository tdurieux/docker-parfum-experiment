{
  "startTime": 1674245619318,
  "endTime": 1674245619455,
  "originalSmells": [
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 28,
        "lineEnd": 28,
        "columnStart": 4,
        "columnEnd": 40
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM openjdk:8\n\nMAINTAINER Prashanth Babu <Prashanth.Babu@gmail.com>\n\n# Scala related variables.\nARG SCALA_VERSION=2.12.2\nARG SCALA_BINARY_ARCHIVE_NAME=scala-${SCALA_VERSION}\nARG SCALA_BINARY_DOWNLOAD_URL=http://downloads.lightbend.com/scala/${SCALA_VERSION}/${SCALA_BINARY_ARCHIVE_NAME}.tgz\n\n# SBT related variables.\nARG SBT_VERSION=0.13.15\nARG SBT_BINARY_ARCHIVE_NAME=sbt-$SBT_VERSION\nARG SBT_BINARY_DOWNLOAD_URL=https://dl.bintray.com/sbt/native-packages/sbt/${SBT_VERSION}/${SBT_BINARY_ARCHIVE_NAME}.tgz\n\n# Spark related variables.\nARG SPARK_VERSION=2.2.0\nARG SPARK_BINARY_ARCHIVE_NAME=spark-${SPARK_VERSION}-bin-hadoop2.7\nARG SPARK_BINARY_DOWNLOAD_URL=http://d3kbcqa49mib13.cloudfront.net/${SPARK_BINARY_ARCHIVE_NAME}.tgz\n\n# Configure env variables for Scala, SBT and Spark.\n# Also configure PATH env variable to include binary folders of Java, Scala, SBT and Spark.\nENV SCALA_HOME  /usr/local/scala\nENV SBT_HOME    /usr/local/sbt\nENV SPARK_HOME  /usr/local/spark\nENV PATH        $JAVA_HOME/bin:$SCALA_HOME/bin:$SBT_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin:$PATH\n\n# Download, uncompress and move all the required packages and libraries to their corresponding directories in /usr/local/ folder.\nRUN apt-get -yqq update && \\\n    apt-get install --no-install-recommends -yqq vim screen tmux && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/* && \\\n    rm -rf /tmp/* && \\\n    wget -qO - ${SCALA_BINARY_DOWNLOAD_URL} | tar -xz -C /usr/local/ && \\\n    wget -qO - ${SBT_BINARY_DOWNLOAD_URL} | tar -xz -C /usr/local/ && \\\n    wget -qO - ${SPARK_BINARY_DOWNLOAD_URL} | tar -xz -C /usr/local/ && \\\n    cd /usr/local/ && \\\n    ln -s ${SCALA_BINARY_ARCHIVE_NAME} scala && \\\n    ln -s ${SPARK_BINARY_ARCHIVE_NAME} spark && \\\n    cp spark/conf/log4j.properties.template spark/conf/log4j.properties && \\\n    sed -i -e s/WARN/ERROR/g spark/conf/log4j.properties && \\\n    sed -i -e s/INFO/ERROR/g spark/conf/log4j.properties\n\n# We will be running our Spark jobs as `root` user.\nUSER root\n\n# Working directory is set to the home folder of `root` user.\nWORKDIR /root\n\n# Expose ports for monitoring.\n# SparkContext web UI on 4040 -- only available for the duration of the application.\n# Spark masterâ€™s web UI on 8080.\n# Spark worker web UI on 8081.\nEXPOSE 4040 8080 8081\n\nCMD [\"/bin/bash\"]"
}