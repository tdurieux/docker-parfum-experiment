{
  "startTime": 1674248290816,
  "endTime": 1674248290918,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 11,
        "lineEnd": 11,
        "columnStart": 4,
        "columnEnd": 49
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 12,
        "lineEnd": 12,
        "columnStart": 4,
        "columnEnd": 72
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 16,
        "lineEnd": 16,
        "columnStart": 4,
        "columnEnd": 47
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# Dockerfile suitable for submitting Dataflow jobs and for runnin nmslib index creator.\n#\n# We don't use the Docker image used for running the training jobs\n# because we have different versioning requirements.\nFROM python:2.7-jessie\n\n# These dependencies are primarily needed with Dataflow\n# so we need to install them for Python2.\n# We do this before copying the code because we don't want to have\n# reinstall the requirements just because the code changed.\nCOPY src/requirements.dataflow.txt /tmp/requirements.dataflow.txt\nRUN pip install --no-cache-dir -r /tmp/requirements.dataflow.txt\nRUN pip install --no-cache-dir https://github.com/kubeflow/batch-predict/tarball/master\n\n# Install nmslib requirements so that we can create the index\nCOPY src/requirements.nmslib.txt /tmp/requirements.nmslib.txt\nRUN pip install --no-cache-dir -r /tmp/requirements.nmslib.txt\n\n# install the spacy model\nRUN python -m spacy download en\n\nADD src/code_search /app/code_search\nADD src             /src\n\n# See: https://github.com/kubeflow/examples/issues/390\n# Dataflow will try to build a source package locally and we need\n# the path to match what we have in setup.py.\nRUN ln -sf /src/requirements.dataflow.txt /src/requirements.txt\n\nWORKDIR /src\n\nENV PYTHONIOENCODING=utf-8 T2T_USR_DIR=/app/code_search/t2t\n"
}