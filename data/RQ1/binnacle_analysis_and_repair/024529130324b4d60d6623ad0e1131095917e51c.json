{
  "startTime": 1674250885642,
  "endTime": 1674250885813,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 25,
        "lineEnd": 25,
        "columnStart": 4,
        "columnEnd": 66
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 25,
        "lineEnd": 25,
        "columnStart": 4,
        "columnEnd": 66
      }
    },
    {
      "rule": "apkAddUseNoCache",
      "position": {
        "lineStart": 10,
        "lineEnd": 10,
        "columnStart": 18,
        "columnEnd": 78
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM anapsix/alpine-java:jdk8\nMAINTAINER Dan Pilch (danielpilch@hotmail.co.uk)\n\nENV SPARK_VERSION=spark-1.6.1-bin-hadoop2.6 \\\n        SPARK_CASSANDRA_CONNECTOR_VERSION=1.5.0\n\n# Create temporary spark runtime dir\nRUN mkdir -p /tmp/spark-events\n\n# Install deps\nRUN apk update && apk add --no-cache bash curl tar git openssh htop vim python python-dev\n\n# Generate keys\nRUN mkdir -p /root/.ssh && \\\n        chmod 700 /root/.ssh/ && \\\n        echo -e \"Port 22\\n\" >> /etc/ssh/sshd_config && \\\n        cp -a /etc/ssh /etc/ssh.cache && \\\n        /usr/bin/ssh-keygen -A && \\\n        echo -e \"\\n\\n\\n\" | ssh-keygen -t rsa && \\\n        cat /root/.ssh/id_rsa.pub > /root/.ssh/authorized_keys && \\\n        ssh-keyscan -H localhost,127.0.0.1 >> /root/.ssh/known_hosts && \\\n        ssh-keyscan -H 127.0.0.1 >> /root/.ssh/known_hosts && \\\n        ssh-keyscan -H localhost >> /root/.ssh/known_hosts\n\n# Download, extract and symlink spark\nRUN curl -f https://d3kbcqa49mib13.cloudfront.net/${SPARK_VERSION}.tgz | tar xz && \\\n        ln -sf /${SPARK_VERSION}/ spark\n\n# Git clone and compile Spark Cassandra Connector and add it to spark\nRUN git clone https://github.com/datastax/spark-cassandra-connector.git && \\\n        cd spark-cassandra-connector && \\\n        git checkout v${SPARK_CASSANDRA_CONNECTOR_VERSION} && \\\n        sbt/sbt assembly && \\\n        mv /spark-cassandra-connector/spark-cassandra-connector/target/scala-2.10/spark-cassandra-connector-assembly-${SPARK_CASSANDRA_CONNECTOR_VERSION}.jar /spark/ && \\\n        rm -rf /spark-cassandra-connector && \\\n        /spark/bin/spark-shell --jars /spark/spark-cassandra-connector-assembly-${SPARK_CASSANDRA_CONNECTOR_VERSION}.jar && \\\n        echo \"JAVA_HOME=/opt/jdk\" >> /spark/conf/spark-env.sh && chmod +x /spark/conf/spark-env.sh\n\n# Create spark-defaults.conf\nRUN echo -e \"spark.eventLog.enabled true\\nspark.driver.extraClassPath /spark/spark-cassandra-connector-assembly-1.5.0.jar\\nspark.executor.extraClassPath /spark/spark-cassandra-connector-assembly-1.5.0.jar\" >> spark/conf/spark-defaults.conf\n\n# Create start.sh\nRUN echo -e \"#\\!/bin/bash\\n\\n/usr/sbin/sshd -D -f /etc/ssh/sshd_config &\\n\\n/spark/sbin/start-all.sh\\n\\n/spark/sbin/start-slave.sh spark://`hostname -i`:7077\\n\\ntail -f /spark/logs/*\" >> start.sh && \\\n        chmod +x start.sh\n\n# Start Spark\nCMD [\"/bin/bash\", \"start.sh\"]\n\n\n"
}