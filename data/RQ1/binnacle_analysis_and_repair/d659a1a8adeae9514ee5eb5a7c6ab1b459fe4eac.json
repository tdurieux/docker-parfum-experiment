{
  "startTime": 1674239148099,
  "endTime": 1674239148287,
  "originalSmells": [
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 23,
        "lineEnd": 23,
        "columnStart": 4,
        "columnEnd": 28
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM nvidia/cuda:8.0-cudnn5-devel\n# cuda8.0 has to be used because this is the first ubuntu16.04 container\n# which is required due to OpenBLAS being incompatible with ubuntu14.04\n# the reason we used a gpu base container because we are going to test MKLDNN\n# operator implementation against GPU implementation\n\nCOPY install/ubuntu_install_core.sh /install/\nRUN /install/ubuntu_install_core.sh\nCOPY install/ubuntu_install_python.sh /install/\nRUN /install/ubuntu_install_python.sh\nCOPY install/ubuntu_install_scala.sh /install/\nRUN /install/ubuntu_install_scala.sh\nCOPY install/ubuntu_install_r.sh /install/\nRUN /install/ubuntu_install_r.sh\nCOPY install/ubuntu_install_perl.sh /install/\nRUN /install/ubuntu_install_perl.sh\n\n# Allows to run tasks on a CPU without nvidia-docker and GPU\nCOPY install/ubuntu_install_nvidia.sh /install/\nRUN /install/ubuntu_install_nvidia.sh\n\n# Add MKLML libraries\nRUN wget --no-check-certificate -O /tmp/mklml.tgz https://github.com/01org/mkl-dnn/releases/download/v0.12/mklml_lnx_2018.0.1.20171227.tgz\nRUN tar -zxvf /tmp/mklml.tgz && cp -rf mklml_*/* /usr/local/ && rm -rf mklml_* && rm /tmp/mklml.tgz\n\nENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/lib\n"
}