{
  "startTime": 1674234327630,
  "endTime": 1674234327733,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 8,
        "columnEnd": 103
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 8,
        "columnEnd": 33
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 7,
        "lineEnd": 7,
        "columnStart": 8,
        "columnEnd": 31
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 12,
        "lineEnd": 12,
        "columnStart": 8,
        "columnEnd": 65
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM java7jre_image\n\nENV HOME /root\nENV DEBIAN_FRONTEND noninteractive\n\nRUN ( SPARK_VERSION=1.3.0 && \\\n        apt-get update && \\\n        apt-get install --no-install-recommends -y wget && \\\n        wget -O /tmp/spark.tgz https://d3kbcqa49mib13.cloudfront.net/spark-${SPARK_VERSION}-bin-cdh4.tgz && \\\n        cd /opt && tar xvf /tmp/spark.tgz && \\\n        rm -fv /tmp/spark.tgz && \\\n        ln -sn spark-${SPARK_VERSION}-bin-cdh4 /opt/spark && \\\n        apt-get install --no-install-recommends -y python python-pip curl jq libgfortran3 && \\\n        pip install --no-cache-dir python-consul && \\\n        apt-get clean -y && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*)\n\nADD app /app\nADD spark-jobs /spark-jobs\nADD startup-scripts /startup-scripts\n\n# Define default command.\nCMD [\"/apps/bin/keep_alive\"]\n\n"
}