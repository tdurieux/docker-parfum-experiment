{
  "startTime": 1674244595817,
  "endTime": 1674244596255,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 44,
        "lineEnd": 44,
        "columnStart": 4,
        "columnEnd": 108
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 71,
        "lineEnd": 71,
        "columnStart": 4,
        "columnEnd": 97
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 74,
        "lineEnd": 74,
        "columnStart": 4,
        "columnEnd": 120
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 71,
        "lineEnd": 71,
        "columnStart": 4,
        "columnEnd": 97
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 74,
        "lineEnd": 74,
        "columnStart": 4,
        "columnEnd": 120
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 25,
        "lineEnd": 28,
        "columnStart": 4,
        "columnEnd": 4
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 36,
        "lineEnd": 36,
        "columnStart": 4,
        "columnEnd": 43
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 41,
        "lineEnd": 41,
        "columnStart": 4,
        "columnEnd": 75
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nFROM centos:centos7\n\nENV SPARK_PROFILE 2.4\nENV SPARK_VERSION 2.4.0\nENV HADOOP_PROFILE 2.7\nENV HADOOP_VERSION 2.7.0\n\n# Update the image with the latest packages\nRUN yum update -y; yum clean all\n\n# Get utils\nRUN yum install -y \\\nwget \\\ntar \\\ncurl \\\n&& \\\nyum clean all && rm -rf /var/cache/yum\n\n# Remove old jdk\nRUN yum remove java; yum remove jdk\n\n# install jdk7\nRUN yum install -y java-1.7.0-openjdk-devel && rm -rf /var/cache/yum\nENV JAVA_HOME /usr/lib/jvm/java\nENV PATH $PATH:$JAVA_HOME/bin\n\n# install hadoop\nRUN yum install -y curl which tar sudo openssh-server openssh-clients rsync && rm -rf /var/cache/yum\n\n# hadoop\nRUN curl -f -s https://archive.apache.org/dist/hadoop/core/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz | tar -xz -C /usr/local/\nRUN cd /usr/local && ln -s ./hadoop-$HADOOP_VERSION hadoop\n\nENV HADOOP_PREFIX /usr/local/hadoop\nENV HADOOP_COMMON_HOME /usr/local/hadoop\nENV HADOOP_HDFS_HOME /usr/local/hadoop\nENV HADOOP_MAPRED_HOME /usr/local/hadoop\nENV HADOOP_YARN_HOME /usr/local/hadoop\nENV HADOOP_CONF_DIR /usr/local/hadoop/etc/hadoop\n\nRUN sed -i '/^export JAVA_HOME/ s:.*:export JAVA_HOME=/usr/lib/jvm/jre-1.7.0-openjdk\\nexport HADOOP_PREFIX=/usr/local/hadoop\\nexport HADOOP_HOME=/usr/local/hadoop\\n:' $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh\nRUN sed -i '/^export HADOOP_CONF_DIR/ s:.*:export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop/:' $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh\n\nRUN mkdir $HADOOP_PREFIX/input\nRUN cp $HADOOP_PREFIX/etc/hadoop/*.xml $HADOOP_PREFIX/input\n\n# hadoop configurations\nADD hdfs_conf/core-site.xml $HADOOP_PREFIX/etc/hadoop/core-site.xml\nADD hdfs_conf/hdfs-site.xml $HADOOP_PREFIX/etc/hadoop/hdfs-site.xml\nADD hdfs_conf/mapred-site.xml $HADOOP_PREFIX/etc/hadoop/mapred-site.xml\nADD hdfs_conf/yarn-site.xml $HADOOP_PREFIX/etc/hadoop/yarn-site.xml\n\nRUN mkdir /data/\nRUN chmod 777 /data/\nRUN $HADOOP_PREFIX/bin/hdfs namenode -format\n\nRUN rm  /usr/local/hadoop/lib/native/*\nRUN curl -f -Ls https://dl.bintray.com/sequenceiq/sequenceiq-bin/hadoop-native-64-$HADOOP_VERSION.tar | tar -x -C /usr/local/hadoop/lib/native/\n\n# install spark\nRUN curl -f -s https://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_PROFILE.tgz | tar -xz -C /usr/local/\nRUN cd /usr/local && ln -s spark-$SPARK_VERSION-bin-hadoop$HADOOP_PROFILE spark\nENV SPARK_HOME /usr/local/spark\n\nENV YARN_CONF_DIR $HADOOP_PREFIX/etc/hadoop\nENV PATH $PATH:$SPARK_HOME/bin:$HADOOP_PREFIX/bin\n\n# passwordless ssh\nRUN ssh-keygen -q -N \"\" -t dsa -f /etc/ssh/ssh_host_dsa_key\nRUN ssh-keygen -q -N \"\" -t rsa -f /etc/ssh/ssh_host_rsa_key\nRUN ssh-keygen -q -N \"\" -t rsa -f /root/.ssh/id_rsa\nRUN cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys\n\nADD ssh_config /root/.ssh/config\nRUN chmod 600 /root/.ssh/config\nRUN chown root:root /root/.ssh/config\nRUN chmod +x /usr/local/hadoop/etc/hadoop/*-env.sh\n\n# update boot script\nCOPY entrypoint.sh /etc/entrypoint.sh\nRUN chown root.root /etc/entrypoint.sh\nRUN chmod 700 /etc/entrypoint.sh\n\n# Hdfs ports\nEXPOSE 50010 50020 50070 50075 50090\n# Mapred ports\nEXPOSE 9000 9001\n#Yarn ports\nEXPOSE 8030 8031 8032 8033 8040 8042 8088\n#spark\nEXPOSE 8080 7077 8888 8081\n\nENTRYPOINT [\"/etc/entrypoint.sh\"]\n"
}