{
  "startTime": 1674240722028,
  "endTime": 1674240723827,
  "originalSmells": [
    {
      "rule": "sha256sumEchoOneSpaces",
      "position": {
        "lineStart": 154,
        "lineEnd": 199,
        "columnStart": 4,
        "columnEnd": 139
      }
    },
    {
      "rule": "sha256sumEchoOneSpaces",
      "position": {
        "lineStart": 154,
        "lineEnd": 196,
        "columnStart": 4,
        "columnEnd": 121
      }
    },
    {
      "rule": "sha256sumEchoOneSpaces",
      "position": {
        "lineStart": 154,
        "lineEnd": 194,
        "columnStart": 4,
        "columnEnd": 108
      }
    },
    {
      "rule": "sha256sumEchoOneSpaces",
      "position": {
        "lineStart": 154,
        "lineEnd": 192,
        "columnStart": 4,
        "columnEnd": 97
      }
    },
    {
      "rule": "sha256sumEchoOneSpaces",
      "position": {
        "lineStart": 154,
        "lineEnd": 190,
        "columnStart": 4,
        "columnEnd": 99
      }
    },
    {
      "rule": "sha256sumEchoOneSpaces",
      "position": {
        "lineStart": 154,
        "lineEnd": 188,
        "columnStart": 4,
        "columnEnd": 92
      }
    },
    {
      "rule": "sha256sumEchoOneSpaces",
      "position": {
        "lineStart": 154,
        "lineEnd": 184,
        "columnStart": 4,
        "columnEnd": 84
      }
    },
    {
      "rule": "sha256sumEchoOneSpaces",
      "position": {
        "lineStart": 154,
        "lineEnd": 180,
        "columnStart": 4,
        "columnEnd": 81
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 166,
        "lineEnd": 166,
        "columnStart": 7,
        "columnEnd": 91
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 178,
        "lineEnd": 178,
        "columnStart": 7,
        "columnEnd": 98
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 181,
        "lineEnd": 181,
        "columnStart": 7,
        "columnEnd": 93
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 185,
        "lineEnd": 185,
        "columnStart": 7,
        "columnEnd": 86
      }
    },
    {
      "rule": "gpgUseBatchFlag",
      "position": {
        "lineStart": 159,
        "lineEnd": 159,
        "columnStart": 7,
        "columnEnd": 80
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# debian:9.6 - linux; amd64\n# https://github.com/docker-library/repo-info/blob/master/repos/debian/tag-details.md#debian96---linux-amd64\nFROM debian@sha256:38236c068c393272ad02db100e09cac36a5465149e2924a035ee60d6c60c38fe\n\nARG BUILD_DATE\nARG CODENAME=\"stretch\"\nARG CONDA_DIR=\"/opt/conda\"\nARG CONDA_ENV_YML=\"data-toolkit-root-conda-base-env.yml\"\nARG CONDA_INSTALLER=\"Miniconda3-4.5.4-Linux-x86_64.sh\"\nARG CONDA_MD5=\"a946ea1d0c4a642ddf0c3a26a18bb16d\"\nARG CONDA_URL=\"https://repo.continuum.io/miniconda\"\nARG DCOS_CLI_URL=\"https://downloads.dcos.io/binaries/cli/linux/x86-64\"\nARG DCOS_CLI_VERSION=\"1.12\"\nARG DCOS_COMMONS_URL=\"https://downloads.mesosphere.com/dcos-commons\"\nARG DCOS_COMMONS_VERSION=\"0.54.3\"\nARG DEBCONF_NONINTERACTIVE_SEEN=\"true\"\nARG DEBIAN_FRONTEND=\"noninteractive\"\nARG DEBIAN_REPO=\"http://cdn-fastly.deb.debian.org\"\nARG DISTRO=\"debian\"\nARG GPG_KEYSERVER=\"hkps://zimmermann.mayfirst.org\"\nARG HADOOP_HDFS_HOME=\"/opt/hadoop\"\nARG HADOOP_MAJOR_VERSION=\"2.9\"\nARG HADOOP_SHA256=\"3d2023c46b1156c1b102461ad08cbc17c8cc53004eae95dab40a1f659839f28a\"\nARG HADOOP_URL=\"http://www-us.apache.org/dist/hadoop/common\"\nARG HADOOP_VERSION=\"2.9.2\"\nARG HOME=\"/root\"\nARG JAVA_HOME=\"/opt/jdk\"\nARG JAVA_URL=\"https://downloads.mesosphere.com/java\"\nARG JAVA_VERSION=\"8u192\"\nARG LANG=\"en_US.UTF-8\"\nARG LANGUAGE=\"en_US.UTF-8\"\nARG LC_ALL=\"en_US.UTF-8\"\nARG LIBMESOS_BUNDLE_SHA256=\"217c43e4b642c1abdfe0fe309bbaede878cbc9a925562678b1c44273d140d40a\"\nARG LIBMESOS_BUNDLE_URL=\"https://downloads.mesosphere.com/libmesos-bundle\"\nARG LIBMESOS_BUNDLE_VERSION=\"1.12.0\"\nARG MESOSPHERE_PREFIX=\"/opt/mesosphere\"\nARG MESOS_JAR_SHA1=\"aab2e3118b01536af38c3b4243224149c625f008\"\nARG MESOS_MAVEN_URL=\"https://repo1.maven.org/maven2/org/apache/mesos/mesos\"\nARG MESOS_PROTOBUF_JAR_SHA1=\"bfb740747d97e5781c7f6c04bbfa93f5c2df0d4f\"\nARG MESOS_VERSION=\"1.7.0\"\nARG MESOSPHERE_DATA_TOOLKIT_VERSION=\"1.0.0-1.0.0\"\nARG OPENRESTY_REPO=\"https://openresty.org/package\"\nARG SPARK_DIST_URL=\"https://downloads.mesosphere.com/mesosphere-jupyter-service/assets/spark\"\nARG SPARK_DIST_SHA256=\"52e29e83a65688e29da975d1ace7815c6a5b55e76c41d43a28e5e80de2b29843\"\nARG SPARK_HOME=\"/opt/spark\"\nARG SPARK_MAJOR_VERSION=\"2.2\"\nARG SPARK_VERSION=\"2.2.1\"\nARG TENSORFLOW_ECO_URL=\"https://downloads.mesosphere.com/mesosphere-jupyter-service/assets/tensorflow\"\nARG TENSORFLOW_HADOOP_JAR_SHA256=\"668b326be1a7cfa4e621e8abaa9a5dbf1a813bad289ba0ad03e983ae8e841290\"\nARG TENSORFLOW_SPARK_JAR_SHA256=\"bcc3bcb48cfe72997f7c51e6fd8d379c64d26fd200cbd08617631fd8182a2fbf\"\nARG TENSORFLOW_JAR_SHA256=\"6a4e5c80bad7c826233a9b1750a7d4b5a28c6e5c8fccebefc1e6a0d5feeae4a3\"\nARG TENSORFLOW_JNI_SHA256=\"8f74ced6dece0e0889eb09b0731ef728feffe0aadadaf8d6401a3ff15aafcc6e\"\nARG TENSORFLOW_SERVING_APT_URL=\"http://storage.googleapis.com/tensorflow-serving-apt\"\nARG TENSORFLOW_SERVING_VERSION=\"1.11.0\"\nARG TENSORFLOW_URL=\"https://storage.googleapis.com/tensorflow\"\nARG TENSORFLOW_VARIANT=\"cpu\"\nARG TENSORFLOW_VERSION=\"1.11.0\"\nARG TINI_GPG_KEY=\"595E85A6B1B4779EA4DAAEC70B588DFF0527A9B7\"\nARG TINI_URL=\"https://github.com/krallin/tini/releases/download\"\nARG TINI_VERSION=\"v0.18.0\"\nARG VCS_REF\nARG XGBOOST_JAVA_JAR_SHA256=\"4a6599ee3f1bd10d984e8b03747d5bc3cb637aeb791474178de2c285857bf69e\"\nARG XGBOOST_SPARK_JAR_SHA256=\"cd31fb96b26fee197e126215949bc4f5c9a3cafd7ff157ab0037a63777c2935e\"\nARG XGBOOST_URL=\"https://downloads.mesosphere.com/mesosphere-jupyter-service/assets/xgboost\"\nARG XGBOOST_VERSION=\"0.71\"\n\nLABEL maintainer=\"Mesosphere Support <support+data-toolkit@mesosphere.com>\" \\\n      org.label-schema.build-date=\"${BUILD_DATE}\" \\\n      org.label-schema.name=\"Mesosphere Data Analytics Toolkit\" \\\n      org.label-schema.description=\"Data Analytics Docker Image bundled with popular tools, libraries and frameworks.\" \\\n      org.label-schema.url=\"https://mesosphere.com\" \\\n      org.label-schema.vcs-ref=\"${VCS_REF}\" \\\n      org.label-schema.vcs-url=\"https://github.com/mesosphere/mesosphere-jupyter-service\" \\\n      org.label-schema.version=\"${MESOSPHERE_DATA_TOOLKIT_VERSION}\" \\\n      org.label-schema.schema-version=\"1.0\"\n\nENV BOOTSTRAP=\"${MESOSPHERE_PREFIX}/bin/bootstrap\" \\\n    CODENAME=${CODENAME:-\"stretch\"} \\\n    CONDA_DIR=${CONDA_DIR:-\"/opt/conda\"} \\\n    DEBCONF_NONINTERACTIVE_SEEN=${DEBCONF_NONINTERACTIVE_SEEN:-\"true\"} \\\n    DEBIAN_FRONTEND=${DEBIAN_FRONTEND:-\"noninteractive\"} \\\n    DISTRO=${DISTRO:-\"debian\"} \\\n    GPG_KEYSERVER=${GPG_KEYSERVER:-\"hkps://zimmermann.mayfirst.org\"} \\\n    HADOOP_HDFS_HOME=${HADOOP_HDFS_HOME:-\"/opt/hadoop\"} \\\n    HOME=${HOME:-\"/root\"} \\\n    JAVA_HOME=${JAVA_HOME:-\"/opt/jdk\"} \\\n    LANG=${LANG:-\"en_US.UTF-8\"} \\\n    LANGUAGE=${LANGUAGE:-\"en_US.UTF-8\"} \\\n    LC_ALL=${LC_ALL:-\"en_US.UTF-8\"} \\\n    MESOSPHERE_PREFIX=${MESOSPHERE_PREFIX:-\"/opt/mesosphere\"} \\\n    MESOS_AUTHENTICATEE=\"com_mesosphere_dcos_ClassicRPCAuthenticatee\" \\\n    MESOS_HTTP_AUTHENTICATEE=\"com_mesosphere_dcos_http_Authenticatee\" \\\n    MESOS_MODULES=\"{\\\"libraries\\\": [{\\\"file\\\": \\\"libdcos_security.so\\\", \\\"modules\\\": [{\\\"name\\\": \\\"com_mesosphere_dcos_ClassicRPCAuthenticatee\\\"}]}]}\" \\\n    MESOS_NATIVE_LIBRARY=\"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libmesos.so\" \\\n    MESOS_NATIVE_JAVA_LIBRARY=\"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libmesos.so\" \\\n    NODE_OPTIONS=\"--max-old-space-size=8192\" \\\n    PATH=\"${JAVA_HOME}/bin:${SPARK_HOME}/bin:${HADOOP_HDFS_HOME}/bin:${CONDA_DIR}/bin:${MESOSPHERE_PREFIX}/bin:${PATH}\" \\\n    SHELL=\"/bin/bash\" \\\n    SPARK_HOME=${SPARK_HOME:-\"/opt/spark\"}\n\nRUN echo \"deb ${DEBIAN_REPO}/${DISTRO} ${CODENAME} main\" >> /etc/apt/sources.list \\\n    && echo \"deb ${DEBIAN_REPO}/${DISTRO}-security ${CODENAME}/updates main\" >> /etc/apt/sources.list \\\n    && apt-get update -yq --fix-missing \\\n    && apt-get install -yq --no-install-recommends apt-transport-https apt-utils ca-certificates curl dirmngr gnupg2 locales \\\n    && echo \"en_US.UTF-8 UTF-8\" >> /etc/locale.gen \\\n    && locale-gen \\\n    && curl --retry 3 -fsSL https://openresty.org/package/pubkey.gpg -o /tmp/openresty-pubkey.gpg \\\n    && apt-key add /tmp/openresty-pubkey.gpg \\\n    && rm /tmp/openresty-pubkey.gpg \\\n    && echo \"deb ${OPENRESTY_REPO}/${DISTRO} ${CODENAME} openresty\" > /etc/apt/sources.list.d/openresty.list \\\n    && apt-get update -yq --fix-missing \\\n    && apt-get -yq dist-upgrade \\\n    && apt-get install -yq --no-install-recommends \\\n       bash-completion \\\n       bzip2 \\\n       cmake \\\n       dnsutils \\\n       ffmpeg \\\n       g++ \\\n       gcc \\\n       git \\\n       info \\\n       jq \\\n       kstart \\\n       less \\\n       libaio1 \\\n       luarocks \\\n       make \\\n       man \\\n       netcat \\\n       openresty \\\n       openresty-opm \\\n       openssh-client \\\n       procps \\\n       psmisc \\\n       rsync \\\n       runit \\\n       sudo \\\n       sssd \\\n       unzip \\\n       vim \\\n       wget \\\n       zlib1g-dev \\\n    && apt-get clean \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && opm get zmartzone/lua-resty-openidc \\\n    && rm -rf ~/.opm/cache \\\n    && chmod ugo+rw /usr/local/openresty/nginx/logs \\\n    && chmod ugo+rw /usr/local/openresty/nginx \\\n    && addgroup --gid 99 nobody \\\n    && usermod -u 99 -g 99 nobody \\\n    && echo \"nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin\" >> /etc/passwd \\\n    && usermod -a -G users nobody\n\nRUN cd /tmp \\\n    && apt-key adv --no-tty --keyserver \"${GPG_KEYSERVER}\" --recv-keys \"${TINI_GPG_KEY}\" \\\n    && curl --retry 3 -fsSL \"${TINI_URL}/${TINI_VERSION}/tini\" -o /usr/bin/tini \\\n    && curl --retry 3 -fsSL -O \"${TINI_URL}/${TINI_VERSION}/tini.asc\" \\\n    && export GNUPGHOME=\"$(mktemp -d)\" \\\n    && gpg --batch --no-tty --keyserver \"${GPG_KEYSERVER}\" --recv-keys \"${TINI_GPG_KEY}\" \\\n    && gpg --no-tty --batch --verify tini.asc /usr/bin/tini \\\n    && rm -rf \"${GNUPGHOME}\" tini.asc \\\n    && chmod +x /usr/bin/tini \\\n    && mkdir -p \"${CONDA_DIR}\" \"${HADOOP_HDFS_HOME}\" \"${JAVA_HOME}\" \"${MESOSPHERE_PREFIX}/bin\" \"${SPARK_HOME}\" \\\n    && curl --retry 3 -fsSL -O \"${LIBMESOS_BUNDLE_URL}/libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz\" \\\n    && echo \"${LIBMESOS_BUNDLE_SHA256}\" \"libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz\" | sha256sum -c - \\\n    && tar xf \"libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz\" -C \"${MESOSPHERE_PREFIX}\" \\\n    && cd \"${MESOSPHERE_PREFIX}/libmesos-bundle/lib\" \\\n    && curl --retry 3 -fsSL -O \"${MESOS_MAVEN_URL}/${MESOS_VERSION}/mesos-${MESOS_VERSION}.jar\" \\\n    && echo \"${MESOS_JAR_SHA1}                                                                                                                                                                                                                                                                mesos-${MESOS_VERSION}.jar\" | sha1sum -c - \\\n    && curl --retry 3 -fsSL -O \"${MESOS_MAVEN_URL}/${MESOS_VERSION}/mesos-${MESOS_VERSION}-shaded-protobuf.jar\" \\\n    && echo \"${MESOS_PROTOBUF_JAR_SHA1}                                                                                                                                                                                                                                                                mesos-${MESOS_VERSION}-shaded-protobuf.jar\" | sha1sum -c - \\\n    && cd /tmp \\\n    && curl --retry 3 -fsSL -O \"${DCOS_COMMONS_URL}/artifacts/${DCOS_COMMONS_VERSION}/bootstrap.zip\" \\\n    && unzip \"bootstrap.zip\" -d \"${MESOSPHERE_PREFIX}/bin/\" \\\n    && curl --retry 3 -fsSL \"${DCOS_CLI_URL}/dcos-${DCOS_CLI_VERSION}/dcos\" -o ${MESOSPHERE_PREFIX}/bin/dcos \\\n    && chmod +x ${MESOSPHERE_PREFIX}/bin/dcos \\\n    && curl --retry 3 -fsSL -O \"${JAVA_URL}/server-jre-${JAVA_VERSION}-linux-x64.tar.gz\" \\\n    && tar xf \"server-jre-${JAVA_VERSION}-linux-x64.tar.gz\" -C \"${JAVA_HOME}\" --strip-components=1 \\\n    && curl --retry 3 -fsSL -O \"${HADOOP_URL}/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz\" \\\n    && echo \"${HADOOP_SHA256}\" \"hadoop-${HADOOP_VERSION}.tar.gz\" | sha256sum -c - \\\n    && tar xf \"hadoop-${HADOOP_VERSION}.tar.gz\" -C \"${HADOOP_HDFS_HOME}\" --strip-components=1 \\\n    && rm -rf \"${HADOOP_HDFS_HOME}/share/doc\" \\\n    && curl --retry 3 -fsSL -O \"${SPARK_DIST_URL}/spark-${SPARK_VERSION}-bin.tgz\" \\\n    && echo \"${SPARK_DIST_SHA256}\" \"spark-${SPARK_VERSION}-bin.tgz\" | sha256sum -c - \\\n    && tar xf \"spark-${SPARK_VERSION}-bin.tgz\" -C \"${SPARK_HOME}\" --strip-components=1 \\\n    && cd \"${SPARK_HOME}/jars\" \\\n    && curl --retry 3 -fsSL -O \"${XGBOOST_URL}/${XGBOOST_VERSION}/xgboost4j-${XGBOOST_VERSION}.jar\" \\\n    && echo \"${XGBOOST_JAVA_JAR_SHA256}\" \"xgboost4j-${XGBOOST_VERSION}.jar\" | sha256sum -c - \\\n    && curl --retry 3 -fsSL -O \"${XGBOOST_URL}/${XGBOOST_VERSION}/xgboost4j-spark-${XGBOOST_VERSION}.jar\" \\\n    && echo \"${XGBOOST_SPARK_JAR_SHA256}\" \"xgboost4j-spark-${XGBOOST_VERSION}.jar\" | sha256sum -c - \\\n    && curl --retry 3 -fsSL -O \"${TENSORFLOW_URL}/libtensorflow/libtensorflow-${TENSORFLOW_VERSION}.jar\" \\\n    && echo \"${TENSORFLOW_JAR_SHA256}\" \"libtensorflow-${TENSORFLOW_VERSION}.jar\" | sha256sum -c - \\\n    && curl --retry 3 -fsSL -O \"${TENSORFLOW_ECO_URL}/${TENSORFLOW_VERSION}/hadoop-${HADOOP_MAJOR_VERSION}/tensorflow-hadoop-${TENSORFLOW_VERSION}.jar\" \\\n    && echo \"${TENSORFLOW_HADOOP_JAR_SHA256}\" \"tensorflow-hadoop-${TENSORFLOW_VERSION}.jar\" | sha256sum -c - \\\n    && curl --retry 3 -fsSL -O \"${TENSORFLOW_ECO_URL}/${TENSORFLOW_VERSION}/spark-${SPARK_MAJOR_VERSION}/spark-tensorflow-connector_2.11-${TENSORFLOW_VERSION}.jar\" \\\n    && echo \"${TENSORFLOW_SPARK_JAR_SHA256}\" \"spark-tensorflow-connector_2.11-${TENSORFLOW_VERSION}.jar\" | sha256sum -c - \\\n    && cd /tmp \\\n    && curl --retry 3 -fsSL -O \"${TENSORFLOW_URL}/libtensorflow/libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz\" \\\n    && echo \"${TENSORFLOW_JNI_SHA256}\" \"libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz\" | sha256sum -c - \\\n    && tar xf \"libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz\" \"./libtensorflow_jni.so\" \\\n    && mv \"libtensorflow_jni.so\" \"/usr/lib\" \\\n    && rm -rf /tmp/* && rm \"libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz\"\n\nRUN echo \"deb [arch=amd64] ${TENSORFLOW_SERVING_APT_URL} stable tensorflow-model-server tensorflow-model-server-universal\" > /etc/apt/sources.list.d/tensorflow-serving.list \\\n    && curl --retry 3 -fsSL ${TENSORFLOW_SERVING_APT_URL}/tensorflow-serving.release.pub.gpg | apt-key add - \\\n    && apt-get update \\\n    && TENSORFLOW_SERVING_DEB=\"$(mktemp)\" \\\n    && curl --retry 3 -fsSL \"${TENSORFLOW_SERVING_APT_URL}/pool/tensorflow-model-server-${TENSORFLOW_SERVING_VERSION}/t/tensorflow-model-server/tensorflow-model-server_${TENSORFLOW_SERVING_VERSION}_all.deb\" -o \"${TENSORFLOW_SERVING_DEB}\"\\\n    && dpkg -i \"${TENSORFLOW_SERVING_DEB}\" \\\n    && rm -f \"${TENSORFLOW_SERVING_DEB}\" \\\n    && apt-get clean \\\n    && rm -rf /var/lib/apt/lists/*\n\nCOPY \"${CONDA_ENV_YML}\" \"${CONDA_DIR}/\"\n\nRUN cd /tmp \\\n    && curl --retry 3 -fsSL -O \"${CONDA_URL}/${CONDA_INSTALLER}\" \\\n    && echo \"${CONDA_MD5}  ${CONDA_INSTALLER}\" | md5sum -c - \\\n    && bash \"./${CONDA_INSTALLER}\" -u -b -p \"${CONDA_DIR}\" \\\n    && ${CONDA_DIR}/bin/conda update --json --all -yq \\\n    && ${CONDA_DIR}/bin/conda config --env --add pinned_packages defaults::conda \\\n    && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::blas \\\n    && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::boost \\\n    && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::gsl \\\n    && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::numpy \\\n    && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::openblas \\\n    && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::scikit-learn \\\n    && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::scipy \\\n    && ${CONDA_DIR}/bin/conda config --system --prepend channels conda-forge \\\n    && ${CONDA_DIR}/bin/conda config --system --set auto_update_conda false \\\n    && ${CONDA_DIR}/bin/conda config --system --set show_channel_urls true \\\n    && ${CONDA_DIR}/bin/conda update --json -yq pip \\\n    && ${CONDA_DIR}/bin/conda env update --json -q -f \"${CONDA_DIR}/${CONDA_ENV_YML}\" \\\n    && ${CONDA_DIR}/bin/conda remove --force --json -yq openjdk pyqt qt qtconsole \\\n    && rm -rf \"${HOME}/.cache/pip\" \"${HOME}/.cache/yarn\" \"${HOME}/.npm/_cacache\" \"${HOME}/.node-gyp\" \\\n    && ${CONDA_DIR}/bin/conda clean --json -tipsy \\\n    && for dir in .conda/envs bin work; \\\n       do mkdir -p \"${HOME}/${dir}\"; done \\\n    && rm -rf /tmp/*\n\nCOPY profile \"/etc/skel/.profile\"\nCOPY profile \"${HOME}/.profile\"\nCOPY bash_profile \"/etc/skel/.bash_profile\"\nCOPY bash_profile \"${HOME}/.bash_profile\"\nCOPY bashrc \"/etc/skel/.bashrc\"\nCOPY bashrc \"${HOME}/.bashrc\"\n\nRUN cp \"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libcurl.so.4\" /usr/lib/x86_64-linux-gnu/libcurl.so.4.4.0\n\nENV SPARK_DIST_CLASSPATH=\"${HADOOP_HDFS_HOME}/etc/hadoop:${HADOOP_HDFS_HOME}/share/hadoop/common/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/common/*:${HADOOP_HDFS_HOME}/share/hadoop/hdfs:${HADOOP_HDFS_HOME}/share/hadoop/hdfs/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/hdfs/*:${HADOOP_HDFS_HOME}/share/hadoop/yarn:${HADOOP_HDFS_HOME}/share/hadoop/yarn/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/yarn/*:${HADOOP_HDFS_HOME}/share/hadoop/mapreduce/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/mapreduce/*:${HADOOP_HDFS_HOME}/share/hadoop/tools/lib/*\" \\\n    HADOOP_CLASSPATH=\"${HADOOP_CLASSPATH}:${HADOOP_HDFS_HOME}/share/hadoop/tools/lib/*\" \\\n    PYTHONPATH=\"${SPARK_HOME}/python:${SPARK_HOME}/python/lib/py4j-0.10.4-src.zip:${PYTHONPATH}\" \\\n    LD_LIBRARY_PATH=\"/usr/lib/x86_64-linux-gnu:${MESOSPHERE_PREFIX}/libmesos-bundle/lib:${JAVA_HOME}/jre/lib/amd64/server:${HADOOP_HDFS_HOME}/lib/native\"\n\nWORKDIR \"/mnt/mesos/sandbox\"\n\nCOPY krb5.conf.mustache /etc/\nCOPY hadoop-env.sh \"${HADOOP_HDFS_HOME}/etc/hadoop/\"\nCOPY hadooprc \"${HOME}/.hadooprc\"\nCOPY conf/ \"${SPARK_HOME}/conf/\"\nCOPY nginx /usr/local/openresty/nginx/\n\nRUN chmod -R ugo+rw \"${SPARK_HOME}/conf\" \\\n    && cp \"${CONDA_DIR}/share/examples/krb5/krb5.conf\" /etc \\\n    && chmod ugo+rw /etc/krb5.conf \\\n    && chmod ugo+rw /usr/local/openresty/nginx/conf/nginx.conf \\\n    && chmod ugo+rw /usr/local/openresty/nginx/conf/sites/proxy.conf\n\nCOPY start-spark-history.sh /usr/local/bin/\nCOPY start-tensorboard.sh /usr/local/bin/\nCOPY start-worker.sh \"/usr/local/bin/\"\nCOPY start-dask-worker.sh \"/usr/local/bin/\"\nCOPY start-ray-worker.sh \"/usr/local/bin/\"\nCOPY ray-worker-health-check.sh \"/usr/local/bin/\"\n"
}