{"repository":"https://github.com/actionml/docker-spark","dockerfilePath":"Dockerfile","startTime":1672326168329,"clone":{"stdout":"","stderr":"Cloning into '/tmp/dinghy-analysis/actionml/docker-spark'...\n","error":null,"commit":"bbd56636f6e8a10d979e56a7d1dcd8376654f0d4"},"originalBuild":{"startTimestamp":1672326169117,"endTimestamp":1672326221796,"error":{"code":2,"killed":false,"signal":null,"cmd":"docker build --no-cache --force-rm -t docker-spark:latest -f /tmp/dinghy-analysis/actionml/docker-spark/Dockerfile ."},"stdout":"Sending build context to Docker daemon  102.9kB\r\r\nStep 1/17 : FROM openjdk:8-alpine3.8\n8-alpine3.8: Pulling from library/openjdk\n169185f82c45: Pulling fs layer\n3bdc61458cff: Pulling fs layer\ndaa7fce0c25f: Pulling fs layer\n3bdc61458cff: Download complete\n169185f82c45: Download complete\n169185f82c45: Pull complete\n3bdc61458cff: Pull complete\ndaa7fce0c25f: Verifying Checksum\ndaa7fce0c25f: Download complete\ndaa7fce0c25f: Pull complete\nDigest: sha256:39d0f4075ccc0076c496b4f7a4e87e6eed63fe1086a10d04c521362c7f69a56c\nStatus: Downloaded newer image for openjdk:8-alpine3.8\n ---> 21a93502ddd8\nStep 2/17 : ARG version\n ---> Running in 53d7a809ead0\nRemoving intermediate container 53d7a809ead0\n ---> 6df1da69b606\nStep 3/17 : ARG release\n ---> Running in 16ca0a3ecc2c\nRemoving intermediate container 16ca0a3ecc2c\n ---> 0aa6c0a6a937\nStep 4/17 : ARG GIT_HASH\n ---> Running in 1a952ce8cdf2\nRemoving intermediate container 1a952ce8cdf2\n ---> 2d6a81fbbf83\nStep 5/17 : ARG DATE_BUILD\n ---> Running in 8ded8bbad603\nRemoving intermediate container 8ded8bbad603\n ---> 14d7e4fc1a7d\nStep 6/17 : ARG BRANCH\n ---> Running in e9f80cbf422c\nRemoving intermediate container e9f80cbf422c\n ---> 775a567b55e8\nStep 7/17 : LABEL com.actionml.spark.vendor=ActionML       com.actionml.spark.version=$version       com.actionml.spark.release=$release\n ---> Running in 9583704277f1\nRemoving intermediate container 9583704277f1\n ---> b4b7d5f447fa\nStep 8/17 : ENV BRANCH=${BRANCH}\n ---> Running in cf01e5c3b7b3\nRemoving intermediate container cf01e5c3b7b3\n ---> e4a4c9380aaa\nStep 9/17 : ENV GIT_HASH=${GIT_HASH}\n ---> Running in 6e92a9751b27\nRemoving intermediate container 6e92a9751b27\n ---> 716c8ccb4093\nStep 10/17 : ENV DATE_BUILD=${DATE_BUILD}\n ---> Running in b95af6b0874e\nRemoving intermediate container b95af6b0874e\n ---> 2776b6dc2c56\nStep 11/17 : ENV SPARK_HOME=/spark     SPARK_PGP_KEYS=\"6EC5F1052DF08FF4 DCE4BFD807461E96\"\n ---> Running in 6b8e83a960b6\nRemoving intermediate container 6b8e83a960b6\n ---> bb41cc9fae5d\nStep 12/17 : RUN adduser -Ds /bin/bash -h ${SPARK_HOME} spark &&     apk add --no-cache bash tini libc6-compat linux-pam krb5 krb5-libs &&     apk add --virtual .deps --no-cache curl tar gnupg &&     cd /tmp && export GNUPGHOME=/tmp &&     file=spark-${version}-bin-hadoop2.7.tgz &&     curl --remote-name-all -w \"%{url_effective} fetched\\n\" -sSL         https://archive.apache.org/dist/spark/spark-${version}/{${file},${file}.asc} &&     gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys ${SPARK_PGP_KEYS} &&     gpg --batch --verify ${file}.asc ${file} &&     mkdir -p ${SPARK_HOME}/work ${SPARK_HOME}/conf && chown spark:spark ${SPARK_HOME}/work &&     tar -xzf ${file} --no-same-owner --strip-components 1 &&     mv bin data examples jars sbin ${SPARK_HOME} &&     apk --no-cache del .deps && ls -A | xargs rm -rf\n ---> Running in af2934eb8f78\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.8/main/x86_64/APKINDEX.tar.gz\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.8/community/x86_64/APKINDEX.tar.gz\n(1/12) Upgrading musl (1.1.19-r10 -> 1.1.19-r11)\n(2/12) Installing ncurses-terminfo-base (6.1_p20180818-r1)\n(3/12) Installing ncurses-terminfo (6.1_p20180818-r1)\n(4/12) Installing ncurses-libs (6.1_p20180818-r1)\n(5/12) Installing readline (7.0.003-r0)\n(6/12) Installing bash (4.4.19-r1)\nExecuting bash-4.4.19-r1.post-install\n(7/12) Installing e2fsprogs-libs (1.44.2-r2)\n(8/12) Installing krb5 (1.15.4-r0)\n(9/12) Upgrading musl-utils (1.1.19-r10 -> 1.1.19-r11)\n(10/12) Installing libc6-compat (1.1.19-r11)\n(11/12) Installing linux-pam (1.3.0-r0)\n(12/12) Installing tini (0.18.0-r0)\nExecuting busybox-1.28.4-r3.trigger\nOK: 111 MiB in 63 packages\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.8/main/x86_64/APKINDEX.tar.gz\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.8/community/x86_64/APKINDEX.tar.gz\n(1/21) Installing nghttp2-libs (1.39.2-r0)\n(2/21) Installing libssh2 (1.9.0-r1)\n(3/21) Installing libcurl (7.61.1-r3)\n(4/21) Installing curl (7.61.1-r3)\n(5/21) Installing tar (1.32-r0)\n(6/21) Installing libgpg-error (1.30-r0)\n(7/21) Installing libassuan (2.5.1-r0)\n(8/21) Installing libcap (2.25-r1)\n(9/21) Installing pinentry (1.1.0-r0)\nExecuting pinentry-1.1.0-r0.post-install\n(10/21) Installing libgcrypt (1.8.3-r2)\n(11/21) Installing gmp (6.1.2-r1)\n(12/21) Installing nettle (3.4.1-r0)\n(13/21) Installing libunistring (0.9.7-r0)\n(14/21) Installing gnutls (3.6.14-r0)\n(15/21) Installing libksba (1.3.5-r0)\n(16/21) Installing db (5.3.28-r0)\n(17/21) Installing libsasl (2.1.26-r15)\n(18/21) Installing libldap (2.4.48-r1)\n(19/21) Installing npth (1.5-r1)\n(20/21) Installing gnupg (2.2.19-r0)\n(21/21) Installing .deps (0)\nExecuting busybox-1.28.4-r3.trigger\nOK: 125 MiB in 84 packages\nhttps://archive.apache.org/dist/spark/spark-/spark--bin-hadoop2.7.tgz fetched\nhttps://archive.apache.org/dist/spark/spark-/spark--bin-hadoop2.7.tgz.asc fetched\n\u001b[91mgpg: keybox '/tmp/pubring.kbx' created\n\u001b[0m\u001b[91mgpg: keyserver receive failed: Server indicated a failure\n\u001b[0mRemoving intermediate container af2934eb8f78\n","stderr":"The command '/bin/sh -c adduser -Ds /bin/bash -h ${SPARK_HOME} spark &&     apk add --no-cache bash tini libc6-compat linux-pam krb5 krb5-libs &&     apk add --virtual .deps --no-cache curl tar gnupg &&     cd /tmp && export GNUPGHOME=/tmp &&     file=spark-${version}-bin-hadoop2.7.tgz &&     curl --remote-name-all -w \"%{url_effective} fetched\\n\" -sSL         https://archive.apache.org/dist/spark/spark-${version}/{${file},${file}.asc} &&     gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys ${SPARK_PGP_KEYS} &&     gpg --batch --verify ${file}.asc ${file} &&     mkdir -p ${SPARK_HOME}/work ${SPARK_HOME}/conf && chown spark:spark ${SPARK_HOME}/work &&     tar -xzf ${file} --no-same-owner --strip-components 1 &&     mv bin data examples jars sbin ${SPARK_HOME} &&     apk --no-cache del .deps && ls -A | xargs rm -rf' returned a non-zero code: 2\n"},"endTime":1672326221872}