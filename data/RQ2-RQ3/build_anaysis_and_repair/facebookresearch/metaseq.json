{"repository":"https://github.com/facebookresearch/metaseq","dockerfilePath":"Dockerfile","startTime":1672183030442,"clone":{"stdout":"","stderr":"Cloning into '/tmp/dinghy-analysis/facebookresearch/metaseq'...\n","error":null,"commit":"b929eef2aee9356c744c8c8e26933915257c98ab"},"originalBuild":{"startTimestamp":1672183033589,"endTimestamp":1672185306209,"error":{"code":1,"killed":false,"signal":null,"cmd":"docker build --no-cache --force-rm -t metaseq:latest -f /tmp/dinghy-analysis/facebookresearch/metaseq/Dockerfile ."},"stdout":"Sending build context to Docker daemon  49.97MB\r\r\nStep 1/25 : FROM nvidia/cuda:11.3.1-devel-ubuntu20.04\n11.3.1-devel-ubuntu20.04: Pulling from nvidia/cuda\n846c0b181fff: Already exists\n6fc9dd88827c: Pulling fs layer\n0b311d7060d0: Pulling fs layer\n326d76058f67: Pulling fs layer\ned7e4c52c661: Pulling fs layer\n4f05f5570c7a: Pulling fs layer\nab264e292103: Pulling fs layer\n527d1d5ab821: Pulling fs layer\nfc46d4e99009: Pulling fs layer\n9ccf692754fa: Pulling fs layer\nc6611ece70c4: Pulling fs layer\nab264e292103: Waiting\n527d1d5ab821: Waiting\nfc46d4e99009: Waiting\n9ccf692754fa: Waiting\nc6611ece70c4: Waiting\ned7e4c52c661: Waiting\n4f05f5570c7a: Waiting\n326d76058f67: Verifying Checksum\n326d76058f67: Download complete\n6fc9dd88827c: Verifying Checksum\n6fc9dd88827c: Download complete\n0b311d7060d0: Verifying Checksum\n0b311d7060d0: Download complete\ned7e4c52c661: Download complete\nab264e292103: Download complete\n6fc9dd88827c: Pull complete\n527d1d5ab821: Download complete\nfc46d4e99009: Download complete\n0b311d7060d0: Pull complete\n326d76058f67: Pull complete\ned7e4c52c661: Pull complete\nc6611ece70c4: Verifying Checksum\nc6611ece70c4: Download complete\n9ccf692754fa: Verifying Checksum\n9ccf692754fa: Download complete\n4f05f5570c7a: Download complete\n4f05f5570c7a: Pull complete\nab264e292103: Pull complete\n527d1d5ab821: Pull complete\nfc46d4e99009: Pull complete\n9ccf692754fa: Pull complete\nc6611ece70c4: Pull complete\nDigest: sha256:9cecf8e18cd1ace85303dd1f39bb19b94ed3069c074feb90f3f627273ec9cf48\nStatus: Downloaded newer image for nvidia/cuda:11.3.1-devel-ubuntu20.04\n ---> f569e319a648\nStep 2/25 : ARG DEBIAN_FRONTEND=noninteractive\n ---> Running in 316fd6d0e4eb\nRemoving intermediate container 316fd6d0e4eb\n ---> 3658cbaa21c5\nStep 3/25 : RUN mkdir -p /build\n ---> Running in 0e063d016b10\nRemoving intermediate container 0e063d016b10\n ---> d259be651b60\nStep 4/25 : WORKDIR /build\n ---> Running in 0da1a04e8278\nRemoving intermediate container 0da1a04e8278\n ---> a2f62247ee94\nStep 5/25 : RUN apt-key del 7fa2af80 &&     apt-get -qq update &&     apt-get -qq install -y --no-install-recommends curl &&     curl -O https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-keyring_1.0-1_all.deb &&     dpkg -i cuda-keyring_1.0-1_all.deb\n ---> Running in 591c41c86ec6\nOK\n\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n\u001b[0mSelecting previously unselected package libkrb5support0:amd64.\r\n(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 12723 files and directories currently installed.)\r\nPreparing to unpack .../00-libkrb5support0_1.17-6ubuntu4.1_amd64.deb ...\r\nUnpacking libkrb5support0:amd64 (1.17-6ubuntu4.1) ...\r\nSelecting previously unselected package libk5crypto3:amd64.\r\nPreparing to unpack .../01-libk5crypto3_1.17-6ubuntu4.1_amd64.deb ...\r\nUnpacking libk5crypto3:amd64 (1.17-6ubuntu4.1) ...\r\nSelecting previously unselected package libkeyutils1:amd64.\r\nPreparing to unpack .../02-libkeyutils1_1.6-6ubuntu1.1_amd64.deb ...\r\nUnpacking libkeyutils1:amd64 (1.6-6ubuntu1.1) ...\r\nSelecting previously unselected package libkrb5-3:amd64.\r\nPreparing to unpack .../03-libkrb5-3_1.17-6ubuntu4.1_amd64.deb ...\r\nUnpacking libkrb5-3:amd64 (1.17-6ubuntu4.1) ...\r\nSelecting previously unselected package libgssapi-krb5-2:amd64.\r\nPreparing to unpack .../04-libgssapi-krb5-2_1.17-6ubuntu4.1_amd64.deb ...\r\nUnpacking libgssapi-krb5-2:amd64 (1.17-6ubuntu4.1) ...\r\nSelecting previously unselected package libpsl5:amd64.\r\nPreparing to unpack .../05-libpsl5_0.21.0-1ubuntu1_amd64.deb ...\r\nUnpacking libpsl5:amd64 (0.21.0-1ubuntu1) ...\r\nSelecting previously unselected package libbrotli1:amd64.\r\nPreparing to unpack .../06-libbrotli1_1.0.7-6ubuntu0.1_amd64.deb ...\r\nUnpacking libbrotli1:amd64 (1.0.7-6ubuntu0.1) ...\r\nSelecting previously unselected package libnghttp2-14:amd64.\r\nPreparing to unpack .../07-libnghttp2-14_1.40.0-1build1_amd64.deb ...\r\nUnpacking libnghttp2-14:amd64 (1.40.0-1build1) ...\r\nSelecting previously unselected package librtmp1:amd64.\r\nPreparing to unpack .../08-librtmp1_2.4+20151223.gitfa8646d.1-2build1_amd64.deb ...\r\nUnpacking librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2build1) ...\r\nSelecting previously unselected package libssh-4:amd64.\r\nPreparing to unpack .../09-libssh-4_0.9.3-2ubuntu2.2_amd64.deb ...\r\nUnpacking libssh-4:amd64 (0.9.3-2ubuntu2.2) ...\r\nSelecting previously unselected package libcurl4:amd64.\r\nPreparing to unpack .../10-libcurl4_7.68.0-1ubuntu2.14_amd64.deb ...\r\nUnpacking libcurl4:amd64 (7.68.0-1ubuntu2.14) ...\r\nSelecting previously unselected package curl.\r\nPreparing to unpack .../11-curl_7.68.0-1ubuntu2.14_amd64.deb ...\r\nUnpacking curl (7.68.0-1ubuntu2.14) ...\r\nSetting up libkeyutils1:amd64 (1.6-6ubuntu1.1) ...\r\nSetting up libpsl5:amd64 (0.21.0-1ubuntu1) ...\r\nSetting up libbrotli1:amd64 (1.0.7-6ubuntu0.1) ...\r\nSetting up libnghttp2-14:amd64 (1.40.0-1build1) ...\r\nSetting up libkrb5support0:amd64 (1.17-6ubuntu4.1) ...\r\nSetting up librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2build1) ...\r\nSetting up libk5crypto3:amd64 (1.17-6ubuntu4.1) ...\r\nSetting up libkrb5-3:amd64 (1.17-6ubuntu4.1) ...\r\nSetting up libgssapi-krb5-2:amd64 (1.17-6ubuntu4.1) ...\r\nSetting up libssh-4:amd64 (0.9.3-2ubuntu2.2) ...\r\nSetting up libcurl4:amd64 (7.68.0-1ubuntu2.14) ...\r\nSetting up curl (7.68.0-1ubuntu2.14) ...\r\nProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\r\n\u001b[91m  % Total    % Received % Xferd  Average Speed   Time \u001b[0m\u001b[91m   Time    \u001b[0m\u001b[91m Time \u001b[0m\u001b[91m Cu\u001b[0m\u001b[91mrre\u001b[0m\u001b[91mnt\n   \u001b[0m\u001b[91m   \u001b[0m\u001b[91m  \u001b[0m\u001b[91m  \u001b[0m\u001b[91m            \u001b[0m\u001b[91m        \u001b[0m\u001b[91m  \u001b[0m\u001b[91m Dl\u001b[0m\u001b[91moad \u001b[0m\u001b[91m Up\u001b[0m\u001b[91mload   Tot\u001b[0m\u001b[91mal   Spen\u001b[0m\u001b[91mt    L\u001b[0m\u001b[91meft  Spee\u001b[0m\u001b[91md\n\r  0     \u001b[0m\u001b[91m0  \u001b[0m\u001b[91m  0    \u001b[0m\u001b[91m 0    0   \u001b[0m\u001b[91m  0\u001b[0m\u001b[91m   \u001b[0m\u001b[91m   \u001b[0m\u001b[91m0    \u001b[0m\u001b[91m  0 --:--:\u001b[0m\u001b[91m-- --:--:-- \u001b[0m\u001b[91m--:--\u001b[0m\u001b[91m:--   \u001b[0m\u001b[91m  0\u001b[0m\u001b[91m\r  0  4332    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--   \u001b[0m\u001b[91m  0\u001b[0m\u001b[91m\r100  4332  100\u001b[0m\u001b[91m  4332    0\u001b[0m\u001b[91m    \u001b[0m\u001b[91m 0   7\u001b[0m\u001b[91m113   \u001b[0m\u001b[91m   \u001b[0m\u001b[91m0 --\u001b[0m\u001b[91m:--\u001b[0m\u001b[91m:-\u001b[0m\u001b[91m- -\u001b[0m\u001b[91m-:-\u001b[0m\u001b[91m-:--\u001b[0m\u001b[91m --:--:--  7\u001b[0m\u001b[91m101\u001b[0m\u001b[91m\n\u001b[0mSelecting previously unselected package cuda-keyring.\n(Reading database ... 12807 files and directories currently installed.)\nPreparing to unpack cuda-keyring_1.0-1_all.deb ...\nUnpacking cuda-keyring (1.0-1) ...\nSetting up cuda-keyring (1.0-1) ...\nRemoving intermediate container 591c41c86ec6\n ---> eb1ecdc27850\nStep 6/25 : RUN apt-get -qq update     && apt-get -qq install -y --no-install-recommends     git     python3-pip python3-dev\n ---> Running in bfd7e22bc691\n\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n\u001b[0mSelecting previously unselected package libpython3.8-minimal:amd64.\r\n(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 12812 files and directories currently installed.)\r\nPreparing to unpack .../libpython3.8-minimal_3.8.10-0ubuntu1~20.04.6_amd64.deb ...\r\nUnpacking libpython3.8-minimal:amd64 (3.8.10-0ubuntu1~20.04.6) ...\r\nSelecting previously unselected package libexpat1:amd64.\r\nPreparing to unpack .../libexpat1_2.2.9-1ubuntu0.6_amd64.deb ...\r\nUnpacking libexpat1:amd64 (2.2.9-1ubuntu0.6) ...\r\nSelecting previously unselected package python3.8-minimal.\r\nPreparing to unpack .../python3.8-minimal_3.8.10-0ubuntu1~20.04.6_amd64.deb ...\r\nUnpacking python3.8-minimal (3.8.10-0ubuntu1~20.04.6) ...\r\nSetting up libpython3.8-minimal:amd64 (3.8.10-0ubuntu1~20.04.6) ...\r\nSetting up libexpat1:amd64 (2.2.9-1ubuntu0.6) ...\r\nSetting up python3.8-minimal (3.8.10-0ubuntu1~20.04.6) ...\r\nSelecting previously unselected package python3-minimal.\r\n(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 13103 files and directories currently installed.)\r\nPreparing to unpack .../0-python3-minimal_3.8.2-0ubuntu2_amd64.deb ...\r\nUnpacking python3-minimal (3.8.2-0ubuntu2) ...\r\nSelecting previously unselected package mime-support.\r\nPreparing to unpack .../1-mime-support_3.64ubuntu1_all.deb ...\r\nUnpacking mime-support (3.64ubuntu1) ...\r\nSelecting previously unselected package libmpdec2:amd64.\r\nPreparing to unpack .../2-libmpdec2_2.4.2-3_amd64.deb ...\r\nUnpacking libmpdec2:amd64 (2.4.2-3) ...\r\nSelecting previously unselected package libpython3.8-stdlib:amd64.\r\nPreparing to unpack .../3-libpython3.8-stdlib_3.8.10-0ubuntu1~20.04.6_amd64.deb ...\r\nUnpacking libpython3.8-stdlib:amd64 (3.8.10-0ubuntu1~20.04.6) ...\r\nSelecting previously unselected package python3.8.\r\nPreparing to unpack .../4-python3.8_3.8.10-0ubuntu1~20.04.6_amd64.deb ...\r\nUnpacking python3.8 (3.8.10-0ubuntu1~20.04.6) ...\r\nSelecting previously unselected package libpython3-stdlib:amd64.\r\nPreparing to unpack .../5-libpython3-stdlib_3.8.2-0ubuntu2_amd64.deb ...\r\nUnpacking libpython3-stdlib:amd64 (3.8.2-0ubuntu2) ...\r\nSetting up python3-minimal (3.8.2-0ubuntu2) ...\r\nSelecting previously unselected package python3.\r\n(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 13505 files and directories currently installed.)\r\nPreparing to unpack .../00-python3_3.8.2-0ubuntu2_amd64.deb ...\r\nUnpacking python3 (3.8.2-0ubuntu2) ...\r\nSelecting previously unselected package python3-pkg-resources.\r\nPreparing to unpack .../01-python3-pkg-resources_45.2.0-1_all.deb ...\r\nUnpacking python3-pkg-resources (45.2.0-1) ...\r\nSelecting previously unselected package libcurl3-gnutls:amd64.\r\nPreparing to unpack .../02-libcurl3-gnutls_7.68.0-1ubuntu2.14_amd64.deb ...\r\nUnpacking libcurl3-gnutls:amd64 (7.68.0-1ubuntu2.14) ...\r\nSelecting previously unselected package liberror-perl.\r\nPreparing to unpack .../03-liberror-perl_0.17029-1_all.deb ...\r\nUnpacking liberror-perl (0.17029-1) ...\r\nSelecting previously unselected package git-man.\r\nPreparing to unpack .../04-git-man_1%3a2.25.1-1ubuntu3.6_all.deb ...\r\nUnpacking git-man (1:2.25.1-1ubuntu3.6) ...\r\nSelecting previously unselected package git.\r\nPreparing to unpack .../05-git_1%3a2.25.1-1ubuntu3.6_amd64.deb ...\r\nUnpacking git (1:2.25.1-1ubuntu3.6) ...\r\nSelecting previously unselected package libexpat1-dev:amd64.\r\nPreparing to unpack .../06-libexpat1-dev_2.2.9-1ubuntu0.6_amd64.deb ...\r\nUnpacking libexpat1-dev:amd64 (2.2.9-1ubuntu0.6) ...\r\nSelecting previously unselected package libpython3.8:amd64.\r\nPreparing to unpack .../07-libpython3.8_3.8.10-0ubuntu1~20.04.6_amd64.deb ...\r\nUnpacking libpython3.8:amd64 (3.8.10-0ubuntu1~20.04.6) ...\r\nSelecting previously unselected package libpython3.8-dev:amd64.\r\nPreparing to unpack .../08-libpython3.8-dev_3.8.10-0ubuntu1~20.04.6_amd64.deb ...\r\nUnpacking libpython3.8-dev:amd64 (3.8.10-0ubuntu1~20.04.6) ...\r\nSelecting previously unselected package libpython3-dev:amd64.\r\nPreparing to unpack .../09-libpython3-dev_3.8.2-0ubuntu2_amd64.deb ...\r\nUnpacking libpython3-dev:amd64 (3.8.2-0ubuntu2) ...\r\nSelecting previously unselected package python-pip-whl.\r\nPreparing to unpack .../10-python-pip-whl_20.0.2-5ubuntu1.6_all.deb ...\r\nUnpacking python-pip-whl (20.0.2-5ubuntu1.6) ...\r\nSelecting previously unselected package zlib1g-dev:amd64.\r\nPreparing to unpack .../11-zlib1g-dev_1%3a1.2.11.dfsg-2ubuntu1.5_amd64.deb ...\r\nUnpacking zlib1g-dev:amd64 (1:1.2.11.dfsg-2ubuntu1.5) ...\r\nSelecting previously unselected package python3.8-dev.\r\nPreparing to unpack .../12-python3.8-dev_3.8.10-0ubuntu1~20.04.6_amd64.deb ...\r\nUnpacking python3.8-dev (3.8.10-0ubuntu1~20.04.6) ...\r\nSelecting previously unselected package python3-lib2to3.\r\nPreparing to unpack .../13-python3-lib2to3_3.8.10-0ubuntu1~20.04_all.deb ...\r\nUnpacking python3-lib2to3 (3.8.10-0ubuntu1~20.04) ...\r\nSelecting previously unselected package python3-distutils.\r\nPreparing to unpack .../14-python3-distutils_3.8.10-0ubuntu1~20.04_all.deb ...\r\nUnpacking python3-distutils (3.8.10-0ubuntu1~20.04) ...\r\nSelecting previously unselected package python3-dev.\r\nPreparing to unpack .../15-python3-dev_3.8.2-0ubuntu2_amd64.deb ...\r\nUnpacking python3-dev (3.8.2-0ubuntu2) ...\r\nSelecting previously unselected package python3-setuptools.\r\nPreparing to unpack .../16-python3-setuptools_45.2.0-1_all.deb ...\r\nUnpacking python3-setuptools (45.2.0-1) ...\r\nSelecting previously unselected package python3-wheel.\r\nPreparing to unpack .../17-python3-wheel_0.34.2-1_all.deb ...\r\nUnpacking python3-wheel (0.34.2-1) ...\r\nSelecting previously unselected package python3-pip.\r\nPreparing to unpack .../18-python3-pip_20.0.2-5ubuntu1.6_all.deb ...\r\nUnpacking python3-pip (20.0.2-5ubuntu1.6) ...\r\nSetting up mime-support (3.64ubuntu1) ...\r\nSetting up libcurl3-gnutls:amd64 (7.68.0-1ubuntu2.14) ...\r\nSetting up liberror-perl (0.17029-1) ...\r\nSetting up libexpat1-dev:amd64 (2.2.9-1ubuntu0.6) ...\r\nSetting up zlib1g-dev:amd64 (1:1.2.11.dfsg-2ubuntu1.5) ...\r\nSetting up git-man (1:2.25.1-1ubuntu3.6) ...\r\nSetting up python-pip-whl (20.0.2-5ubuntu1.6) ...\r\nSetting up libmpdec2:amd64 (2.4.2-3) ...\r\nSetting up libpython3.8-stdlib:amd64 (3.8.10-0ubuntu1~20.04.6) ...\r\nSetting up python3.8 (3.8.10-0ubuntu1~20.04.6) ...\r\nSetting up libpython3-stdlib:amd64 (3.8.2-0ubuntu2) ...\r\nSetting up python3 (3.8.2-0ubuntu2) ...\r\nSetting up python3-wheel (0.34.2-1) ...\r\nSetting up libpython3.8:amd64 (3.8.10-0ubuntu1~20.04.6) ...\r\nSetting up git (1:2.25.1-1ubuntu3.6) ...\r\nSetting up python3-lib2to3 (3.8.10-0ubuntu1~20.04) ...\r\nSetting up python3-pkg-resources (45.2.0-1) ...\r\nSetting up python3-distutils (3.8.10-0ubuntu1~20.04) ...\r\nSetting up python3-setuptools (45.2.0-1) ...\r\nSetting up libpython3.8-dev:amd64 (3.8.10-0ubuntu1~20.04.6) ...\r\nSetting up python3-pip (20.0.2-5ubuntu1.6) ...\r\nSetting up python3.8-dev (3.8.10-0ubuntu1~20.04.6) ...\r\nSetting up libpython3-dev:amd64 (3.8.2-0ubuntu2) ...\r\nSetting up python3-dev (3.8.2-0ubuntu2) ...\r\nProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\r\nRemoving intermediate container bfd7e22bc691\n ---> e145b0679bac\nStep 7/25 : RUN pip3 install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio==0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n ---> Running in c7df88a41c0a\nLooking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\nCollecting torch==1.10.1+cu113\n  Downloading https://download.pytorch.org/whl/cu113/torch-1.10.1%2Bcu113-cp38-cp38-linux_x86_64.whl (1821.4 MB)\nCollecting torchvision==0.11.2+cu113\n  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.11.2%2Bcu113-cp38-cp38-linux_x86_64.whl (24.6 MB)\nCollecting torchaudio==0.10.1+cu113\n  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.10.1%2Bcu113-cp38-cp38-linux_x86_64.whl (2.9 MB)\nCollecting typing-extensions\n  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\nCollecting pillow!=8.3.0,>=5.3.0\n  Downloading Pillow-9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\nCollecting numpy\n  Downloading numpy-1.24.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\nInstalling collected packages: typing-extensions, torch, pillow, numpy, torchvision, torchaudio\nSuccessfully installed numpy-1.24.1 pillow-9.3.0 torch-1.10.1+cu113 torchaudio-0.10.1+cu113 torchvision-0.11.2+cu113 typing-extensions-4.4.0\nRemoving intermediate container c7df88a41c0a\n ---> 55fea7b2d580\nStep 8/25 : RUN git clone https://github.com/NVIDIA/apex.git\n ---> Running in 7bb0da675b36\n\u001b[91mCloning into 'apex'...\n\u001b[0mRemoving intermediate container 7bb0da675b36\n ---> 0a3ad3a218e5\nStep 9/25 : WORKDIR /build/apex\n ---> Running in 94273c662bfb\nRemoving intermediate container 94273c662bfb\n ---> 2f490981b5a2\nStep 10/25 : RUN git checkout e2083df5eb96643c61613b9df48dd4eea6b07690\n ---> Running in 1fbae6e9ad72\n\u001b[91mNote: switching to 'e2083df5eb96643c61613b9df48dd4eea6b07690'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by switching back to a branch.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -c with the switch command. Example:\n\n  git switch -c <new-branch-name>\n\nOr undo this operation with:\n\n  git switch -\n\nTurn off this advice by setting config variable advice.detachedHead to false\n\nHEAD is now at e2083df fast layer norm (#1037)\n\u001b[0mRemoving intermediate container 1fbae6e9ad72\n ---> 56fd289b5ad8\nStep 11/25 : RUN pip3 install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" --global-option=\"--deprecated_fused_adam\" --global-option=\"--xentropy\" --global-option=\"--fast_multihead_attn\" ./\n ---> Running in 4ae5bc3af807\nNon-user install because site-packages writeable\nCreated temporary directory: /tmp/pip-ephem-wheel-cache-wy599i2z\nCreated temporary directory: /tmp/pip-req-tracker-2uotp2ch\nInitialized build tracking at /tmp/pip-req-tracker-2uotp2ch\nCreated build tracker: /tmp/pip-req-tracker-2uotp2ch\nEntered build tracker: /tmp/pip-req-tracker-2uotp2ch\nCreated temporary directory: /tmp/pip-install-_vt11oqd\nProcessing /build/apex\n  Created temporary directory: /tmp/pip-req-build-40r49h1x\n  Added file:///build/apex to build tracker '/tmp/pip-req-tracker-2uotp2ch'\n    Running setup.py (path:/tmp/pip-req-build-40r49h1x/setup.py) egg_info for package from file:///build/apex\n\u001b[91m/usr/lib/python3/dist-packages/pip/_internal/commands/install.py:255: UserWarning: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\n  cmdoptions.check_install_build_global(options)\n    Running command python setup.py egg_info\n\u001b[0m\u001b[91m    No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n\n    Warning: Torch did not find available GPUs on this system.\n     If your intention is to cross-compile, this is not an error.\n    By default, Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\n    Volta (compute capability 7.0), Turing (compute capability 7.5),\n    and, if the CUDA version is >= 11.0, Ampere (compute capability 8.0).\n    If you wish to cross-compile for a single specific architecture,\n    export TORCH_CUDA_ARCH_LIST=\"compute capability\" before running setup.py.\n\n\n\n    torch.__version__  = 1.10.1+cu113\n\n\n    running egg_info\n    creating /tmp/pip-req-build-40r49h1x/pip-egg-info/apex.egg-info\n\u001b[0m\u001b[91m    writing /tmp/pip-req-build-40r49h1x/pip-egg-info/apex.egg-info/PKG-INFO\n\u001b[0m\u001b[91m    writing dependency_links to /tmp/pip-req-build-40r49h1x/pip-egg-info/apex.egg-info/dependency_links.txt\n\u001b[0m\u001b[91m    writing top-level names to /tmp/pip-req-build-40r49h1x/pip-egg-info/apex.egg-info/top_level.txt\n\u001b[0m\u001b[91m    writing manifest file '/tmp/pip-req-build-40r49h1x/pip-egg-info/apex.egg-info/SOURCES.txt'\n\u001b[0m\u001b[91m    reading manifest file '/tmp/pip-req-build-40r49h1x/pip-egg-info/apex.egg-info/SOURCES.txt'\n\u001b[0m\u001b[91m    writing manifest file '/tmp/pip-req-build-40r49h1x/pip-egg-info/apex.egg-info/SOURCES.txt'\n\u001b[0m\u001b[91m    /tmp/pip-req-build-40r49h1x/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n\u001b[0m\u001b[91m      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n\u001b[0m  Source in /tmp/pip-req-build-40r49h1x has version 0.1, which satisfies requirement apex==0.1 from file:///build/apex\n  Removed apex==0.1 from file:///build/apex from build tracker '/tmp/pip-req-tracker-2uotp2ch'\nSkipping wheel build for apex, due to binaries being disabled for it.\nInstalling collected packages: apex\n  Created temporary directory: /tmp/pip-record-9w33r22f\n    Running setup.py install for apex: started\n\u001b[91m    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-40r49h1x/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-40r49h1x/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext --deprecated_fused_adam --xentropy --fast_multihead_attn install --record /tmp/pip-record-9w33r22f/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.8/apex\n\u001b[0m\u001b[91m    No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    Warning: Torch did not find available GPUs on this system.\n\u001b[0m\u001b[91m     If your intention is to cross-compile, this is not an error.\n\u001b[0m\u001b[91m    By default, Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\n\u001b[0m\u001b[91m    Volta (compute capability 7.0), Turing (compute capability 7.5),\n\u001b[0m\u001b[91m    and, if the CUDA version is >= 11.0, Ampere (compute capability 8.0).\n\u001b[0m\u001b[91m    If you wish to cross-compile for a single specific architecture,\n\u001b[0m\u001b[91m    export TORCH_CUDA_ARCH_LIST=\"compute capability\" before running setup.py.\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    torch.__version__  = 1.10.1+cu113\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    /tmp/pip-req-build-40r49h1x/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n\u001b[0m\u001b[91m      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    Compiling cuda extensions with\n    nvcc: NVIDIA (R) Cuda compiler driver\n\u001b[0m\u001b[91m    Copyright (c) 2005-2021 NVIDIA Corporation\n\u001b[0m\u001b[91m    Built on Mon_May__3_19:15:13_PDT_2021\n\u001b[0m\u001b[91m    Cuda compilation tools, release 11.3, V11.3.109\n\u001b[0m\u001b[91m    Build cuda_11.3.r11.3/compiler.29920130_0\n\u001b[0m\u001b[91m    from /usr/local/cuda/bin\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    Submodule 'apex/contrib/csrc/multihead_attn/cutlass' (https://github.com/NVIDIA/cutlass.git) registered for path 'apex/contrib/csrc/multihead_attn/cutlass'\n\u001b[0m\u001b[91m    Cloning into '/tmp/pip-req-build-40r49h1x/apex/contrib/csrc/multihead_attn/cutlass'...\n\u001b[0m\u001b[91m    Submodule path 'apex/contrib/csrc/multihead_attn/cutlass': checked out 'ed2ed4d667ce95e1371bd62db32b6a114e774336'\n\u001b[0m\u001b[91m    running install\n\u001b[0m\u001b[91m    running build\n\u001b[0m\u001b[91m    running build_py\n\u001b[0m\u001b[91m    creating build\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex\n\u001b[0m\u001b[91m    copying apex/__init__.py -> build/lib.linux-x86_64-3.8/apex\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/contrib\n\u001b[0m\u001b[91m    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/reparameterization\n\u001b[0m\u001b[91m    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.8/apex/reparameterization\n\u001b[0m\u001b[91m    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.8/apex/reparameterization\n\u001b[0m\u001b[91m    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.8/apex/reparameterization\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.8/apex/amp\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/RNN\n\u001b[0m\u001b[91m    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.8/apex/RNN\n\u001b[0m\u001b[91m    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.8/apex/RNN\n\u001b[0m\u001b[91m    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.8/apex/RNN\n\u001b[0m\u001b[91m    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.8/apex/RNN\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/multi_tensor_apply\n\u001b[0m\u001b[91m    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.8/apex/multi_tensor_apply\n\u001b[0m\u001b[91m    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.8/apex/multi_tensor_apply\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/parallel\n\u001b[0m\u001b[91m    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.8/apex/parallel\n\u001b[0m\u001b[91m    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.8/apex/parallel\n\u001b[0m\u001b[91m    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.8/apex/parallel\n\u001b[0m\u001b[91m    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.8/apex/parallel\n\u001b[0m\u001b[91m    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.8/apex/parallel\n\u001b[0m\u001b[91m    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.8/apex/parallel\n\u001b[0m\u001b[91m    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.8/apex/parallel\n\u001b[0m\u001b[91m    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.8/apex/parallel\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/optimizers\n\u001b[0m\u001b[91m    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.8/apex/optimizers\n\u001b[0m\u001b[91m    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.8/apex/optimizers\n\u001b[0m\u001b[91m    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.8/apex/optimizers\n\u001b[0m\u001b[91m    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.8/apex/optimizers\n\u001b[0m\u001b[91m    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.8/apex/optimizers\n\u001b[0m\u001b[91m    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.8/apex/optimizers\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/fp16_utils\n\u001b[0m\u001b[91m    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.8/apex/fp16_utils\n\u001b[0m\u001b[91m    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.8/apex/fp16_utils\n\u001b[0m\u001b[91m    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.8/apex/fp16_utils\n\u001b[0m\u001b[91m    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.8/apex/fp16_utils\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/pyprof\n\u001b[0m\u001b[91m    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.8/apex/pyprof\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/normalization\n\u001b[0m\u001b[91m    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.8/apex/normalization\n\u001b[0m\u001b[91m    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.8/apex/normalization\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/mlp\n\u001b[0m\u001b[91m    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.8/apex/mlp\n\u001b[0m\u001b[91m    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.8/apex/mlp\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/contrib/sparsity\n\u001b[0m\u001b[91m    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/sparsity\n\u001b[0m\u001b[91m    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.8/apex/contrib/sparsity\n\u001b[0m\u001b[91m    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.8/apex/contrib/sparsity\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/contrib/xentropy\n\u001b[0m\u001b[91m    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/xentropy\n\u001b[0m\u001b[91m    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.8/apex/contrib/xentropy\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/contrib/layer_norm\n\u001b[0m\u001b[91m    copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-3.8/apex/contrib/layer_norm\n\u001b[0m\u001b[91m    copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/layer_norm\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/contrib/groupbn\n\u001b[0m\u001b[91m    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/groupbn\n\u001b[0m\u001b[91m    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.8/apex/contrib/groupbn\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/amp/lists\n\u001b[0m\u001b[91m    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.8/apex/amp/lists\n\u001b[0m\u001b[91m    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.8/apex/amp/lists\n\u001b[0m\u001b[91m    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.8/apex/amp/lists\n\u001b[0m\u001b[91m    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.8/apex/amp/lists\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.8/apex/pyprof/prof\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/pyprof/parse\n\u001b[0m\u001b[91m    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.8/apex/pyprof/parse\n\u001b[0m\u001b[91m    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.8/apex/pyprof/parse\n\u001b[0m\u001b[91m    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.8/apex/pyprof/parse\n\u001b[0m\u001b[91m    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.8/apex/pyprof/parse\n\u001b[0m\u001b[91m    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.8/apex/pyprof/parse\n\u001b[0m\u001b[91m    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.8/apex/pyprof/parse\n\u001b[0m\u001b[91m    creating build/lib.linux-x86_64-3.8/apex/pyprof/nvtx\n\u001b[0m\u001b[91m    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.8/apex/pyprof/nvtx\n\u001b[0m\u001b[91m    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.8/apex/pyprof/nvtx\n\u001b[0m\u001b[91m    running build_ext\n\u001b[0m\u001b[91m    building 'apex_C' extension\n\u001b[0m\u001b[91m    creating build/temp.linux-x86_64-3.8\n\u001b[0m\u001b[91m    creating build/temp.linux-x86_64-3.8/csrc\n\u001b[0m\u001b[91m    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.8/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/flatten_unflatten.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/apex_C.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'amp_C' extension\n\u001b[0m\u001b[91m    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.8/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.8/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.8/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.8/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.8/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.8/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.8/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.8/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.8/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.8/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.8/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.8/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.8/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.8/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.8/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.8/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.8/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.8/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.8/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.8/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.8/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/amp_C.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'syncbn' extension\n\u001b[0m\u001b[91m    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.8/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/welford.cu -o build/temp.linux-x86_64-3.8/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/syncbn.o build/temp.linux-x86_64-3.8/csrc/welford.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/syncbn.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'fused_layer_norm_cuda' extension\n\u001b[0m\u001b[91m    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.8/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp: In function std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double):\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n\u001b[0m\u001b[91m          |                                                                ^~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      129 |   CHECK_INPUT(input);\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp: In function std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double):\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n\u001b[0m\u001b[91m          |                                                                ^~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      149 |   CHECK_INPUT(input);\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n\u001b[0m\u001b[91m          |                                                                ^~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      150 |   CHECK_INPUT(gamma);\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n\u001b[0m\u001b[91m          |                                                                ^~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      151 |   CHECK_INPUT(beta);\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp: In function at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double):\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n\u001b[0m\u001b[91m          |                                                                ^~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      193 |   CHECK_INPUT(dout);\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n\u001b[0m\u001b[91m          |                                                                ^~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      194 |   CHECK_INPUT(mean);\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n\u001b[0m\u001b[91m          |                                                                ^~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      195 |   CHECK_INPUT(invvar);\n          |   ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n\u001b[0m\u001b[91m          |                                                                ^~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      196 |   CHECK_INPUT(input);\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp: In function std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double):\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n\u001b[0m\u001b[91m          |                                                                ^~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      218 |   CHECK_INPUT(dout);\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n\u001b[0m\u001b[91m          |                                                                ^~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      219 |   CHECK_INPUT(mean);\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n          |                                                                ^~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      220 |   CHECK_INPUT(invvar);\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n\u001b[0m\u001b[91m          |                                                                ^~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      221 |   CHECK_INPUT(input);\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n\u001b[0m\u001b[91m          |                                                                ^~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      222 |   CHECK_INPUT(gamma);\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/DeviceType.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:42: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/macros/Macros.h:197:64: note: in definition of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      197 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n\u001b[0m\u001b[91m          |                                                                ^~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:441:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      441 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro TORCH_CHECK\n\u001b[0m\u001b[91m      117 | #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m      119 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m      223 |   CHECK_INPUT(beta);\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from csrc/layer_norm_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.8/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.8/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/fused_layer_norm_cuda.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'mlp_cuda' extension\n\u001b[0m\u001b[91m    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.8/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    csrc/mlp.cpp: In function std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>):\n    csrc/mlp.cpp:56:21: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n\u001b[0m\u001b[91m       56 |   for (int i = 0; i < num_layers; i++) {\n\u001b[0m\u001b[91m          |                   ~~^~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:64:77: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       64 |   auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n\u001b[0m\u001b[91m          |                                                                             ^\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:65:67: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       65 |   auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n\u001b[0m\u001b[91m          |                                                                   ^\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:65:36: warning: narrowing conversion of reserved_size from long unsigned int to long int [-Wnarrowing]\n\u001b[0m\u001b[91m       65 |   auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n\u001b[0m\u001b[91m          |                                    ^~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:65:36: warning: narrowing conversion of reserved_size from long unsigned int to long int [-Wnarrowing]\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:13,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    csrc/mlp.cpp: In lambda function:\n\u001b[0m\u001b[91m    csrc/mlp.cpp:67:54: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       67 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n\u001b[0m\u001b[91m          |                                                      ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:276:28: note: in definition of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      276 |     const auto& the_type = TYPE;                                               \\\n\u001b[0m\u001b[91m          |                            ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:13,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n\u001b[0m\u001b[91m          |                                                        ^\n\u001b[0m\u001b[91m    csrc/mlp.cpp:67:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m       67 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\n\u001b[0m\u001b[91m      176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n\u001b[0m\u001b[91m          |                                                        ^\n\u001b[0m\u001b[91m    csrc/mlp.cpp:67:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m       67 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\n\u001b[0m\u001b[91m      176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp: In lambda function:\n\u001b[0m\u001b[91m    csrc/mlp.cpp:70:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n\u001b[0m\u001b[91m       70 |     for (int i = 0; i < num_layers; i++) {\n\u001b[0m\u001b[91m          |                     ~~^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:67:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m       67 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:76:10: warning: unused variable result [-Wunused-variable]\n\u001b[0m\u001b[91m       76 |     auto result = mlp_fp<scalar_t>(\n\u001b[0m\u001b[91m          |          ^~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:67:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m       67 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp: In lambda function:\n\u001b[0m\u001b[91m    csrc/mlp.cpp:70:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n       70 |     for (int i = 0; i < num_layers; i++) {\n\u001b[0m\u001b[91m          |                     ~~^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:67:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m       67 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:76:10: warning: unused variable result [-Wunused-variable]\n\u001b[0m\u001b[91m       76 |     auto result = mlp_fp<scalar_t>(\n\u001b[0m\u001b[91m          |          ^~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:67:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m       67 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp: In lambda function:\n\u001b[0m\u001b[91m    csrc/mlp.cpp:70:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n\u001b[0m\u001b[91m       70 |     for (int i = 0; i < num_layers; i++) {\n\u001b[0m\u001b[91m          |                     ~~^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:67:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m       67 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:76:10: warning: unused variable result [-Wunused-variable]\n\u001b[0m\u001b[91m       76 |     auto result = mlp_fp<scalar_t>(\n\u001b[0m\u001b[91m          |          ^~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:67:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m       67 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp: In function std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>):\n    csrc/mlp.cpp:113:21: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n\u001b[0m\u001b[91m      113 |   for (int i = 0; i < num_layers; i++) {\n\u001b[0m\u001b[91m          |                   ~~^~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:119:21: warning: comparison of integer expressions of different signedness: int and std::vector<at::Tensor>::size_type {aka long unsigned int} [-Wsign-compare]\n\u001b[0m\u001b[91m      119 |   for (int i = 0; i < inputs.size(); i++) {\n\u001b[0m\u001b[91m          |                   ~~^~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:120:67: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      120 |     outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n\u001b[0m\u001b[91m          |                                                                   ^\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:13,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    csrc/mlp.cpp: In lambda function:\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:54: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |                                                      ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:276:28: note: in definition of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      276 |     const auto& the_type = TYPE;                                               \\\n\u001b[0m\u001b[91m          |                            ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:13,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n\u001b[0m\u001b[91m          |                                                        ^\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\n\u001b[0m\u001b[91m      176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:278:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      278 |     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n\u001b[0m\u001b[91m          |                                                        ^\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:176:23: note: declared here\n\u001b[0m\u001b[91m      176 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp: In lambda function:\n\u001b[0m\u001b[91m    csrc/mlp.cpp:125:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n\u001b[0m\u001b[91m      125 |     for (int i = 0; i < num_layers; i++) {\n\u001b[0m\u001b[91m          |                     ~~^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:129:23: warning: comparison of integer expressions of different signedness: int and std::vector<at::Tensor>::size_type {aka long unsigned int} [-Wsign-compare]\n\u001b[0m\u001b[91m      129 |     for (int i = 0; i < inputs.size(); i++) {\n\u001b[0m\u001b[91m          |                     ~~^~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:137:80: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      137 |     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n\u001b[0m\u001b[91m          |                                                                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:13,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    csrc/mlp.cpp:137:44: warning: narrowing conversion of (work_size / sizeof (scalar_t)) from long unsigned int to long int [-Wnarrowing]\n\u001b[0m\u001b[91m      137 |     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n\u001b[0m\u001b[91m          |                                  ~~~~~~~~~~^~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:137:44: warning: narrowing conversion of (work_size / sizeof (scalar_t)) from long unsigned int to long int [-Wnarrowing]\n\u001b[0m\u001b[91m      137 |     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n\u001b[0m\u001b[91m          |                                  ~~~~~~~~~~^~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:139:10: warning: unused variable result [-Wunused-variable]\n\u001b[0m\u001b[91m      139 |     auto result = mlp_bp<scalar_t>(\n\u001b[0m\u001b[91m          |          ^~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      281 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp: In lambda function:\n\u001b[0m\u001b[91m    csrc/mlp.cpp:125:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n\u001b[0m\u001b[91m      125 |     for (int i = 0; i < num_layers; i++) {\n\u001b[0m\u001b[91m          |                     ~~^~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n      282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:129:23: warning: comparison of integer expressions of different signedness: int and std::vector<at::Tensor>::size_type {aka long unsigned int} [-Wsign-compare]\n\u001b[0m\u001b[91m      129 |     for (int i = 0; i < inputs.size(); i++) {\n\u001b[0m\u001b[91m          |                     ~~^~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:137:80: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      137 |     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n\u001b[0m\u001b[91m          |                                                                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:13,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    csrc/mlp.cpp:137:44: warning: narrowing conversion of (work_size / sizeof (scalar_t)) from long unsigned int to long int [-Wnarrowing]\n\u001b[0m\u001b[91m      137 |     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n\u001b[0m\u001b[91m          |                                  ~~~~~~~~~~^~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:137:44: warning: narrowing conversion of (work_size / sizeof (scalar_t)) from long unsigned int to long int [-Wnarrowing]\n\u001b[0m\u001b[91m      137 |     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n\u001b[0m\u001b[91m          |                                  ~~~~~~~~~~^~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:139:10: warning: unused variable result [-Wunused-variable]\n\u001b[0m\u001b[91m      139 |     auto result = mlp_bp<scalar_t>(\n\u001b[0m\u001b[91m          |          ^~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:282:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      282 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp: In lambda function:\n\u001b[0m\u001b[91m    csrc/mlp.cpp:125:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n\u001b[0m\u001b[91m      125 |     for (int i = 0; i < num_layers; i++) {\n\u001b[0m\u001b[91m          |                     ~~^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:129:23: warning: comparison of integer expressions of different signedness: int and std::vector<at::Tensor>::size_type {aka long unsigned int} [-Wsign-compare]\n\u001b[0m\u001b[91m      129 |     for (int i = 0; i < inputs.size(); i++) {\n\u001b[0m\u001b[91m          |                     ~~^~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:137:80: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      137 |     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n\u001b[0m\u001b[91m          |                                                                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:13,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from csrc/mlp.cpp:1:\n    csrc/mlp.cpp:137:44: warning: narrowing conversion of (work_size / sizeof (scalar_t)) from long unsigned int to long int [-Wnarrowing]\n\u001b[0m\u001b[91m      137 |     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n          |                                  ~~~~~~~~~~^~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    csrc/mlp.cpp:137:44: warning: narrowing conversion of (work_size / sizeof (scalar_t)) from long unsigned int to long int [-Wnarrowing]\n\u001b[0m\u001b[91m      137 |     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n\u001b[0m\u001b[91m          |                                  ~~~~~~~~~~^~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:139:10: warning: unused variable result [-Wunused-variable]\n\u001b[0m\u001b[91m      139 |     auto result = mlp_bp<scalar_t>(\n\u001b[0m\u001b[91m          |          ^~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n\u001b[0m\u001b[91m       66 |     return __VA_ARGS__();                                                        \\\n\u001b[0m\u001b[91m          |            ^~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:283:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n\u001b[0m\u001b[91m      283 |       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    csrc/mlp.cpp:123:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n\u001b[0m\u001b[91m      123 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/mlp.o build/temp.linux-x86_64-3.8/csrc/mlp_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/mlp_cuda.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'xentropy_cuda' extension\n\u001b[0m\u001b[91m    creating build/temp.linux-x86_64-3.8/apex\n\u001b[0m\u001b[91m    creating build/temp.linux-x86_64-3.8/apex/contrib\n\u001b[0m\u001b[91m    creating build/temp.linux-x86_64-3.8/apex/contrib/csrc\n\u001b[0m\u001b[91m    creating build/temp.linux-x86_64-3.8/apex/contrib/csrc/xentropy\n\u001b[0m\u001b[91m    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/tmp/pip-req-build-40r49h1x/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/xentropy/interface.cpp -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/xentropy/interface.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=xentropy_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/xentropy/interface.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp: In function std::vector<at::Tensor> softmax_xentropy_forward(const at::Tensor&, const at::Tensor&, float, bool):\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:20:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       20 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:20:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       20 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:29:5: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       29 |     CHECK_CUDA(input);\n\u001b[0m\u001b[91m          |     ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/xentropy/interface.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/xentropy/interface.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:20:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       20 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:20:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       20 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:22:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       22 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:30:5: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       30 |     CHECK_INPUT(labels);\n\u001b[0m\u001b[91m          |     ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/xentropy/interface.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/xentropy/interface.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp: In function at::Tensor softmax_xentropy_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:20:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       20 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:20:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       20 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:41:5: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       41 |     CHECK_CUDA(grad_loss);\n\u001b[0m\u001b[91m          |     ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/xentropy/interface.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/xentropy/interface.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:20:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       20 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:20:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       20 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:42:5: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       42 |     CHECK_CUDA(logits);\n\u001b[0m\u001b[91m          |     ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/xentropy/interface.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/xentropy/interface.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:20:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       20 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:20:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       20 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:22:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       22 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:43:5: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       43 |     CHECK_INPUT(max_log_sum_exp);\n\u001b[0m\u001b[91m          |     ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/xentropy/interface.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/xentropy/interface.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:20:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       20 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:20:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       20 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:22:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       22 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/xentropy/interface.cpp:44:5: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       44 |     CHECK_INPUT(labels);\n\u001b[0m\u001b[91m          |     ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/xentropy/interface.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/tmp/pip-req-build-40r49h1x/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/xentropy/xentropy_kernel.cu -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/xentropy/xentropy_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=xentropy_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/apex/contrib/csrc/xentropy/interface.o build/temp.linux-x86_64-3.8/apex/contrib/csrc/xentropy/xentropy_kernel.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/xentropy_cuda.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'fused_adam_cuda' extension\n\u001b[0m\u001b[91m    creating build/temp.linux-x86_64-3.8/apex/contrib/csrc/optimizers\n\u001b[0m\u001b[91m    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/tmp/pip-req-build-40r49h1x/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/optimizers/fused_adam_cuda.cpp -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/optimizers/fused_adam_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp: In function void strided_check_finite(at::Tensor&, at::Tensor&, int, int):\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:26:2: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       26 |  CHECK_INPUT(p_copy);\n\u001b[0m\u001b[91m          |  ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp: In function void adam(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, float, float, float, float, float, int, int, int, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:30:9: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       30 |         CHECK_INPUT(p);\n\u001b[0m\u001b[91m          |         ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:31:33: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       31 |         if (p_copy.numel() > 0) CHECK_INPUT(p_copy);\n\u001b[0m\u001b[91m          |                                 ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:32:9: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       32 |         CHECK_INPUT(m);\n\u001b[0m\u001b[91m          |         ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n          |                                         ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n          |                                       ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:33:9: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       33 |         CHECK_INPUT(v);\n\u001b[0m\u001b[91m          |         ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:34:9: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       34 |         CHECK_INPUT(g);\n\u001b[0m\u001b[91m          |         ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp: In function void reversible_adam(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, float, float, float, float, float, int, int, int, float):\n    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:44:9: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       44 |         CHECK_INPUT(p);\n\u001b[0m\u001b[91m          |         ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:45:33: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       45 |         if (p_copy.numel() > 0) CHECK_INPUT(p_copy);\n\u001b[0m\u001b[91m          |                                 ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:46:9: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       46 |         CHECK_INPUT(m);\n\u001b[0m\u001b[91m          |         ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:47:9: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       47 |         CHECK_INPUT(v);\n\u001b[0m\u001b[91m          |         ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:48:9: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       48 |         CHECK_INPUT(g);\n\u001b[0m\u001b[91m          |         ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp: In function void maybe_adam_undo(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, float, float, float, float, float, int, int, int, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:58:9: note: in expansion of macro CHECK_INPUT\n       58 |         CHECK_INPUT(p);\n\u001b[0m\u001b[91m          |         ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:59:9: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       59 |         CHECK_INPUT(m);\n\u001b[0m\u001b[91m          |         ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n          |                       ^~~~~~~~~~\n    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:60:9: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       60 |         CHECK_INPUT(v);\n\u001b[0m\u001b[91m          |         ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:61:9: note: in expansion of macro CHECK_INPUT\n       61 |         CHECK_INPUT(g);\n\u001b[0m\u001b[91m          |         ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp: In function void maybe_cast(at::Tensor&, at::Tensor&, at::Tensor&):\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n          |                       ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:70:2: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       70 |  CHECK_INPUT(p_in);\n          |  ^~~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:15:23: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       15 | #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n\u001b[0m\u001b[91m          |                       ^~~~~~~~~~\n    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:17:24: note: in expansion of macro CHECK_CUDA\n\u001b[0m\u001b[91m       17 | #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\u001b[0m\u001b[91m          |                        ^~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:71:2: note: in expansion of macro CHECK_INPUT\n\u001b[0m\u001b[91m       71 |  CHECK_INPUT(p_out);\n\u001b[0m\u001b[91m          |  ^~~~~~~~~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/optimizers/fused_adam_cuda.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/tmp/pip-req-build-40r49h1x/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/optimizers/fused_adam_cuda_kernel.cu -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/optimizers/fused_adam_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_62,code=sm_62 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -std=c++14\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/apex/contrib/csrc/optimizers/fused_adam_cuda.o build/temp.linux-x86_64-3.8/apex/contrib/csrc/optimizers/fused_adam_cuda_kernel.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/fused_adam_cuda.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'fast_additive_mask_softmax_dropout' extension\n\u001b[0m\u001b[91m    creating build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn\n\u001b[0m\u001b[91m    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_additive_mask_softmax_dropout -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp: In function std::vector<at::Tensor> multihead_attn::fused_softmax::additive_mask_softmax_dropout::fwd(bool, bool, int, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:41:25: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       41 |   AT_ASSERTM(input.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:41:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       41 |   AT_ASSERTM(input.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:45:29: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       45 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Half, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                             ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:45:4: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       45 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Half, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |    ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp: In function at::Tensor multihead_attn::fused_softmax::additive_mask_softmax_dropout::bwd(bool, int, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:70:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       70 |   AT_ASSERTM(output_grads.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:70:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       70 |   AT_ASSERTM(output_grads.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:71:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       71 |   AT_ASSERTM(softmax_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:71:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       71 |   AT_ASSERTM(softmax_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout_cuda.cu -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 -I./apex/contrib/csrc/multihead_attn/cutlass/ -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_80,code=sm_80 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_additive_mask_softmax_dropout -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout_cuda.cu(36): warning: variable \"dropout_elems\" was declared but never referenced\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout_cuda.cu(57): warning: variable \"softmax_success\" was set but never used\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout_cuda.cu(104): warning: variable \"dropout_elems\" was declared but never referenced\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout_cuda.cu(36): warning: variable \"dropout_elems\" was declared but never referenced\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout_cuda.cu(57): warning: variable \"softmax_success\" was set but never used\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout_cuda.cu(104): warning: variable \"dropout_elems\" was declared but never referenced\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout.o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/additive_masked_softmax_dropout_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/fast_additive_mask_softmax_dropout.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'fast_mask_softmax_dropout' extension\n\u001b[0m\u001b[91m    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/masked_softmax_dropout.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_mask_softmax_dropout -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp: In function std::vector<at::Tensor> multihead_attn::fused_softmax::mask_softmax_dropout::fwd(bool, bool, int, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:41:25: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       41 |   AT_ASSERTM(input.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:41:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       41 |   AT_ASSERTM(input.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:45:29: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       45 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                             ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:45:4: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       45 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |    ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp: In function at::Tensor multihead_attn::fused_softmax::mask_softmax_dropout::bwd(bool, int, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:71:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       71 |   AT_ASSERTM(output_grads.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:71:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       71 |   AT_ASSERTM(output_grads.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:72:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       72 |   AT_ASSERTM(softmax_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:72:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       72 |   AT_ASSERTM(softmax_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/masked_softmax_dropout.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 -I./apex/contrib/csrc/multihead_attn/cutlass/ -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_80,code=sm_80 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_mask_softmax_dropout -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(36): warning: variable \"dropout_elems\" was declared but never referenced\n\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(57): warning: variable \"softmax_success\" was set but never used\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(105): warning: variable \"dropout_elems\" was declared but never referenced\n\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(36): warning: variable \"dropout_elems\" was declared but never referenced\n\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(57): warning: variable \"softmax_success\" was set but never used\n\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.cu(105): warning: variable \"dropout_elems\" was declared but never referenced\n\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/masked_softmax_dropout.o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/masked_softmax_dropout_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/fast_mask_softmax_dropout.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'fast_self_multihead_attn_bias_additive_mask' extension\n\u001b[0m\u001b[91m    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_self_multihead_attn_bias_additive_mask -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp: In function std::vector<at::Tensor> multihead_attn::self_bias_additive_mask::cublas_gemmex::fwd(bool, bool, bool, int, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:62:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       62 |   AT_ASSERTM(inputs.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:62:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       62 |   AT_ASSERTM(inputs.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:63:33: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n       63 |   AT_ASSERTM(input_weights.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                 ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:63:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       63 |   AT_ASSERTM(input_weights.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:64:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n       64 |   AT_ASSERTM(output_weights.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                  ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:64:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       64 |   AT_ASSERTM(output_weights.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:69:29: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n       69 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Half, \"Only Half is supported\");\n\u001b[0m\u001b[91m          |                             ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:69:4: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       69 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Half, \"Only Half is supported\");\n\u001b[0m\u001b[91m          |    ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp: In function std::vector<at::Tensor> multihead_attn::self_bias_additive_mask::cublas_gemmex::bwd(int, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:110:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      110 |   AT_ASSERTM(output_grads.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:110:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      110 |   AT_ASSERTM(output_grads.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:111:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      111 |   AT_ASSERTM(matmul2_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:111:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      111 |   AT_ASSERTM(matmul2_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:112:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      112 |   AT_ASSERTM(dropout_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:112:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      112 |   AT_ASSERTM(dropout_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:113:37: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      113 |   AT_ASSERTM(input_lin_results.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                     ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:113:3: note: in expansion of macro AT_ASSERTM\n      113 |   AT_ASSERTM(input_lin_results.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:114:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      114 |   AT_ASSERTM(inputs.type().scalarType()            == at::ScalarType::Half, \"Only HALF is supported\");\n          |                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:114:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      114 |   AT_ASSERTM(inputs.type().scalarType()            == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:115:33: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      115 |   AT_ASSERTM(input_weights.type().scalarType()     == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                 ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:115:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      115 |   AT_ASSERTM(input_weights.type().scalarType()     == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:116:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      116 |   AT_ASSERTM(output_weights.type().scalarType()    == at::ScalarType::Half, \"Only HALF is supported\");\n          |                                  ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:116:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      116 |   AT_ASSERTM(output_weights.type().scalarType()    == at::ScalarType::Half, \"Only HALF is supported\");\n          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:117:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      117 |   AT_ASSERTM(dropout_mask.type().scalarType()      == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:117:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      117 |   AT_ASSERTM(dropout_mask.type().scalarType()      == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n          |                              ^~~~\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 -I./apex/contrib/csrc/multihead_attn/cutlass/ -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_80,code=sm_80 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_self_multihead_attn_bias_additive_mask -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(49): warning: variable \"dropout_elems\" was declared but never referenced\n\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(128): warning: variable \"softmax_success\" was set but never used\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(355): warning: type qualifier is meaningless on cast type\n\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(234): warning: variable \"dropout_elems\" was declared but never referenced\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/softmax.h(1751): warning: variable \"flag_vec4\" was declared but never referenced\n              detected during:\n\u001b[0m\u001b[91m                instantiation of \"__nv_bool masked_scale_softmax_warp_backward_recompute_kernel<input_t,output_t,acc_t,is_log_softmax>(int, int, int &, int &, masked_scale_softmax_warp_backward_recompute_func<input_t, output_t, acc_t, is_log_softmax> &) [with input_t=half, output_t=half, acc_t=float, is_log_softmax=false]\"\n\u001b[0m\u001b[91m    (1990): here\n\u001b[0m\u001b[91m                instantiation of \"__nv_bool dispatch_masked_scale_softmax_backward_recompute<input_t,output_t,acc_t,is_log_softmax>(output_t *, const input_t *, const input_t *, const input_t *, const uint8_t *, acc_t, int, int, int, int, cudaStream_t) [with input_t=half, output_t=half, acc_t=float, is_log_softmax=false]\"\n    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(353): here\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(49): warning: variable \"dropout_elems\" was declared but never referenced\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(128): warning: variable \"softmax_success\" was set but never used\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(355): warning: type qualifier is meaningless on cast type\n\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(234): warning: variable \"dropout_elems\" was declared but never referenced\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/softmax.h(1751): warning: variable \"flag_vec4\" was declared but never referenced\n              detected during:\n                instantiation of \"__nv_bool masked_scale_softmax_warp_backward_recompute_kernel<input_t,output_t,acc_t,is_log_softmax>(int, int, int &, int &, masked_scale_softmax_warp_backward_recompute_func<input_t, output_t, acc_t, is_log_softmax> &) [with input_t=half, output_t=half, acc_t=float, is_log_softmax=false]\"\n\u001b[0m\u001b[91m    (1990): here\n\u001b[0m\u001b[91m                instantiation of \"__nv_bool dispatch_masked_scale_softmax_backward_recompute<input_t,output_t,acc_t,is_log_softmax>(output_t *, const input_t *, const input_t *, const input_t *, const uint8_t *, acc_t, int, int, int, int, cudaStream_t) [with input_t=half, output_t=half, acc_t=float, is_log_softmax=false]\"\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(353): here\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.cu(355): warning: type qualifier is meaningless on cast type\n\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask.o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_additive_mask_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/fast_self_multihead_attn_bias_additive_mask.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'fast_self_multihead_attn_bias' extension\n\u001b[0m\u001b[91m    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_self_multihead_attn_bias -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp: In function std::vector<at::Tensor> multihead_attn::self_bias::cublas_gemmex::fwd(bool, bool, bool, int, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:59:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       59 |   AT_ASSERTM(inputs.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:59:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       59 |   AT_ASSERTM(inputs.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:60:33: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       60 |   AT_ASSERTM(input_weights.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                 ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:60:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       60 |   AT_ASSERTM(input_weights.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:61:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       61 |   AT_ASSERTM(output_weights.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                  ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:61:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       61 |   AT_ASSERTM(output_weights.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:65:29: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n       65 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                             ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:65:4: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       65 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |    ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp: In function std::vector<at::Tensor> multihead_attn::self_bias::cublas_gemmex::bwd(int, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:106:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      106 |   AT_ASSERTM(output_grads.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:106:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      106 |   AT_ASSERTM(output_grads.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:107:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      107 |   AT_ASSERTM(matmul2_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:107:3: note: in expansion of macro AT_ASSERTM\n      107 |   AT_ASSERTM(matmul2_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:108:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      108 |   AT_ASSERTM(dropout_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:108:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      108 |   AT_ASSERTM(dropout_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:109:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      109 |   AT_ASSERTM(softmax_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:109:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      109 |   AT_ASSERTM(softmax_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:110:37: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      110 |   AT_ASSERTM(input_lin_results.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                     ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:110:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      110 |   AT_ASSERTM(input_lin_results.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:111:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      111 |   AT_ASSERTM(inputs.type().scalarType()            == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:111:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      111 |   AT_ASSERTM(inputs.type().scalarType()            == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:112:33: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      112 |   AT_ASSERTM(input_weights.type().scalarType()     == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                 ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:112:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      112 |   AT_ASSERTM(input_weights.type().scalarType()     == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:113:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      113 |   AT_ASSERTM(output_weights.type().scalarType()    == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                  ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:113:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      113 |   AT_ASSERTM(output_weights.type().scalarType()    == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:114:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      114 |   AT_ASSERTM(dropout_mask.type().scalarType()      == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:114:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      114 |   AT_ASSERTM(dropout_mask.type().scalarType()      == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_cuda.cu -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 -I./apex/contrib/csrc/multihead_attn/cutlass/ -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_80,code=sm_80 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_self_multihead_attn_bias -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_cuda.cu(49): warning: variable \"dropout_elems\" was declared but never referenced\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_cuda.cu(127): warning: variable \"softmax_success\" was set but never used\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_cuda.cu(245): warning: variable \"dropout_elems\" was declared but never referenced\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_cuda.cu(49): warning: variable \"dropout_elems\" was declared but never referenced\n\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_cuda.cu(127): warning: variable \"softmax_success\" was set but never used\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_cuda.cu(245): warning: variable \"dropout_elems\" was declared but never referenced\n\u001b[0m\u001b[91m\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_bias.o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_bias_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/fast_self_multihead_attn_bias.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'fast_self_multihead_attn' extension\n    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_self_multihead_attn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp: In function std::vector<at::Tensor> multihead_attn::self::cublas_gemmex::fwd(bool, bool, bool, int, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:54:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       54 |   AT_ASSERTM(inputs.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:54:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       54 |   AT_ASSERTM(inputs.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:55:33: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       55 |   AT_ASSERTM(input_weights.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                 ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:55:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       55 |   AT_ASSERTM(input_weights.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:56:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       56 |   AT_ASSERTM(output_weights.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                  ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:56:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       56 |   AT_ASSERTM(output_weights.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:60:29: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       60 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                             ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:60:4: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       60 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |    ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp: In function std::vector<at::Tensor> multihead_attn::self::cublas_gemmex::bwd(int, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:99:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       99 |   AT_ASSERTM(output_grads.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:99:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       99 |   AT_ASSERTM(output_grads.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:100:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      100 |   AT_ASSERTM(matmul2_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:100:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      100 |   AT_ASSERTM(matmul2_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:101:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      101 |   AT_ASSERTM(dropout_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:101:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      101 |   AT_ASSERTM(dropout_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:102:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      102 |   AT_ASSERTM(softmax_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:102:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      102 |   AT_ASSERTM(softmax_results.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:103:37: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      103 |   AT_ASSERTM(input_lin_results.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n          |                                     ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n          |                                       ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:103:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      103 |   AT_ASSERTM(input_lin_results.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:104:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      104 |   AT_ASSERTM(inputs.type().scalarType()            == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:104:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      104 |   AT_ASSERTM(inputs.type().scalarType()            == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:105:33: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      105 |   AT_ASSERTM(input_weights.type().scalarType()     == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                 ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:105:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      105 |   AT_ASSERTM(input_weights.type().scalarType()     == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:106:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      106 |   AT_ASSERTM(output_weights.type().scalarType()    == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                  ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:106:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      106 |   AT_ASSERTM(output_weights.type().scalarType()    == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:107:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      107 |   AT_ASSERTM(dropout_mask.type().scalarType()      == at::ScalarType::Byte, \"Only BYTE is supported\");\n          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:107:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      107 |   AT_ASSERTM(dropout_mask.type().scalarType()      == at::ScalarType::Byte, \"Only BYTE is supported\");\n          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/self_multihead_attn_cuda.cu -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 -I./apex/contrib/csrc/multihead_attn/cutlass/ -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_80,code=sm_80 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_self_multihead_attn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn.o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/fast_self_multihead_attn.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'fast_self_multihead_attn_norm_add' extension\n    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_self_multihead_attn_norm_add -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp: In function std::vector<at::Tensor> multihead_attn::self_norm_add::cublas_gemmex::fwd(bool, bool, bool, int, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:67:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       67 |   AT_ASSERTM(inputs.type().scalarType()                == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:67:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       67 |   AT_ASSERTM(inputs.type().scalarType()                == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:68:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       68 |   AT_ASSERTM(lyr_nrm_gamma_weights.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:68:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       68 |   AT_ASSERTM(lyr_nrm_gamma_weights.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:69:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       69 |   AT_ASSERTM(lyr_nrm_beta_weights.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                        ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:69:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       69 |   AT_ASSERTM(lyr_nrm_beta_weights.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:70:33: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       70 |   AT_ASSERTM(input_weights.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                 ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:70:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       70 |   AT_ASSERTM(input_weights.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:71:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n       71 |   AT_ASSERTM(output_weights.type().scalarType()        == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                  ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:71:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       71 |   AT_ASSERTM(output_weights.type().scalarType()        == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:75:29: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       75 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                             ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:75:4: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       75 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |    ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp: In function std::vector<at::Tensor> multihead_attn::self_norm_add::cublas_gemmex::bwd(int, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:129:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      129 |   AT_ASSERTM(output_grads.type().scalarType()          == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:129:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      129 |   AT_ASSERTM(output_grads.type().scalarType()          == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:130:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      130 |   AT_ASSERTM(matmul2_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:130:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      130 |   AT_ASSERTM(matmul2_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:131:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      131 |   AT_ASSERTM(dropout_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:131:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      131 |   AT_ASSERTM(dropout_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:132:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      132 |   AT_ASSERTM(softmax_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:132:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      132 |   AT_ASSERTM(softmax_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:133:37: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      133 |   AT_ASSERTM(input_lin_results.type().scalarType()     == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                     ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:133:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      133 |   AT_ASSERTM(input_lin_results.type().scalarType()     == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:134:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      134 |   AT_ASSERTM(lyr_nrm_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:134:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      134 |   AT_ASSERTM(lyr_nrm_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:135:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      135 |   AT_ASSERTM(lyr_nrm_mean.type().scalarType()          == at::ScalarType::Float, \"Only FLOAT is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:135:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      135 |   AT_ASSERTM(lyr_nrm_mean.type().scalarType()          == at::ScalarType::Float, \"Only FLOAT is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:136:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      136 |   AT_ASSERTM(lyr_nrm_invvar.type().scalarType()        == at::ScalarType::Float, \"Only FLOAT is supported\");\n\u001b[0m\u001b[91m          |                                  ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:136:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      136 |   AT_ASSERTM(lyr_nrm_invvar.type().scalarType()        == at::ScalarType::Float, \"Only FLOAT is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:137:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      137 |   AT_ASSERTM(inputs.type().scalarType()                == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                          ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:137:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      137 |   AT_ASSERTM(inputs.type().scalarType()                == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:138:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      138 |   AT_ASSERTM(lyr_nrm_gamma_weights.type().scalarType() == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:138:3: note: in expansion of macro AT_ASSERTM\n      138 |   AT_ASSERTM(lyr_nrm_gamma_weights.type().scalarType() == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:139:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      139 |   AT_ASSERTM(lyr_nrm_beta_weights.type().scalarType()  == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                        ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:139:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      139 |   AT_ASSERTM(lyr_nrm_beta_weights.type().scalarType()  == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:140:33: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      140 |   AT_ASSERTM(input_weights.type().scalarType()         == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                 ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:140:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      140 |   AT_ASSERTM(input_weights.type().scalarType()         == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:141:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      141 |   AT_ASSERTM(output_weights.type().scalarType()        == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                  ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:141:3: note: in expansion of macro AT_ASSERTM\n      141 |   AT_ASSERTM(output_weights.type().scalarType()        == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:142:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      142 |   AT_ASSERTM(dropout_mask.type().scalarType()          == at::ScalarType::Byte,  \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:142:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      142 |   AT_ASSERTM(dropout_mask.type().scalarType()          == at::ScalarType::Byte,  \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:143:36: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      143 |   AT_ASSERTM(dropout_add_mask.type().scalarType()      == at::ScalarType::Byte,  \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                                    ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:143:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      143 |   AT_ASSERTM(dropout_add_mask.type().scalarType()      == at::ScalarType::Byte,  \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add_cuda.cu -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 -I./apex/contrib/csrc/multihead_attn/cutlass/ -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_80,code=sm_80 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_self_multihead_attn_norm_add -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add.o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/self_multihead_attn_norm_add_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/fast_self_multihead_attn_norm_add.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'fast_encdec_multihead_attn' extension\n    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/encdec_multihead_attn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_encdec_multihead_attn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp: In function std::vector<at::Tensor> multihead_attn::encdec::cublas_gemmex::fwd(bool, bool, bool, int, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:63:28: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       63 |   AT_ASSERTM(inputs_q.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                            ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:63:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       63 |   AT_ASSERTM(inputs_q.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:64:29: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       64 |   AT_ASSERTM(inputs_kv.type().scalarType()        == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                             ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:64:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       64 |   AT_ASSERTM(inputs_kv.type().scalarType()        == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:65:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       65 |   AT_ASSERTM(input_weights_q.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:65:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       65 |   AT_ASSERTM(input_weights_q.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:66:36: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       66 |   AT_ASSERTM(input_weights_kv.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                    ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:66:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       66 |   AT_ASSERTM(input_weights_kv.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:67:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       67 |   AT_ASSERTM(output_weights.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                  ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:67:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       67 |   AT_ASSERTM(output_weights.type().scalarType()   == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:71:29: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       71 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                             ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:71:4: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       71 |    AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |    ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp: In function std::vector<at::Tensor> multihead_attn::encdec::cublas_gemmex::bwd(int, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:118:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      118 |   AT_ASSERTM(output_grads.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:118:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      118 |   AT_ASSERTM(output_grads.type().scalarType()         == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:119:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      119 |   AT_ASSERTM(matmul2_results.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:119:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      119 |   AT_ASSERTM(matmul2_results.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:120:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      120 |   AT_ASSERTM(dropout_results.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:120:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      120 |   AT_ASSERTM(dropout_results.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:121:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      121 |   AT_ASSERTM(softmax_results.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:121:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      121 |   AT_ASSERTM(softmax_results.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:122:39: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      122 |   AT_ASSERTM(input_lin_q_results.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:122:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      122 |   AT_ASSERTM(input_lin_q_results.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:123:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      123 |   AT_ASSERTM(input_lin_kv_results.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                        ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:123:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      123 |   AT_ASSERTM(input_lin_kv_results.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:124:28: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      124 |   AT_ASSERTM(inputs_q.type().scalarType()             == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                            ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:124:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      124 |   AT_ASSERTM(inputs_q.type().scalarType()             == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:125:29: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      125 |   AT_ASSERTM(inputs_kv.type().scalarType()            == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                             ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:125:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      125 |   AT_ASSERTM(inputs_kv.type().scalarType()            == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:126:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      126 |   AT_ASSERTM(input_weights_q.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:126:3: note: in expansion of macro AT_ASSERTM\n      126 |   AT_ASSERTM(input_weights_q.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:127:36: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      127 |   AT_ASSERTM(input_weights_kv.type().scalarType()     == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                    ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:127:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      127 |   AT_ASSERTM(input_weights_kv.type().scalarType()     == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:128:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      128 |   AT_ASSERTM(output_weights.type().scalarType()       == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                  ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:128:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      128 |   AT_ASSERTM(output_weights.type().scalarType()       == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:129:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      129 |   AT_ASSERTM(dropout_mask.type().scalarType()         == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                                ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:129:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      129 |   AT_ASSERTM(dropout_mask.type().scalarType()         == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n          |                              ^~~~\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/encdec_multihead_attn_cuda.cu -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/encdec_multihead_attn_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 -I./apex/contrib/csrc/multihead_attn/cutlass/ -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_80,code=sm_80 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_encdec_multihead_attn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/encdec_multihead_attn.o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/encdec_multihead_attn_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/fast_encdec_multihead_attn.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    building 'fast_encdec_multihead_attn_norm_add' extension\n\u001b[0m\u001b[91m    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_encdec_multihead_attn_norm_add -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp: In function std::vector<at::Tensor> multihead_attn::encdec_norm_add::cublas_gemmex::fwd(bool, bool, bool, int, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:76:28: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       76 |   AT_ASSERTM(inputs_q.type().scalarType()              == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                            ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:76:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       76 |   AT_ASSERTM(inputs_q.type().scalarType()              == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:77:29: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       77 |   AT_ASSERTM(inputs_kv.type().scalarType()             == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                             ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:77:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       77 |   AT_ASSERTM(inputs_kv.type().scalarType()             == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:78:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       78 |   AT_ASSERTM(lyr_nrm_gamma_weights.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:78:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       78 |   AT_ASSERTM(lyr_nrm_gamma_weights.type().scalarType() == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:79:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       79 |   AT_ASSERTM(lyr_nrm_beta_weights.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                        ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:79:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       79 |   AT_ASSERTM(lyr_nrm_beta_weights.type().scalarType()  == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:80:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       80 |   AT_ASSERTM(input_weights_q.type().scalarType()       == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:80:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       80 |   AT_ASSERTM(input_weights_q.type().scalarType()       == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:81:36: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       81 |   AT_ASSERTM(input_weights_kv.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                    ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:81:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       81 |   AT_ASSERTM(input_weights_kv.type().scalarType()      == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:82:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       82 |   AT_ASSERTM(output_weights.type().scalarType()        == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                  ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:82:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       82 |   AT_ASSERTM(output_weights.type().scalarType()        == at::ScalarType::Half, \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:86:30: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m       86 |     AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Byte, \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                              ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:86:5: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m       86 |     AT_ASSERTM(pad_mask.type().scalarType()       == at::ScalarType::Byte, \"Only BYTE is supported\");\n          |     ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp: In function std::vector<at::Tensor> multihead_attn::encdec_norm_add::cublas_gemmex::bwd(int, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float):\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:147:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      147 |   AT_ASSERTM(output_grads.type().scalarType()          == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:147:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      147 |   AT_ASSERTM(output_grads.type().scalarType()          == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:148:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      148 |   AT_ASSERTM(matmul2_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:148:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      148 |   AT_ASSERTM(matmul2_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:149:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      149 |   AT_ASSERTM(dropout_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:149:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      149 |   AT_ASSERTM(dropout_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:150:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      150 |   AT_ASSERTM(softmax_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:150:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      150 |   AT_ASSERTM(softmax_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:151:39: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      151 |   AT_ASSERTM(input_lin_q_results.type().scalarType()   == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:151:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      151 |   AT_ASSERTM(input_lin_q_results.type().scalarType()   == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:152:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      152 |   AT_ASSERTM(input_lin_kv_results.type().scalarType()  == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                        ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:152:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      152 |   AT_ASSERTM(input_lin_kv_results.type().scalarType()  == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:153:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      153 |   AT_ASSERTM(lyr_nrm_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:153:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      153 |   AT_ASSERTM(lyr_nrm_results.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:154:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      154 |   AT_ASSERTM(lyr_nrm_mean.type().scalarType()          == at::ScalarType::Float, \"Only FLOAT is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:154:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      154 |   AT_ASSERTM(lyr_nrm_mean.type().scalarType()          == at::ScalarType::Float, \"Only FLOAT is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:155:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      155 |   AT_ASSERTM(lyr_nrm_invvar.type().scalarType()        == at::ScalarType::Float, \"Only FLOAT is supported\");\n\u001b[0m\u001b[91m          |                                  ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:155:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      155 |   AT_ASSERTM(lyr_nrm_invvar.type().scalarType()        == at::ScalarType::Float, \"Only FLOAT is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:156:28: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      156 |   AT_ASSERTM(inputs_q.type().scalarType()              == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                            ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:156:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      156 |   AT_ASSERTM(inputs_q.type().scalarType()              == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:157:29: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      157 |   AT_ASSERTM(inputs_kv.type().scalarType()             == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                             ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:157:3: note: in expansion of macro AT_ASSERTM\n      157 |   AT_ASSERTM(inputs_kv.type().scalarType()             == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:158:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      158 |   AT_ASSERTM(lyr_nrm_gamma_weights.type().scalarType() == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                         ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:158:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      158 |   AT_ASSERTM(lyr_nrm_gamma_weights.type().scalarType() == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:159:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      159 |   AT_ASSERTM(lyr_nrm_beta_weights.type().scalarType()  == at::ScalarType::Half,  \"Only HALF is supported\");\n          |                                        ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:159:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      159 |   AT_ASSERTM(lyr_nrm_beta_weights.type().scalarType()  == at::ScalarType::Half,  \"Only HALF is supported\");\n          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:160:35: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      160 |   AT_ASSERTM(input_weights_q.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                   ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:160:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      160 |   AT_ASSERTM(input_weights_q.type().scalarType()       == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:161:36: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n\u001b[0m\u001b[91m      161 |   AT_ASSERTM(input_weights_kv.type().scalarType()      == at::ScalarType::Half,  \"Only HALF is supported\");\n          |                                    ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:161:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      161 |   AT_ASSERTM(input_weights_kv.type().scalarType()      == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:162:34: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      162 |   AT_ASSERTM(output_weights.type().scalarType()        == at::ScalarType::Half,  \"Only HALF is supported\");\n\u001b[0m\u001b[91m          |                                  ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:162:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      162 |   AT_ASSERTM(output_weights.type().scalarType()        == at::ScalarType::Half,  \"Only HALF is supported\");\n          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n\u001b[0m\u001b[91m                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:163:32: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      163 |   AT_ASSERTM(dropout_mask.type().scalarType()          == at::ScalarType::Byte,  \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                                ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n          |                                       ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n\u001b[0m\u001b[91m          |                                ^~~~~~~~~~~~~~~~~~~~~\n    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:163:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      163 |   AT_ASSERTM(dropout_mask.type().scalarType()          == at::ScalarType::Byte,  \"Only BYTE is supported\");\n          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n\u001b[0m\u001b[91m      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Allocator.h:6,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:7,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:164:36: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n      164 |   AT_ASSERTM(dropout_add_mask.type().scalarType()      == at::ScalarType::Byte,  \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |                                    ^\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:241:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n\u001b[0m\u001b[91m      241 | #define C10_EXPAND_MSVC_WORKAROUND(x) x\n\u001b[0m\u001b[91m          |                                       ^\n    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:261:34: note: in expansion of macro C10_UNLIKELY\n\u001b[0m\u001b[91m      261 | #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n\u001b[0m\u001b[91m          |                                  ^~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:313:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n\u001b[0m\u001b[91m      313 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n\u001b[0m\u001b[91m          |       ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:599:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n\u001b[0m\u001b[91m      599 |     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n          |                                ^~~~~~~~~~~~~~~~~~~~~\n\u001b[0m\u001b[91m    apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:164:3: note: in expansion of macro AT_ASSERTM\n\u001b[0m\u001b[91m      164 |   AT_ASSERTM(dropout_add_mask.type().scalarType()      == at::ScalarType::Byte,  \"Only BYTE is supported\");\n\u001b[0m\u001b[91m          |   ^~~~~~~~~~\n\u001b[0m\u001b[91m    In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n\u001b[0m\u001b[91m                     from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n                     from apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.cpp:1:\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:194:30: note: declared here\n      194 |   DeprecatedTypeProperties & type() const {\n\u001b[0m\u001b[91m          |                              ^~~~\n\u001b[0m\u001b[91m    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add_cuda.cu -o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 -I./apex/contrib/csrc/multihead_attn/cutlass/ -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_80,code=sm_80 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fast_encdec_multihead_attn_norm_add -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n\u001b[0m\u001b[91m    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add.o build/temp.linux-x86_64-3.8/apex/contrib/csrc/multihead_attn/encdec_multihead_attn_norm_add_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/fast_encdec_multihead_attn_norm_add.cpython-38-x86_64-linux-gnu.so\n\u001b[0m\u001b[91m    running install_lib\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/fast_mask_softmax_dropout.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/fused_adam_cuda.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/fast_additive_mask_softmax_dropout.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/fused_layer_norm_cuda.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/fast_self_multihead_attn.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/fast_self_multihead_attn_bias.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/fast_encdec_multihead_attn_norm_add.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/fast_self_multihead_attn_bias_additive_mask.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/fast_self_multihead_attn_norm_add.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/contrib\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/contrib/xentropy\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/xentropy\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/xentropy\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/contrib/layer_norm\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/layer_norm/layer_norm.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/layer_norm\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/layer_norm/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/layer_norm\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/contrib/groupbn\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/groupbn\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/groupbn\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/reparameterization\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/reparameterization/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/reparameterization\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.8/dist-packages/apex/reparameterization\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.8/dist-packages/apex/reparameterization\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/_amp_state.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/frontend.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/__version__.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/wrap.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/amp.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/amp/lists\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/lists/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/amp/lists\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.8/dist-packages/apex/amp/lists\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.8/dist-packages/apex/amp/lists\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.8/dist-packages/apex/amp/lists\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/compat.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/rnn_compat.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/opt.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/_initialize.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/scaler.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/utils.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/amp/handle.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/RNN\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/RNN/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/RNN\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.8/dist-packages/apex/RNN\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/RNN/cells.py -> /usr/local/lib/python3.8/dist-packages/apex/RNN\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/RNN/models.py -> /usr/local/lib/python3.8/dist-packages/apex/RNN\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/multi_tensor_apply\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/multi_tensor_apply\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.8/dist-packages/apex/multi_tensor_apply\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/parallel\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/parallel/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/parallel/LARC.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/parallel/distributed.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/parallel/multiproc.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/optimizers/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.8/dist-packages/apex/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.8/dist-packages/apex/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.8/dist-packages/apex/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.8/dist-packages/apex/optimizers\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.8/dist-packages/apex/optimizers\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/fp16_utils\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.8/dist-packages/apex/fp16_utils\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.8/dist-packages/apex/fp16_utils\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/fp16_utils\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.8/dist-packages/apex/fp16_utils\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/pyprof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/base.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/output.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/data.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/pyprof/parse\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/parse\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/parse\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/parse\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/parse/db.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/parse\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/parse\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/parse\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/pyprof/nvtx\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/nvtx\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.8/dist-packages/apex/pyprof/nvtx\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/normalization\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/normalization/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/normalization\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.8/dist-packages/apex/normalization\n\u001b[0m\u001b[91m    creating /usr/local/lib/python3.8/dist-packages/apex/mlp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/mlp/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/mlp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex/mlp/mlp.py -> /usr/local/lib/python3.8/dist-packages/apex/mlp\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/mlp_cuda.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/syncbn.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/apex_C.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/xentropy_cuda.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/fast_encdec_multihead_attn.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    copying build/lib.linux-x86_64-3.8/amp_C.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/layer_norm/layer_norm.py to layer_norm.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/layer_norm/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/frontend.py to frontend.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/__version__.py to __version__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/wrap.py to wrap.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/amp.py to amp.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/compat.py to compat.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/opt.py to opt.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/_initialize.py to _initialize.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/scaler.py to scaler.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/utils.py to utils.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/handle.py to handle.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/RNN/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/RNN/cells.py to cells.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/RNN/models.py to models.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/LARC.py to LARC.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/distributed.py to distributed.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/optimizers/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/base.py to base.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/output.py to output.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/data.py to data.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-38.pyc\n    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-38.pyc\n    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-38.pyc\n    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/parse/db.py to db.cpython-38.pyc\n    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-38.pyc\n    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-38.pyc\n    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-38.pyc\n    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-38.pyc\n    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/normalization/__init__.py to __init__.cpython-38.pyc\n    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-38.pyc\n    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/mlp/__init__.py to __init__.cpython-38.pyc\n\u001b[0m\u001b[91m    byte-compiling /usr/local/lib/python3.8/dist-packages/apex/mlp/mlp.py to mlp.cpython-38.pyc\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/apex/mlp/mlp.py:40: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n\u001b[0m\u001b[91m      if activation is 'none':\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/apex/mlp/mlp.py:42: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n\u001b[0m\u001b[91m      elif activation is 'relu':\n\u001b[0m\u001b[91m    /usr/local/lib/python3.8/dist-packages/apex/mlp/mlp.py:44: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n\u001b[0m\u001b[91m      elif activation is 'sigmoid':\n\u001b[0m\u001b[91m    running install_egg_info\n\u001b[0m\u001b[91m    running egg_info\n\u001b[0m\u001b[91m    creating apex.egg-info\n\u001b[0m\u001b[91m    writing apex.egg-info/PKG-INFO\n\u001b[0m\u001b[91m    writing dependency_links to apex.egg-info/dependency_links.txt\n\u001b[0m\u001b[91m    writing top-level names to apex.egg-info/top_level.txt\n\u001b[0m\u001b[91m    writing manifest file 'apex.egg-info/SOURCES.txt'\n\u001b[0m\u001b[91m    reading manifest file 'apex.egg-info/SOURCES.txt'\n\u001b[0m\u001b[91m    writing manifest file 'apex.egg-info/SOURCES.txt'\n\u001b[0m\u001b[91m    Copying apex.egg-info to /usr/local/lib/python3.8/dist-packages/apex-0.1.egg-info\n\u001b[0m\u001b[91m    running install_scripts\n\u001b[0m\u001b[91m    writing list of installed files to '/tmp/pip-record-9w33r22f/install-record.txt'\n\u001b[0m    Running setup.py install for apex: finished with status 'done'\nSuccessfully installed apex-0.1\nCleaning up...\n  Removing source in /tmp/pip-req-build-40r49h1x\nRemoved build tracker: '/tmp/pip-req-tracker-2uotp2ch'\nRemoving intermediate container 4ae5bc3af807\n ---> 789974566677\nStep 12/25 : WORKDIR /build\n ---> Running in 833505c963e2\nRemoving intermediate container 833505c963e2\n ---> 65104034fe4f\nStep 13/25 : RUN git clone --branch fairseq_v2 https://github.com/ngoyal2707/Megatron-LM.git\n ---> Running in a881bdaa3238\n\u001b[91mCloning into 'Megatron-LM'...\n\u001b[0mRemoving intermediate container a881bdaa3238\n ---> e8d82d6b4046\nStep 14/25 : WORKDIR /build/Megatron-LM\n ---> Running in 35885a6b6737\nRemoving intermediate container 35885a6b6737\n ---> 810f7f3929f9\nStep 15/25 : RUN pip3 install six regex\n ---> Running in aea24b1bfa92\nCollecting six\n  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\nCollecting regex\n  Downloading regex-2022.10.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\nInstalling collected packages: six, regex\nSuccessfully installed regex-2022.10.31 six-1.16.0\nRemoving intermediate container aea24b1bfa92\n ---> f6080d0e252e\nStep 16/25 : RUN pip3 install -e .\n ---> Running in 536713fb1e54\nObtaining file:///build/Megatron-LM\nRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from megatron-lm==1.1.5) (1.24.1)\nCollecting pybind11\n  Downloading pybind11-2.10.2-py3-none-any.whl (222 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from megatron-lm==1.1.5) (2022.10.31)\nRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from megatron-lm==1.1.5) (1.16.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from megatron-lm==1.1.5) (1.10.1+cu113)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->megatron-lm==1.1.5) (4.4.0)\nInstalling collected packages: pybind11, megatron-lm\n  Running setup.py develop for megatron-lm\n\u001b[91m    ERROR: Command errored out with exit status 1:\n     command: /usr/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/build/Megatron-LM/setup.py'\"'\"'; __file__='\"'\"'/build/Megatron-LM/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\n         cwd: /build/Megatron-LM/\n    Complete output (63 lines):\n    No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n    running develop\n    running egg_info\n    writing megatron_lm.egg-info/PKG-INFO\n    writing dependency_links to megatron_lm.egg-info/dependency_links.txt\n    writing requirements to megatron_lm.egg-info/requires.txt\n    writing top-level names to megatron_lm.egg-info/top_level.txt\n    reading manifest file 'megatron_lm.egg-info/SOURCES.txt'\n    writing manifest file 'megatron_lm.egg-info/SOURCES.txt'\n    running build_ext\n    building 'megatron.fused_kernels.scaled_upper_triang_masked_softmax_cuda' extension\n    creating build\n    creating build/temp.linux-x86_64-3.8\n    creating build/temp.linux-x86_64-3.8/megatron\n    creating build/temp.linux-x86_64-3.8/megatron/fused_kernels\n    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c megatron/fused_kernels/scaled_upper_triang_masked_softmax.cpp -o build/temp.linux-x86_64-3.8/megatron/fused_kernels/scaled_upper_triang_masked_softmax.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n    /usr/lib/python3.8/distutils/extension.py:131: UserWarning: Unknown Extension options: 'extra_cflags', 'extra_cuda_cflags'\n      warnings.warn(msg)\n    /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:381: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n      warnings.warn(msg.format('we could not find ninja.'))\n    Traceback (most recent call last):\n      File \"<string>\", line 1, in <module>\n      File \"/build/Megatron-LM/setup.py\", line 83, in <module>\n        setuptools.setup(\n      File \"/usr/lib/python3/dist-packages/setuptools/__init__.py\", line 144, in setup\n        return distutils.core.setup(**attrs)\n      File \"/usr/lib/python3.8/distutils/core.py\", line 148, in setup\n        dist.run_commands()\n      File \"/usr/lib/python3.8/distutils/dist.py\", line 966, in run_commands\n        self.run_command(cmd)\n      File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\n        cmd_obj.run()\n      File \"/usr/lib/python3/dist-packages/setuptools/command/develop.py\", line 38, in run\n        self.install_for_development()\n      File \"/usr/lib/python3/dist-packages/setuptools/command/develop.py\", line 140, in install_for_development\n        self.run_command('build_ext')\n      File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\n        self.distribution.run_command(command)\n      File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\n        cmd_obj.run()\n      File \"/usr/lib/python3/dist-packages/setuptools/command/build_ext.py\", line 87, in run\n        _build_ext.run(self)\n      File \"/usr/lib/python3.8/distutils/command/build_ext.py\", line 340, in run\n        self.build_extensions()\n      File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 735, in build_extensions\n        build_ext.build_extensions(self)\n      File \"/usr/lib/python3.8/distutils/command/build_ext.py\", line 449, in build_extensions\n        self._build_extensions_serial()\n      File \"/usr/lib/python3.8/distutils/command/build_ext.py\", line 474, in _build_extensions_serial\n        self.build_extension(ext)\n      File \"/usr/lib/python3/dist-packages/setuptools/command/build_ext.py\", line 208, in build_extension\n        _build_ext.build_extension(self, ext)\n      File \"/usr/lib/python3.8/distutils/command/build_ext.py\", line 528, in build_extension\n        objects = self.compiler.compile(sources,\n      File \"/usr/lib/python3.8/distutils/ccompiler.py\", line 574, in compile\n        self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\n      File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 483, in unix_wrap_single_compile\n        cflags = unix_cuda_flags(cflags)\n      File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 450, in unix_cuda_flags\n        cflags + _get_cuda_arch_flags(cflags))\n      File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 1606, in _get_cuda_arch_flags\n        arch_list[-1] += '+PTX'\n    IndexError: list index out of range\n    ----------------------------------------\n\u001b[0m\u001b[91mERROR: Command errored out with exit status 1: /usr/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/build/Megatron-LM/setup.py'\"'\"'; __file__='\"'\"'/build/Megatron-LM/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps Check the logs for full command output.\n\u001b[0mRemoving intermediate container 536713fb1e54\n","stderr":"The command '/bin/sh -c pip3 install -e .' returned a non-zero code: 1\n"},"endTime":1672185306287}