{
  "startTime": 1674254199839,
  "endTime": 1674254201350,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 285,
        "lineEnd": 285,
        "columnStart": 19,
        "columnEnd": 94
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 353,
        "lineEnd": 353,
        "columnStart": 19,
        "columnEnd": 94
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 232,
        "lineEnd": 232,
        "columnStart": 4,
        "columnEnd": 75
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 33,
        "lineEnd": 33,
        "columnStart": 4,
        "columnEnd": 49
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 35,
        "lineEnd": 104,
        "columnStart": 4,
        "columnEnd": 16
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 33,
        "lineEnd": 33,
        "columnStart": 4,
        "columnEnd": 49
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 35,
        "lineEnd": 104,
        "columnStart": 4,
        "columnEnd": 16
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# *******************************************************************************\n# Copyright 2020-2022 Arm Limited and affiliates.\n# SPDX-License-Identifier: Apache-2.0\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# *******************************************************************************\n\n\n# ========\n# Stage 1: Base image including OS and key packages\n# ========\nARG njobs\nARG bazel_mem\nARG default_py_version=3.8\n\nFROM ubuntu:20.04 AS tensorflow-base\nARG default_py_version\nENV PY_VERSION=\"${default_py_version}\"\n\nRUN if ! [ \"$(arch)\" = \"aarch64\" ] ; then exit 1; fi\n\n#Install core OS packages\nRUN apt-get -y update && \\\n    apt-get -y --no-install-recommends install software-properties-common && \\\n    add-apt-repository ppa:ubuntu-toolchain-r/test && \\\n    apt-get -y --no-install-recommends install \\\n      accountsservice \\\n      apport \\\n      at \\\n      autoconf \\\n      automake \\\n      bc \\\n      build-essential \\\n      cmake \\\n      cpufrequtils \\\n      curl \\\n      ethtool \\\n      gcc-10 \\\n      g++-10 \\\n      gettext-base \\\n      gfortran-10 \\\n      git \\\n      iproute2 \\\n      iputils-ping \\\n      lxd \\\n      libbz2-dev \\\n      libc++-dev \\\n      libcgal-dev \\\n      libffi-dev \\\n      libfreetype6-dev \\\n      libhdf5-dev \\\n      libjpeg-dev \\\n      liblzma-dev \\\n      libncurses5-dev \\\n      libncursesw5-dev \\\n      libpng-dev \\\n      libreadline-dev \\\n      libssl-dev \\\n      libsqlite3-dev \\\n      libtool \\\n      libxml2-dev \\\n      libxslt-dev \\\n      locales \\\n      lsb-release \\\n      lvm2 \\\n      moreutils \\\n      net-tools \\\n      open-iscsi \\\n      openjdk-8-jdk \\\n      openssl \\\n      pciutils \\\n      policykit-1 \\\n      python${PY_VERSION} \\\n      python${PY_VERSION}-dev \\\n      python${PY_VERSION}-distutils \\\n      python${PY_VERSION}-venv \\\n      python3-pip \\\n      python-openssl \\\n      rsync \\\n      rsyslog \\\n      snapd \\\n      scons \\\n      ssh \\\n      sudo \\\n      swig \\\n      time \\\n      udev \\\n      unzip \\\n      ufw \\\n      uuid-runtime \\\n      vim \\\n      wget \\\n      xz-utils \\\n      zip \\\n      zlib1g-dev && rm -rf /var/lib/apt/lists/*;\n\n\n# Set default gcc, python and pip versions\nRUN update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-10 1 && \\\n    update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-10 1 && \\\n    update-alternatives --install /usr/bin/gfortran gfortran /usr/bin/gfortran-10 1 && \\\n    update-alternatives --install /usr/bin/python python /usr/bin/python3 1 && \\\n    update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1\n\n# DOCKER_USER for the Docker user\nENV DOCKER_USER=ubuntu\n\n# Setup default user\nRUN useradd --create-home -s /bin/bash -m $DOCKER_USER && echo \"$DOCKER_USER:Portland\" | chpasswd && adduser $DOCKER_USER sudo\nRUN echo '%sudo ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers\nRUN echo 'debconf debconf/frontend select Noninteractive' | debconf-set-selections\n\n# Import profile for bash\nCOPY bash_profile /home/$DOCKER_USER/.bash_profile\nRUN chown $DOCKER_USER:$DOCKER_USER /home/$DOCKER_USER/.bash_profile\nCOPY patches/welcome.txt /home/$DOCKER_USER/.\nRUN echo '[ ! -z \"$TERM\" -a -r /home/$DOCKER_USER/welcome.txt ] && cat /home/$DOCKER_USER/welcome.txt' >> /etc/bash.bashrc\n\n# ========\n# Stage 2: augment the base image with some essential libs\n# ========\nFROM tensorflow-base AS tensorflow-libs\nARG njobs\nARG cpu\nARG arch\nARG blas_cpu\nARG blas_ncores\n\nENV NP_MAKE=\"${njobs}\" \\\n    CPU=\"${cpu}\" \\\n    ARCH=\"${arch}\" \\\n    BLAS_CPU=\"${blas_cpu}\" \\\n    BLAS_NCORES=\"${blas_ncores}\"\n\n# Key version numbers\nENV OPENBLAS_VERSION=0.3.20 \\\n    YAML_VERSION=yaml-cpp-0.7.0\n\n# Package build parameters\nENV PROD_DIR=/opt \\\n    PACKAGE_DIR=packages\n\n# Make directories to hold package source & build directories (PACKAGE_DIR)\n# and install build directories (PROD_DIR).\nRUN mkdir -p $PACKAGE_DIR && \\\n    mkdir -p $PROD_DIR\n\n# Common compiler settings\nENV CC=gcc \\\n    CXX=g++ \\\n    BASE_CFLAGS=\"-mcpu=${CPU} -march=${ARCH} -O3\" \\\n    BASE_LDFLAGS=\"\"\n\n# Build OpenBLAS from source\nCOPY scripts/build-openblas.sh $PACKAGE_DIR/.\nRUN $PACKAGE_DIR/build-openblas.sh\nENV OPENBLAS_DIR=$PROD_DIR/openblas\nENV LD_LIBRARY_PATH=$OPENBLAS_DIR/lib:$LD_LIBRARY_PATH\n\n# Build and install OpenCV from GitHub sources (needed for C++ API examples)\nCOPY scripts/build-opencv.sh $PACKAGE_DIR/.\nRUN $PACKAGE_DIR/build-opencv.sh\nENV LD_LIBRARY_PATH=$PROD_DIR/opencv/install/lib:$LD_LIBRARY_PATH\n\n# Build and install yaml-cpp from Github source (needed for C++ API examples)\nCOPY scripts/build-yamlcpp.sh $PACKAGE_DIR/.\nRUN $PACKAGE_DIR/build-yamlcpp.sh\n\n# ========\n# Stage 3: install essential python dependencies into a venv\n# ========\nFROM tensorflow-libs AS tensorflow-tools\nARG njobs\nARG default_py_version\nARG cpu\nARG arch\n\nENV PY_VERSION=\"${default_py_version}\" \\\n    NP_MAKE=\"${njobs}\" \\\n    CPU=\"${cpu}\" \\\n    ARCH=\"${arch}\"\n# Key version numbers\nENV NUMPY_VERSION=1.21.5 \\\n    SCIPY_VERSION=1.7.3 \\\n    NPY_DISTUTILS_APPEND_FLAGS=1\n\n# Using venv means this can be done in userspace\nWORKDIR /home/$DOCKER_USER\nUSER $DOCKER_USER\nENV PACKAGE_DIR=/home/$DOCKER_USER/$PACKAGE_DIR\nRUN mkdir -p $PACKAGE_DIR\n\n# Setup a Python virtual environment\nENV VIRTUAL_ENV=/home/$DOCKER_USER/python3-venv\nRUN python -m venv $VIRTUAL_ENV\nENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n\n# Install Rust into user-space, needed for transformers dependencies\nRUN curl https://sh.rustup.rs -sSf | sh -s -- -y\nENV PATH=\"/home/$DOCKER_USER/.cargo/bin:${PATH}\"\n\n# Install some basic python packages\nRUN pip install --no-cache-dir --upgrade pip\nRUN pip install --no-cache-dir \"setuptools>=41.0.0\" six mock wheel cython sh\n\n# Build numpy from source, using OpenBLAS for BLAS calls\nCOPY scripts/build-numpy.sh $PACKAGE_DIR/.\nCOPY patches/site.cfg $PACKAGE_DIR/site.cfg\nRUN $PACKAGE_DIR/build-numpy.sh\n\n# Install some  basic python packages needed for SciPy\nRUN pip install --no-cache-dir pybind11 pyangbind pythran\n# Build scipy from source, using OpenBLAS for BLAS calls\nCOPY scripts/build-scipy.sh $PACKAGE_DIR/.\nCOPY patches/site.cfg $PACKAGE_DIR/site.cfg\nRUN $PACKAGE_DIR/build-scipy.sh\n\n# Install some TensorFlow essentials\n# enum34 is not compatible with Python 3.6+, and not required\n# it is installed as a dependency for an earlier package and needs\n# to be removed in order for the OpenCV build to complete.\nRUN pip uninstall enum34 -y\nRUN HDF5_DIR=/usr/lib/aarch64-linux-gnu/hdf5/serial pip --no-cache-dir install h5py==3.1.0\nRUN pip install --no-cache-dir grpcio tensorflow-io-gcs-filesystem pytest\nRUN pip install --no-cache-dir ck==1.55.5 absl-py pycocotools pillow==8.2.0\nRUN pip install --no-cache-dir transformers pandas\n\n# Install OpenCV into our venv (needed for MLCommons benchmarks)\nRUN pip install --no-cache-dir opencv-python-headless\n\nCMD [\"bash\", \"-l\"]\n\n# ========\n# Stage 4: install Bazel, and build tensorflow\n# ========\nFROM tensorflow-libs AS tensorflow-dev\nARG njobs\nARG bazel_mem\nARG enable_onednn\nARG onednn_opt\nARG tf_version\nARG default_py_version\nARG tune\nARG arch\nARG eigen_l1_cache\nARG eigen_l2_cache\nARG eigen_l3_cache\n\nENV NP_MAKE=\"${njobs}\" \\\n    BZL_RAM=\"${bazel_mem}\" \\\n    ONEDNN_BUILD=\"${onednn_opt}\" \\\n    TUNE=\"${tune}\" \\\n    ARCH=\"${arch}\" \\\n    EIGEN_L1_CACHE=\"${eigen_l1_cache}\" \\\n    EIGEN_L2_CACHE=\"${eigen_l2_cache}\" \\\n    EIGEN_L3_CACHE=\"${eigen_l3_cache}\"\n# Key version numbers\nENV PY_VERSION=\"${default_py_version}\" \\\n    TF_VERSION=\"${tf_version}\"\n# Set runtime flag to enable/disable oneDNN backend\nENV TF_ENABLE_ONEDNN_OPTS=\"${enable_onednn}\"\n\n# Use a PACKAGE_DIR in userspace\nWORKDIR /home/$DOCKER_USER\nUSER $DOCKER_USER\nENV PACKAGE_DIR=/home/$DOCKER_USER/$PACKAGE_DIR\nRUN mkdir -p $PACKAGE_DIR\n\n# Copy in the Python virtual environment\nENV VIRTUAL_ENV=/home/$DOCKER_USER/python3-venv\nCOPY --chown=$DOCKER_USER:$DOCKER_USER --from=tensorflow-tools $VIRTUAL_ENV /home/$DOCKER_USER/python3-venv\nENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n\n# Get Bazel binary for AArch64 using the latest Bazelisk release\nRUN mkdir -p $PACKAGE_DIR/bazel\nRUN bazelisk_url=$( curl -f -L -s https://api.github.com/repos/bazelbuild/bazelisk/releases/latest \\\n    | grep -o -E \"https://(.*)bazelisk-linux-arm64\") && \\\n    wget $bazelisk_url -O $PACKAGE_DIR/bazel/bazel\nRUN chmod a+x $PACKAGE_DIR/bazel/bazel\nENV PATH=\"$PACKAGE_DIR/bazel:$PATH\"\n\n# Build TensorFlow\nCOPY patches/tf_acl.patch $PACKAGE_DIR/.\nCOPY patches/compute_library.patch $PACKAGE_DIR/.\nCOPY patches/onednn_acl_threadcap.patch $PACKAGE_DIR/.\nCOPY patches/onednn_acl_pooling.patch $PACKAGE_DIR/.\nCOPY patches/onednn_acl_postops.patch $PACKAGE_DIR/.\nCOPY scripts/build-tensorflow.sh $PACKAGE_DIR/.\nRUN $PACKAGE_DIR/build-tensorflow.sh\nCOPY scripts/build-tensorflow-addons.sh $PACKAGE_DIR/.\nRUN $PACKAGE_DIR/build-tensorflow-addons.sh\n\nCMD [\"bash\", \"-l\"]\n\n# =========\n# Stage 4b: install Bazel, and build tensorflow-serving\n# =========\nFROM tensorflow-libs AS tensorflow-serving\nARG njobs\nARG bazel_mem\nARG enable_onednn\nARG onednn_opt\nARG tfserving_version\nARG default_py_version\nARG cpu\nARG arch\n\nENV NP_MAKE=\"${njobs}\" \\\n    BZL_RAM=\"${bazel_mem}\" \\\n    ONEDNN_BUILD=\"${onednn_opt}\" \\\n    CPU=\"${cpu}\" \\\n    ARCH=\"${arch}\"\n\n# Key version numbers\nENV PY_VERSION=\"${default_py_version}\" \\\n    TFSERVING_VERSION=\"${tfserving_version}\"\n# Set runtime flag to enable/disable oneDNN backend\nENV TF_ENABLE_ONEDNN_OPTS=\"${enable_onednn}\"\n\n# gRPC port\nEXPOSE 8500\n# REST port\nEXPOSE 8501\n\n# Model store within the container\nENV MODEL_BASE_PATH=/home/$DOCKER_USER/models\nRUN mkdir -p ${MODEL_BASE_PATH}\n# MODEL_NAME is updated at runtime with `docker run -e MODEL_NAME=<name> ...`\nENV MODEL_NAME=model\n\n# Use a PACKAGE_DIR in userspace\nWORKDIR /home/$DOCKER_USER\nUSER $DOCKER_USER\nENV PACKAGE_DIR=/home/$DOCKER_USER/$PACKAGE_DIR\nRUN mkdir -p $PACKAGE_DIR\n\n# Copy in the Python virtual environment\nENV VIRTUAL_ENV=/home/$DOCKER_USER/python3-venv\nCOPY --chown=$DOCKER_USER:$DOCKER_USER --from=tensorflow-tools $VIRTUAL_ENV /home/$DOCKER_USER/python3-venv\nENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n\n# Get Bazel binary for AArch64 using the latest Bazelisk release\nRUN mkdir -p $PACKAGE_DIR/bazel\nRUN bazelisk_url=$( curl -f -L -s https://api.github.com/repos/bazelbuild/bazelisk/releases/latest \\\n    | grep -o -E \"https://(.*)bazelisk-linux-arm64\") && \\\n    wget $bazelisk_url -O $PACKAGE_DIR/bazel/bazel\nRUN chmod a+x $PACKAGE_DIR/bazel/bazel\nENV PATH=\"$PACKAGE_DIR/bazel:$PATH\"\n\n# Build TensorFlow Serving\nCOPY scripts/build-tensorflow-serving.sh $PACKAGE_DIR/.\nRUN $PACKAGE_DIR/build-tensorflow-serving.sh\n\n# Setup entrypoint for passing model details through `docker run`\nCOPY scripts/tf_serving_entrypoint.sh /home/$DOCKER_USER/.\nENTRYPOINT [ \"/bin/bash\", \"-c\", \"exec /home/$DOCKER_USER/tf_serving_entrypoint.sh \\\"${@}\\\"\", \"--\" ]\n\n# ========\n# Stage 5: Install benchmarks and examples\n# ========\nFROM tensorflow-libs AS tensorflow\nARG enable_onednn\n\n# Set runtime flag to enable/disable oneDNN backend\nENV TF_ENABLE_ONEDNN_OPTS=\"${enable_onednn}\"\n\nWORKDIR /home/$DOCKER_USER\nUSER $DOCKER_USER\n\n# Copy in the Python virtual environment\nENV VIRTUAL_ENV=/home/$DOCKER_USER/python3-venv\nCOPY --chown=$DOCKER_USER:$DOCKER_USER --from=tensorflow-dev $VIRTUAL_ENV /home/$DOCKER_USER/python3-venv\nENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\nENV LD_LIBRARY_PATH=$VIRTUAL_ENV/tensorflow/lib:$LD_LIBRARY_PATH\n\n# Examples, benchmarks, and associated 'helper' scripts will be installed\n# in $EXAMPLE_DIR.\nENV EXAMPLE_DIR=/home/$DOCKER_USER/examples\nENV MLCOMMONS_DIR=$EXAMPLE_DIR/MLCommons\nRUN mkdir -p $EXAMPLE_DIR\nRUN mkdir -p $MLCOMMONS_DIR\n\n# Clone and install MLCommons (MLPerf)\nCOPY patches/optional-mlcommons-changes.patch $MLCOMMONS_DIR/optional-mlcommons-changes.patch\nCOPY patches/mlcommons_bert.patch $MLCOMMONS_DIR/mlcommons_bert.patch\nCOPY scripts/build-mlcommons.sh $MLCOMMONS_DIR/.\nRUN $MLCOMMONS_DIR/build-mlcommons.sh\nRUN rm -f $MLCOMMONS_DIR/build-mlcommons.sh\n\n# Install missing Python package dependencies required to run examples\nRUN pip install --no-cache-dir pyyaml\nRUN pip install --no-cache-dir tqdm\n\n# MLCommons ServerMode\nCOPY patches/Makefile.patch $MLCOMMONS_DIR/.\nCOPY patches/servermode.patch $MLCOMMONS_DIR/.\nCOPY scripts/build-boost.sh $MLCOMMONS_DIR/.\nCOPY scripts/build-loadgen-integration.sh $MLCOMMONS_DIR/.\n\n# Copy scripts to download dataset and models\nCOPY scripts/download-dataset.sh $MLCOMMONS_DIR/.\nCOPY scripts/download-model.sh $MLCOMMONS_DIR/.\nCOPY scripts/setup-servermode.sh $MLCOMMONS_DIR/.\n\n# Copy examples\nCOPY --chown=$DOCKER_USER:$DOCKER_USER examples $EXAMPLE_DIR\nCOPY patches/welcome_verbose.txt /home/$DOCKER_USER/welcome.txt\n\nCMD [\"bash\", \"-l\"]\n"
}