{
  "startTime": 1674216039577,
  "endTime": 1674216040192,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 11,
        "lineEnd": 11,
        "columnStart": 4,
        "columnEnd": 21
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 16,
        "lineEnd": 16,
        "columnStart": 26,
        "columnEnd": 64
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 10,
        "lineEnd": 10,
        "columnStart": 4,
        "columnEnd": 123
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 10,
        "lineEnd": 10,
        "columnStart": 4,
        "columnEnd": 123
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 10,
        "lineEnd": 10,
        "columnStart": 4,
        "columnEnd": 123
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM $USER/hadoop-base\nNAME spark\nNAME spark-client\n\n# Make the various directories needed\nRUN mkdir -p /service/runscripts/start /service/runscripts/restart /service/runscripts/test /service/runscripts/stop\n\n# Install everything. Spark needs a newer version of Numpy, so we'll need to\n# use `pip` to install it.\nRUN apt-get update && DEBIAN_FRONTEND=noninteractive apt-get --no-install-recommends --yes install build-essential git scala libgfortran3 jblas python-pip python-dev && rm -rf /var/lib/apt/lists/*;\nRUN pip install --no-cache-dir numpy\n\n# Add the binaries\nRUN wget $DOWNLOAD_URL/spark-1.1.0-bin-hadoop2.4.tgz -P /service/packages/\n# RUN wget $DOWNLOAD_URL/spark-assembly_2.10-0.9.1-hadoop2.3.0.jar -P /service/packages/\nRUN cd /service/packages; tar -xzf spark-1.1.0-bin-hadoop2.4.tgz && rm spark-1.1.0-bin-hadoop2.4.tgz\n\n# Make some symlinks\nRUN ln -s /service/packages/spark-1.1.0-bin-hadoop2.4 /service/packages/spark\nRUN ln -s /service/packages/spark/conf /service/conf/spark\n\n# Add all the scripts.\nADD ./startnode /service/sbin/\nADD ./start01.sh /service/runscripts/start/\nADD ./stop10.sh /service/runscripts/stop/\nADD ./restart01.sh /service/runscripts/restart/\nADD ./test01.sh /service/runscripts/test/\nRUN chmod a+x /service/sbin/startnode;chmod a+x /service/runscripts/start/*;chmod a+x /service/runscripts/stop/*;chmod a+x /service/runscripts/restart/*;chmod a+x /service/runscripts/test/*\n\n# Example scripts\nRUN mkdir -p /service/examples/python\nRUN mkdir -p /service/examples/data\nADD ./classification.py /service/examples/python/\nADD ./clustering.py /service/examples/python/\nADD ./filtering.py /service/examples/python/\nADD ./regression.py /service/examples/python/\nADD ./kmeans_test.data /service/examples/data/\nADD ./lpsa_test.data /service/examples/data/\nADD ./svm_test.data /service/examples/data/\nADD ./als_test.data /service/examples/data/\nADD ./tree_test.data /service/examples/data/\n\n# Environment variables\nENV SPARK_HOME /service/packages/spark\nRUN echo export SPARK_HOME=/service/packages/spark >> /etc/profile\n# ENV SPARK_JAR /service/packages/spark-assembly_2.10-0.9.1-hadoop2.3.0.jar\nENV SPARK_JAR /service/packages/spark/lib/spark-assembly-1.1.0-hadoop2.4.0.jar\n# RUN echo export SPARK_JAR=/service/packages/spark-assembly_2.10-0.9.1-hadoop2.3.0.jar >> /etc/profile\nRUN echo export SPARK_JAR=/service/packages/spark/lib/spark-assembly-1.1.0-hadoop2.4.0.jar >> /etc/profile\nRUN echo export PATH=$$PATH:$$SPARK_HOME/sbin:$$SPARK_HOME/bin >> /etc/profile\nENV SPARK_YARN_APP_JAR /service/packages/spark/examples/target/spark-examples_2.10-0.9.1-sources.jar\nRUN echo export SPARK_YARN_APP_JAR=/service/packages/spark/examples/target/spark-examples_2.10-0.9.1-sources.jar >> /etc/profile\n\n# Generate an ssh key for this image.\nRUN mkdir /home/ferry/.ssh;ssh-keygen -f /home/ferry/.ssh/id_rsa -t rsa -N '' > /dev/null\nRUN cat /home/ferry/.ssh/id_rsa.pub >> /home/ferry/.ssh/authorized_keys;echo \"StrictHostKeyChecking no\" >> /etc/ssh/ssh_config;touch /etc/mtab\nRUN chown -R ferry:ferry /home/ferry/.ssh\n\n# Remove any intermediate packages\nRUN rm /service/packages/*.tgz\nRUN rm -rf /var/cache/apt/archives/*\nRUN rm -rf /var/lib/apt/lists/*"
}