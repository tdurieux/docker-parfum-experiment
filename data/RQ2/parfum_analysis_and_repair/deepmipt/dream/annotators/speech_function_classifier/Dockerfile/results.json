{
  "startTime": 1674254421347,
  "endTime": 1674254422056,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 7,
        "lineEnd": 7,
        "columnStart": 4,
        "columnEnd": 104
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 10,
        "lineEnd": 10,
        "columnStart": 4,
        "columnEnd": 109
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 16,
        "lineEnd": 16,
        "columnStart": 4,
        "columnEnd": 35
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 4,
        "lineEnd": 4,
        "columnStart": 22,
        "columnEnd": 73
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM pytorch/pytorch:1.9.0-cuda10.2-cudnn7-runtime\n\nWORKDIR /src\n\nRUN apt-get update && apt-get install --no-install-recommends -y --allow-unauthenticated git curl && rm -rf /var/lib/apt/lists/*\n\nRUN mkdir /models && \\\n    curl -f https://files.deeppavlov.ai/alexaprize_data/speech_function_classifier.tar.gz --output arch.tgz && \\\n    tar zxfv arch.tgz && \\\n    rm -rf arch.tgz && \\\n    curl -f https://files.deeppavlov.ai/dream/speech_function_classifier/res_cor.json --output data/res_cor.json && \\\n    mv data/* /models && \\\n    rm -rf data\n\nCOPY annotators/speech_function_classifier/requirements.txt requirements.txt\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nRUN python -c \"import nltk; nltk.download('punkt')\"\nRUN python -c \"model = 'DeepPavlov/bert-base-cased-conversational';\\\nimport transformers as tfmr;tfmr.AutoTokenizer.from_pretrained(model);tfmr.AutoModel.from_pretrained(model)\"\n\nCOPY . ./\n\nARG SERVICE_NAME\nENV SERVICE_NAME ${SERVICE_NAME}\n\nARG SERVICE_PORT\nENV SERVICE_PORT ${SERVICE_PORT}\n\nCMD gunicorn --workers=1 server:app -b 0.0.0.0:${SERVICE_PORT}"
}