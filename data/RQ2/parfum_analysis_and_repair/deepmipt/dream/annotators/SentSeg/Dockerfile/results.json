{
  "startTime": 1674254098663,
  "endTime": 1674254100048,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 10,
        "lineEnd": 10,
        "columnStart": 4,
        "columnEnd": 48
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 11,
        "lineEnd": 11,
        "columnStart": 4,
        "columnEnd": 53
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 12,
        "lineEnd": 12,
        "columnStart": 4,
        "columnEnd": 68
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 18,
        "lineEnd": 18,
        "columnStart": 4,
        "columnEnd": 35
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM python:3.7.4\n\nARG DATA_URL=files.deeppavlov.ai/alexaprize_data/sentseg/elmo2.tar.gz\nARG MODEL_META_URL=files.deeppavlov.ai/alexaprize_data/sentseg/model.meta\nARG MODEL_DATA_URL=files.deeppavlov.ai/alexaprize_data/sentseg/model.data-00000-of-00001\n\nWORKDIR /src\nRUN mkdir /data\nRUN mkdir /elmo2\n\nRUN curl -f -L $DATA_URL --output /tmp/elmo2.tar.gz && tar -xf /tmp/elmo2.tar.gz -C /elmo2 && rm /tmp/elmo2.tar.gz\nRUN curl -f -L $MODEL_META_URL --output /data/model.meta\nRUN curl -f -L $MODEL_DATA_URL --output /data/model.data-00000-of-00001\n\nRUN mkdir tfhub_cache_dir\nENV TFHUB_CACHE_DIR tfhub_cache_dir\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\nRUN python -c \"import nltk; nltk.download('punkt')\"\n\nCOPY . .\nCOPY model.index /data/\n\nCMD gunicorn --workers=1 server:app\n"
}