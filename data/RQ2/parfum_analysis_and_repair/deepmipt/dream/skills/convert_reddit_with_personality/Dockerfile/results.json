{
  "startTime": 1674253837119,
  "endTime": 1674253837614,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 61
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 22,
        "lineEnd": 22,
        "columnStart": 4,
        "columnEnd": 40
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 15,
        "lineEnd": 15,
        "columnStart": 4,
        "columnEnd": 35
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM tensorflow/tensorflow:1.14.0-py3\n\n########### DOWNLOADING MODELS ###########\n\nRUN apt-get update && \\\n    apt-get install -y --no-install-recommends \\\n        curl &&\\\n    apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false && \\\n\trm -rf /var/lib/apt/lists/* && \\\n    rm -rf /root/.cache\n\nRUN mkdir -p /root/convert_data && \\\n    DATA_URL=http://files.deeppavlov.ai/alexaprize_data/convert_reddit.tar.gz && \\\n    curl -f $DATA_URL > /root/convert_data/convert_reddit.tar.gz && \\\n    cd /root/convert_data/ && \\\n    tar -xvzf convert_reddit.tar.gz && rm convert_reddit.tar.gz\n\n########## MODELS ###########\n\nRUN mkdir /app\n\nCOPY requirements.txt /app/requirements.txt\nRUN pip install --no-cache-dir -r /app/requirements.txt\n\nENV LC_ALL C.UTF-8\nENV LANG C.UTF-8\nENV MODEL_PATH /root/convert_data/convert\nENV DATABASE_PATH /root/convert_data/replies.pkl\nENV CONFIDENCE_PATH /root/convert_data/confidences.npy\nENV PYTHONPATH /usr/local/bin/python\nENV DEVICE cpu\n\nCOPY . /app/\nWORKDIR /app\n\nCMD gunicorn --workers=2 server:app --timeout 120\n"
}