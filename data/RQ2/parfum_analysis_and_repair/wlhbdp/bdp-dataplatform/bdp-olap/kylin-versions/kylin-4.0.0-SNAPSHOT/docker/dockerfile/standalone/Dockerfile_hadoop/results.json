{
  "startTime": 1674253347029,
  "endTime": 1674253348299,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 59,
        "lineEnd": 59,
        "columnStart": 4,
        "columnEnd": 49
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 63,
        "lineEnd": 63,
        "columnStart": 4,
        "columnEnd": 260
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 43,
        "lineEnd": 43,
        "columnStart": 4,
        "columnEnd": 108
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 50,
        "lineEnd": 50,
        "columnStart": 7,
        "columnEnd": 81
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 60,
        "lineEnd": 60,
        "columnStart": 7,
        "columnEnd": 28
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# Docker image with Hadoop/Spark/Hive/ZK/Kafka installed\nFROM centos:7.9.2009\n\nENV HIVE_VERSION 1.2.1\nENV HADOOP_VERSION 2.8.5\nENV SPARK_VERSION 2.4.7\nENV ZK_VERSION 3.4.6\nENV KAFKA_VERSION 1.1.1\n\nENV JAVA_HOME /home/admin/jdk1.8.0_141\nENV MVN_HOME /home/admin/apache-maven-3.6.1\nENV HADOOP_HOME /home/admin/hadoop-$HADOOP_VERSION\nENV HIVE_HOME /home/admin/apache-hive-$HIVE_VERSION-bin\nENV HADOOP_CONF $HADOOP_HOME/etc/hadoop\nENV HADOOP_CONF_DIR $HADOOP_HOME/etc/hadoop\nENV SPARK_HOME /home/admin/spark-$SPARK_VERSION-bin-hadoop2.7\nENV SPARK_CONF_DIR $SPARK_HOME/conf\nENV ZK_HOME /home/admin/zookeeper-$ZK_VERSION\nENV KAFKA_HOME /home/admin/kafka_2.11-$KAFKA_VERSION\nENV PATH $PATH:$JAVA_HOME/bin:$ZK_HOME/bin:$HADOOP_HOME/bin:$HIVE_HOME/bin:$MVN_HOME/bin:$KAFKA_HOME/bin\n\nUSER root\n\nWORKDIR /home/admin\n\n# install tools\nRUN yum -y install lsof.x86_64 wget.x86_64 tar.x86_64 git.x86_64 which.x86_64 net-tools.x86_64 unzip.x86_64 && rm -rf /var/cache/yum\n\n#install mysql\nRUN wget https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm \\\n    && rpm -Uvh mysql80-community-release-el7-3.noarch.rpm \\\n    && yum-config-manager --disable mysql80-community \\\n    && yum-config-manager --enable mysql57-community \\\n    && yum install -y mysql-community-server.x86_64 mysql-community-client.x86_64 && rm -rf /var/cache/yum\n\n# install mvn\nRUN wget https://archive.apache.org/dist/maven/maven-3/3.6.1/binaries/apache-maven-3.6.1-bin.tar.gz \\\n    && tar -zxvf apache-maven-3.6.1-bin.tar.gz \\\n    && rm -f apache-maven-3.6.1-bin.tar.gz\nCOPY conf/maven/settings.xml $MVN_HOME/conf/settings.xml\n\n# install npm\nRUN curl -f -sL https://rpm.nodesource.com/setup_8.x | bash - \\\n    && yum install -y nodejs && rm -rf /var/cache/yum\n\n# setup jdk\nRUN wget --no-cookies --no-check-certificate --header \"Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\" \"https://download.oracle.com/otn-pub/java/jdk/8u141-b15/336fa29ff2bb4ef291e347e091f7f4a7/jdk-8u141-linux-x64.tar.gz\" \\\n    && tar -zxvf /home/admin/jdk-8u141-linux-x64.tar.gz \\\n    && rm -f /home/admin/jdk-8u141-linux-x64.tar.gz\n\n# setup hadoop\nRUN wget https://archive.apache.org/dist/hadoop/core/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz \\\n    && tar -zxvf /home/admin/hadoop-$HADOOP_VERSION.tar.gz \\\n    && rm -f /home/admin/hadoop-$HADOOP_VERSION.tar.gz \\\n    && mkdir -p /data/hadoop\nCOPY conf/hadoop/* $HADOOP_CONF/\n\n# setup hive\nRUN wget https://archive.apache.org/dist/hive/hive-$HIVE_VERSION/apache-hive-$HIVE_VERSION-bin.tar.gz \\\n    && tar -zxvf /home/admin/apache-hive-$HIVE_VERSION-bin.tar.gz \\\n    && rm -f /home/admin/apache-hive-$HIVE_VERSION-bin.tar.gz \\\n    && wget -P $HIVE_HOME/lib https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.24/mysql-connector-java-5.1.24.jar\nCOPY conf/hive/hive-site.xml $HIVE_HOME/conf\nCOPY conf/hive/hive-site.xml $HADOOP_CONF/\n\n# setup spark\nRUN wget https://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop2.7.tgz \\\n    && tar -zxvf /home/admin/spark-$SPARK_VERSION-bin-hadoop2.7.tgz \\\n    && rm -f /home/admin/spark-$SPARK_VERSION-bin-hadoop2.7.tgz \\\n    && cp $HIVE_HOME/conf/hive-site.xml $SPARK_HOME/conf \\\n    && cp $SPARK_HOME/yarn/*.jar $HADOOP_HOME/share/hadoop/yarn/lib\nRUN cp $HIVE_HOME/lib/mysql-connector-java-5.1.24.jar $SPARK_HOME/jars\nRUN cp $HIVE_HOME/hcatalog/share/hcatalog/hive-hcatalog-core-1.2.1.jar $SPARK_HOME/jars/\nCOPY conf/spark/* $SPARK_CONF_DIR/\n\n# setup kafka\nRUN wget https://archive.apache.org/dist/kafka/$KAFKA_VERSION/kafka_2.11-$KAFKA_VERSION.tgz \\\n    && tar -zxvf /home/admin/kafka_2.11-$KAFKA_VERSION.tgz \\\n    && rm -f /home/admin/kafka_2.11-$KAFKA_VERSION.tgz\n\n# setup zk\nRUN wget https://archive.apache.org/dist/zookeeper/zookeeper-$ZK_VERSION/zookeeper-$ZK_VERSION.tar.gz \\\n    && tar -zxvf /home/admin/zookeeper-$ZK_VERSION.tar.gz \\\n    && rm -f /home/admin/zookeeper-$ZK_VERSION.tar.gz \\\n    && mkdir -p /data/zookeeper\nCOPY conf/zk/zoo.cfg $ZK_HOME/conf\n"
}