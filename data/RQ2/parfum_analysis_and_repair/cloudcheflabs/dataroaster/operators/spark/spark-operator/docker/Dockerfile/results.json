{
  "startTime": 1674220640318,
  "endTime": 1674220641097,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 20,
        "lineEnd": 20,
        "columnStart": 4,
        "columnEnd": 134
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 33,
        "lineEnd": 33,
        "columnStart": 4,
        "columnEnd": 99
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 4,
        "lineEnd": 4,
        "columnStart": 4,
        "columnEnd": 74
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 11,
        "lineEnd": 11,
        "columnStart": 4,
        "columnEnd": 57
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 44,
        "lineEnd": 44,
        "columnStart": 4,
        "columnEnd": 24
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 54,
        "lineEnd": 54,
        "columnStart": 4,
        "columnEnd": 27
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM centos:7\n\nENV LANG='en_US.UTF-8' LANGUAGE='en_US:en' LC_ALL='en_US.UTF-8'\n\nRUN yum install -y tzdata openssl curl ca-certificates fontconfig gzip tar \\\n    && yum update -y; rm -rf /var/cache/yum yum clean all\n\n\n# install jdk.\n\nRUN set -eux; \\\n    yum install java-11-openjdk java-11-openjdk-devel -y; rm -rf /var/cache/yum\n\n# install spark.\nARG SPARK_VERSION\nENV SPARK_BASE /opt/spark\nENV SPARK_HOME ${SPARK_BASE}/spark-$SPARK_VERSION\nRUN set -eux; \\\n    mkdir -p ${SPARK_BASE}; \\\n    cd ${SPARK_BASE}; \\\n    curl -f -L -O https://github.com/cloudcheflabs/spark/releases/download/v${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-custom-spark.tgz; \\\n    tar zxvf spark-${SPARK_VERSION}-bin-custom-spark.tgz; \\\n    mv spark-${SPARK_VERSION}-bin-custom-spark spark-${SPARK_VERSION}; \\\n    rm -rf spark-${SPARK_VERSION}*.tgz;\n\n# export spark bin to PATH.\nENV PATH=\"$PATH:$SPARK_HOME/bin\"\n\n# install maven.\nENV MAVEN_HOME /opt/maven\nRUN set -eux; \\\n    mkdir -p ${MAVEN_HOME}; \\\n    cd ${MAVEN_HOME}; \\\n    curl -f -L -O https://dlcdn.apache.org/maven/maven-3/3.8.6/binaries/apache-maven-3.8.6-bin.tar.gz; \\\n    tar zxvf apache-maven-3.8.6-bin.tar.gz; \\\n    cp -R apache-maven-3.8.6/* .; \\\n    rm -rf apache-maven-3.8.6 apache-maven-3.8.6-bin.tar.gz;\n\n# export maven home to path.\nENV PATH=\"$PATH:$MAVEN_HOME/bin\"\n\n\n# install mc.\nRUN set -eux; \\\n    yum install wget -y; rm -rf /var/cache/yum \\\n    wget https://dl.min.io/client/mc/release/linux-amd64/mc; \\\n    cp mc /usr/local/bin; \\\n    chmod +x /usr/local/bin/mc;\n\n\n# add kubernetes repo.\nADD kubernetes.repo /etc/yum.repos.d\n\n# install kubectl.\nRUN yum install kubectl -y; rm -rf /var/cache/yum\n\n# install spark operator.\nENV SPARK_OPERATOR_HOME /opt/spark-operator\nENV SPARK_OPERATOR_USER spark_operator\n\nRUN useradd -ms /bin/bash -d ${SPARK_OPERATOR_HOME} ${SPARK_OPERATOR_USER}\n\n# add pom.xml to download spark deps jars.\nADD pom.xml ${SPARK_OPERATOR_HOME}\n\n# add spark operator jar.\nARG SPARK_OPERATOR_JAR\nADD ${SPARK_OPERATOR_JAR} ${SPARK_OPERATOR_HOME}\n\n# add spark run shell.\nADD run-spark-operator.sh ${SPARK_OPERATOR_HOME}\n\n# add permissions.\nRUN chmod +x ${SPARK_OPERATOR_HOME}/run-spark-operator.sh\nRUN chown ${SPARK_OPERATOR_USER}: -R ${SPARK_OPERATOR_HOME}\n\n# change work directory.\nUSER ${SPARK_OPERATOR_USER}\nWORKDIR ${SPARK_OPERATOR_HOME}\n\n# download dependency jars to run spark job.\nRUN mvn -e clean install;\n\n# make kubeconfig directory.\nRUN mkdir -p ${SPARK_OPERATOR_HOME}/.kube\n"
}