{
  "startTime": 1674215969277,
  "endTime": 1674215971217,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 68,
        "lineEnd": 68,
        "columnStart": 4,
        "columnEnd": 55
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 171,
        "lineEnd": 171,
        "columnStart": 4,
        "columnEnd": 55
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 69,
        "lineEnd": 69,
        "columnStart": 22,
        "columnEnd": 61
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 172,
        "lineEnd": 172,
        "columnStart": 22,
        "columnEnd": 61
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM nvidia/cuda:10.1-cudnn7-devel AS ngraph\nRUN apt-get update -y && \\\n    apt-get install -y --no-install-recommends \\\n    build-essential \\\n    cmake \\\n    clang-3.9 \\\n    git \\\n    curl \\\n    zlib1g \\\n    zlib1g-dev \\\n    libtinfo-dev \\\n    unzip \\\n    autoconf \\\n    automake \\\n    libtool \\\n    python3-dev \\\n    python3-pip \\\n    python3-wheel \\\n    python3-setuptools && \\\n    rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\n# nGraph build, referenced ngraph-onnx/BUILDING.md\n# NOTE(disktnk): should use 'DPYTHON_EXECUTABLE' (currently not supported)\n# NOTE(disktnk): failed with '-DNGRAPH_GPU_ENABLE=TRUE', stop using CUDA enabled\n# NOTE(disktnk): cannot build python bind with multiprocess\nRUN ln -s /usr/bin/python3 /usr/bin/python\nARG NGRAPH_VERSION=\"0.21.0\"\nRUN git clone https://github.com/NervanaSystems/ngraph.git -b v${NGRAPH_VERSION} && \\\n    mkdir ngraph/build && cd ngraph/build && \\\n    cmake .. \\\n        -DCMAKE_INSTALL_PREFIX=$HOME/ngraph_dist \\\n        -DNGRAPH_ONNX_IMPORT_ENABLE=TRUE \\\n        -DNGRAPH_USE_PREBUILT_LLVM=TRUE \\\n        -DNGRAPH_INTELGPU_ENABLE=TRUE \\\n        -DNGRAPH_GPU_ENABLE=FALSE \\\n        -DNGRAPH_UNIT_TEST_ENABLE=FALSE \\\n    && \\\n    make -j1 && \\\n    make install && \\\n    cd .. && rm -rf build\nRUN cd ngraph/python && sed -e \"s/^distutils.ccompiler.CCompiler.compile/# &/\" setup.py > setup_.py\nRUN cd ngraph/python && \\\n    git clone --recursive https://github.com/jagerman/pybind11.git && \\\n    export PYBIND_HEADERS_PATH=$PWD/pybind11 && \\\n    export NGRAPH_CPP_BUILD_PATH=$HOME/ngraph_dist && \\\n    export NGRAPH_ONNX_IMPORT_ENABLE=TRUE && \\\n    python3 -m pip install --user numpy && \\\n    python3 setup_.py bdist_wheel && \\\n    python3 -m pip install --user -U dist/*.whl && rm -rf build\nARG NGRAPH_ONNX_VERSION=\"0.21.0\"\nRUN cd ngraph && \\\n    git clone https://github.com/NervanaSystems/ngraph-onnx.git -b v${NGRAPH_ONNX_VERSION} && \\\n    cd ngraph-onnx && \\\n    python3 -m pip install --user -r requirements.txt && \\\n    python3 -m pip install --user -r requirements_test.txt && \\\n    python3 -m pip install --user .\n\nFROM nvidia/cuda:10.1-cudnn7-devel AS tvm\n# TVM Build, referenced Dockerfile.demo_gpu\n# NOTE(disktnk): official installer does not copy header file\nARG TVM_VERSION=\"0.5\"\nRUN apt-get update -y && \\\n    apt-get install -y --no-install-recommends wget && \\\n    rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN wget https://raw.githubusercontent.com/dmlc/tvm/v${TVM_VERSION}/docker/install/ubuntu_install_core.sh -P /install && \\\n    bash /install/ubuntu_install_core.sh && \\\n    rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN echo deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-6.0 main \\\n    >> /etc/apt/sources.list.d/llvm.list && \\\n    wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add - && \\\n    apt-get update && apt-get install --no-install-recommends -y --force-yes llvm-6.0 && \\\n    rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\n# based https://raw.githubusercontent.com/dmlc/tvm/v${TVM_VERSION}/docker/install/install_tvm_gpu.sh\nRUN cd /usr && \\\n    git clone https://github.com/dmlc/tvm --recursive -b v${TVM_VERSION} && \\\n    cd /usr/tvm && \\\n    echo set\\(USE_LLVM llvm-config-6.0\\) >> config.cmake && \\\n    echo set\\(USE_CUDA ON\\) >> config.cmake && \\\n    echo set\\(USE_CUDNN ON\\) >> config.cmake && \\\n    echo set\\(USE_RPC ON\\) >> config.cmake && \\\n    echo set\\(USE_SORT ON\\) >> config.cmake && \\\n    echo set\\(USE_GRAPH_RUNTIME ON\\) >> config.cmake && \\\n    echo set\\(USE_BLAS openblas\\) >> config.cmake && \\\n    echo set\\(INSTALL_DEV ON\\) >> config.cmake && \\\n    mkdir -p build && cd build && \\\n    cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/tvm_dist && \\\n    make -j10 && make install && \\\n    cd .. && rm -rf build\nRUN mkdir -p /usr/tvm/3rdparty/dmlc-core/build && \\\n    cd /usr/tvm/3rdparty/dmlc-core/build && \\\n    cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/dmlc_core_dist && \\\n    make && make install\nRUN mkdir -p /usr/tvm/3rdparty/dlpack/build && \\\n    cd /usr/tvm/3rdparty/dlpack/build && \\\n    cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/dlpack_dist && \\\n    make && make install\nRUN apt-get update -y && \\\n    apt-get install -y --no-install-recommends \\\n    python3-dev \\\n    python3-pip \\\n    python3-setuptools && \\\n    rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\n# hot fix to enable topi module\nRUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1\nENV LD_LIBRARY_PATH=/root/tvm_dist/lib:/usr/local/cuda/lib64:/usr/local/cuda/lib64/stubs:$LD_LIBRARY_PATH\nRUN cd /usr/tvm/python && python3 setup.py install --user && \\\n    cd ../topi/python && python3 setup.py install --user && \\\n    cd ../../nnvm/python && python3 setup.py install --user\n\nFROM ubuntu:18.04 AS dldt\n# TODO(hamaji): Use the official repository again once the\n# ShuffleNet units issue is fixed. See:\n# https://github.com/opencv/dldt/pull/193\nARG DLDT_VERSION=\"fuse-split-fix\"\nRUN apt-get update -y && \\\n    apt-get install -y --no-install-recommends \\\n    python3-dev \\\n    python3-pip \\\n    python3-wheel \\\n    python3-setuptools \\\n    git \\\n    wget \\\n    sudo && \\\n    rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN mkdir neo && cd neo && \\\n    wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-gmmlib_18.4.1_amd64.deb && \\\n    wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-core_18.50.1270_amd64.deb && \\\n    wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-opencl_18.50.1270_amd64.deb && \\\n    wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-opencl_19.04.12237_amd64.deb && \\\n    wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-ocloc_19.04.12237_amd64.deb &&\\\n    sudo dpkg -i *.deb\nRUN python3 -m pip install cython\nRUN git clone https://github.com/shinh/dldt.git --recursive -b ${DLDT_VERSION} && \\\n    cd dldt/inference-engine && \\\n    bash install_dependencies.sh && \\\n    rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/* && \\\n    mkdir build && cd build && \\\n    cmake .. \\\n        -DCMAKE_INSTALL_PREFIX=$HOME/dldt_dist \\\n        -DCMAKE_BUILD_TYPE=Release \\\n        -DGEMM=OPENBLAS \\\n        -DPYTHON_EXECUTABLE=$(which python3) \\\n        -DENABLE_PYTHON=ON \\\n    && \\\n    make -j4 && make install && \\\n    cd .. && rm -rf build\nRUN cd dldt/model-optimizer && python3 -m pip install --user -r requirements_onnx.txt\n\nFROM nvidia/cuda:10.1-cudnn7-devel AS ci-base\nENV DEBIAN_FRONTEND=noninteractive\nRUN apt-get update -y && \\\n    apt-get install -y --no-install-recommends \\\n    python3-dev \\\n    python3-pip \\\n    python3-wheel \\\n    python3-setuptools \\\n    git \\\n    cmake \\\n    libblas3 \\\n    libblas-dev \\\n    libopenblas-dev \\\n    curl \\\n    wget \\\n    unzip \\\n    sudo \\\n    ninja-build \\\n    libopencv-dev \\\n    libnvinfer-dev \\\n    libnvonnxparsers-dev && \\\n    rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN echo deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-6.0 main \\\n    >> /etc/apt/sources.list.d/llvm.list && \\\n    wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add - && \\\n    apt-get update && apt-get install --no-install-recommends -y --force-yes llvm-6.0 && \\\n    rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nCOPY --from=ngraph /root/ngraph_dist /root/ngraph_dist\nCOPY --from=ngraph /root/.local /root/.local\nCOPY --from=tvm /root/tvm_dist /root/tvm_dist\nCOPY --from=tvm /root/dmlc_core_dist /root/dmlc_core_dist\nCOPY --from=tvm /root/dlpack_dist /root/dlpack_dist\nCOPY --from=tvm /root/.local /root/.local\nRUN mkdir neo && cd neo && \\\n    wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-gmmlib_18.4.1_amd64.deb && \\\n    wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-core_18.50.1270_amd64.deb && \\\n    wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-opencl_18.50.1270_amd64.deb && \\\n    wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-opencl_19.04.12237_amd64.deb && \\\n    wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-ocloc_19.04.12237_amd64.deb &&\\\n    sudo dpkg -i *.deb\nCOPY --from=dldt /root/dldt_dist /root/dldt_dist\nCOPY --from=dldt /dldt/inference-engine/include /root/dldt/inference-engine/include\nCOPY --from=dldt /dldt/inference-engine/bin/intel64/Release/lib /root/dldt/inference-engine/bin/intel64/Release/lib\nCOPY --from=dldt /root/.local /root/.local\nCOPY --from=dldt /dldt/model-optimizer /root/dldt/model-optimizer\nRUN python3 -m pip install --user decorator attrs\nENV PATH=/usr/local/cuda/bin:/root/.local/bin:${PATH}\nENV LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/lib64/stubs:${LD_LIBRARY_PATH}\n\nFROM ci-base AS dev-base\nRUN git clone --recursive https://github.com/pfnet-research/chainer-compiler.git\nRUN python3 -m pip install --user gast==0.3.2 packaging\nRUN export CHAINER_VERSION=$(python3 -c \"import imp;print(imp.load_source('_version','chainer-compiler/third_party/chainer/chainer/_version.py').__version__)\") && \\\n    python3 -m pip install --user cupy-cuda101==$CHAINER_VERSION\nRUN CHAINER_BUILD_CHAINERX=1 CHAINERX_BUILD_CUDA=1 MAKEFLAGS=-j8 \\\n    CHAINERX_NVCC_GENERATE_CODE=arch=compute_70,code=sm_70 \\\n    python3 -m pip install --user chainer-compiler/third_party/chainer[test]\nRUN python3 -m pip install --user 'pytest<5.0.0' 'chainercv>=0.11.0' onnxruntime==0.4.0\nRUN mkdir -p chainer-compiler/build && \\\n    cd chainer-compiler/build && \\\n    cmake .. \\\n        -DCHAINER_COMPILER_ENABLE_CUDA=ON \\\n        -DCHAINER_COMPILER_ENABLE_CUDNN=ON \\\n        -DCHAINER_COMPILER_ENABLE_OPENCV=ON \\\n        -DCHAINER_COMPILER_ENABLE_PYTHON=ON \\\n        -DCHAINER_COMPILER_ENABLE_TVM=ON \\\n        -DCHAINER_COMPILER_TVM_DIR=$HOME/tvm_dist \\\n        -DCHAINER_COMPILER_TVM_INCLUDE_DIRS=\"/root/tvm_dist/include;/root/dmlc_core_dist/include;/root/dlpack/include;/root/tvm_dist/include/HalideIR\" \\\n        -DCHAINER_COMPILER_NGRAPH_DIR=$HOME/ngraph_dist \\\n        -DCHAINER_COMPILER_DLDT_DIR=$HOME/dldt \\\n        -DPYTHON_EXECUTABLE=$(which python3) \\\n        -DCHAINERX_BUILD_CUDA=ON \\\n        -DCHAINERX_BUILD_PYTHON=ON \\\n        -DCHAINER_COMPILER_PREBUILT_CHAINERX_DIR=$(pip3 show chainer | awk '/^Location: / {print $2}')/chainerx \\\n        && \\\n    make -j8\n# NOTE(disktnk): to run tvm module, required libcuda.so.1\n# $ ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1\n\nFROM dev-base\nLABEL author=\"Daisuke Tanaka <duaipp@gmail.com>\"\n# Optional packages.\nRUN apt-get update -y && \\\n    apt-get install -y --no-install-recommends \\\n    less \\\n    lv \\\n    screen \\\n    vim \\\n    zsh \\\n    && \\\n    rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\n"
}