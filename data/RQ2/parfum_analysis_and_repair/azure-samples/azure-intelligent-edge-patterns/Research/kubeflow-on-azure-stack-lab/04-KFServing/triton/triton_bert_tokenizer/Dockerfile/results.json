{
  "startTime": 1674249471133,
  "endTime": 1674249472440,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 9,
        "lineEnd": 9,
        "columnStart": 4,
        "columnEnd": 25
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 11,
        "lineEnd": 11,
        "columnStart": 4,
        "columnEnd": 70
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 20
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 10,
        "lineEnd": 10,
        "columnStart": 122,
        "columnEnd": 165
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 5,
        "lineEnd": 5,
        "columnStart": 5,
        "columnEnd": 28
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "#\n# See the original for the latest version: https://github.com/kubeflow/kfserving/tree/master/docs/samples\n#\nFROM python:3.7-slim\nRUN apt-get update \\\n  && apt-get install --no-install-recommends -y wget \\\n  && rm -rf /var/lib/apt/lists/*\nCOPY bert_transformer bert_transformer/bert_transformer\nCOPY setup.py bert_transformer/setup.py\nRUN pip install --no-cache-dir kfserving\nRUN wget https://github.com/triton-inference-server/server/releases/download/v1.11.0/v1.11.0_ubuntu1604.clients.tar.gz && tar -xvzf v1.11.0_ubuntu1604.clients.tar.gz && rm v1.11.0_ubuntu1604.clients.tar.gz\nRUN pip install --no-cache-dir python/tensorrtserver-1.11.0-py3-none-linux_x86_64.whl\nWORKDIR bert_transformer\nRUN pip install --no-cache-dir -e .\nENTRYPOINT [\"python\", \"-m\", \"bert_transformer\"]\n"
}