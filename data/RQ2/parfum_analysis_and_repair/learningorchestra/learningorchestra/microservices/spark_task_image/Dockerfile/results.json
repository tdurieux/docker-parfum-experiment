{
  "startTime": 1674252841621,
  "endTime": 1674252842217,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 19,
        "lineEnd": 19,
        "columnStart": 4,
        "columnEnd": 121
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 22,
        "lineEnd": 22,
        "columnStart": 4,
        "columnEnd": 39
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 3,
        "lineEnd": 3,
        "columnStart": 4,
        "columnEnd": 128
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 10,
        "lineEnd": 10,
        "columnStart": 4,
        "columnEnd": 69
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM python:3.7\n\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y apt-transport-https ca-certificates wget dirmngr gnupg software-properties-common && rm -rf /var/lib/apt/lists/*;\n\nRUN wget -qO - https://adoptopenjdk.jfrog.io/adoptopenjdk/api/gpg/key/public | apt-key add -\n\nRUN add-apt-repository --yes https://adoptopenjdk.jfrog.io/adoptopenjdk/deb/\n\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y adoptopenjdk-8-hotspot && rm -rf /var/lib/apt/lists/*;\n\nENV SPARK_VERSION 2.4.7\nENV SPARK_INSTALL /usr/local\nENV SPARK_HOME $SPARK_INSTALL/spark\nENV HADOOP_VERSION 2.7\nENV PYSPARK_PYTHON python3\nENV PYSPARK_DRIVER_PYTHON python3\n\nRUN curl -f -s https://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz | tar -xz -C $SPARK_INSTALL && \\\n    cd $SPARK_INSTALL && ln -s spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION spark\n\nRUN pip install --no-cache-dir pyspark==$SPARK_VERSION\n\nRUN apt-get autoremove && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*\n"
}