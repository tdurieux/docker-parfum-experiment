{
  "startTime": 1674253631016,
  "endTime": 1674253631750,
  "originalSmells": [
    {
      "rule": "yarnCacheCleanAfterInstall",
      "position": {
        "lineStart": 21,
        "lineEnd": 21,
        "columnStart": 4,
        "columnEnd": 16
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM openjdk:11-jre-slim-stretch as server\n\nARG SPARK_VERSION=3.2.1\n\nWORKDIR /home/app/\nCOPY server/ ./server/\n\nWORKDIR /home/app/server/\nRUN ./gradlew build -PSPARK_VERSION=${SPARK_VERSION}\n\nFROM node:lts-alpine3.14 as frontend\n\nARG SPARK_VERSION=3.2.1\n\nENV REACT_APP_API_BASE_URL='/lighter'\n\nWORKDIR /home/app/\nCOPY frontend/ ./frontend/\nRUN wget \"https://downloads.apache.org/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop3.2.tgz\" -O - | tar -xz\n\nWORKDIR /home/app/frontend/\nRUN yarn install && yarn build && yarn cache clean;\n\nFROM openjdk:11-jre-slim-stretch\n\nARG SPARK_VERSION=3.2.1\n\nENV FRONTEND_PATH=/home/app/frontend/\nENV SPARK_HOME=/home/app/spark/\n\n# Add symlinks so that after deployment of CM configs symlinks are still in tact\nRUN ln -s /etc/hadoop/conf.cloudera.yarn /etc/alternatives/hadoop-conf \\\n  && ln -s /etc/hive/conf.cloudera.hive /etc/alternatives/hive-conf\n\nWORKDIR /home/app/\nCOPY --from=server /home/app/server/build/docker/main/layers/libs /home/app/libs\nCOPY --from=server /home/app/server/build/docker/main/layers/resources /home/app/resources\nCOPY --from=server /home/app/server/build/docker/main/layers/application.jar /home/app/application.jar\n\nCOPY --from=frontend /home/app/frontend/build/ ./frontend/\nCOPY --from=frontend /home/app/spark-${SPARK_VERSION}-bin-hadoop3.2/ ./spark/\n\nCOPY k8s/ ./k8s/\n\nEXPOSE 8080\nEXPOSE 25333\n\nENTRYPOINT [\"java\", \"-jar\", \"/home/app/application.jar\"]\n"
}