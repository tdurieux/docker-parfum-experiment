{
  "startTime": 1674250186827,
  "endTime": 1674250187855,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 18,
        "lineEnd": 18,
        "columnStart": 4,
        "columnEnd": 125
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 20,
        "lineEnd": 20,
        "columnStart": 4,
        "columnEnd": 93
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 22,
        "lineEnd": 22,
        "columnStart": 4,
        "columnEnd": 115
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 23,
        "lineEnd": 23,
        "columnStart": 4,
        "columnEnd": 122
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 24,
        "lineEnd": 24,
        "columnStart": 4,
        "columnEnd": 120
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 25,
        "lineEnd": 25,
        "columnStart": 4,
        "columnEnd": 138
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 26,
        "lineEnd": 26,
        "columnStart": 4,
        "columnEnd": 123
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 27,
        "lineEnd": 27,
        "columnStart": 4,
        "columnEnd": 116
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 28,
        "lineEnd": 28,
        "columnStart": 4,
        "columnEnd": 130
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 16,
        "lineEnd": 16,
        "columnStart": 4,
        "columnEnd": 57
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM centos:7.3.1611\n\nARG sm_version=2.6.1.1736\nARG dbaas_build=1.0.924\nARG spark_version=2.1.1\nARG hadoop_version=2.6\nARG cdh_version=5.8.3\n\nENV SPARK_VERSION=$spark_version\nENV HADOOP_VERSION=$hadoop_version\nENV SPARK_HOME=/usr/local/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION\nENV JAVA_HOME=/usr/local/jdk1.8.0_121\nENV PATH=$JAVA_HOME/bin:$SPARK_HOME/bin:$PATH\nENV MESOS_NATIVE_JAVA_LIBRARY=/usr/local/libmesos-bundle/lib/libmesos.so\nENV LD_LIBRARY_PATH=/usr/local/libmesos-bundle/lib:/native:/usr/local/lib:$LD_LIBRARY_PATH\n\nRUN yum install -y bind-utils net-tools which nc jq unzip && rm -rf /var/cache/yum\n\nRUN curl -f -kLs \"https://s3.amazonaws.com/splicemachine/$sm_version-$dbaas_build/artifacts/hadoop-2.6.0-cdh$cdh_version.tar.gz\" | tar -xz\nRUN ln -s /hadoop-2.6.0-cdh$cdh_version /hadoop\nRUN curl -f -kLs \"https://s3.amazonaws.com/splicemachine/artifacts/cdh${cdh_version}-native.tgz\" | tar -xz\nRUN chown -R root:root /native\nRUN curl -f -kLs \"https://s3.amazonaws.com/splicemachine/artifacts/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz\" | tar -xz -C /usr/local\nRUN curl -f -kLso $SPARK_HOME/jars/shiro-core-1.2.3.jar https://s3.amazonaws.com/splicemachine/artifacts/shiro-core-1.2.3.jar\nRUN curl -f -kLso $SPARK_HOME/jars/shiro-web-1.2.3.jar https://s3.amazonaws.com/splicemachine/artifacts/shiro-web-1.2.3.jar\nRUN curl -f -kLso $SPARK_HOME/jars/splice-shiro-$sm_version.jar https://s3.amazonaws.com/splicemachine/artifacts/splice-shiro-$sm_version.jar\nRUN curl -f -kLs \"https://s3.amazonaws.com/splicemachine/$sm_version-$dbaas_build/artifacts/splice-zeppelin-0.7.1-bin-all.tgz\" | tar -xz -C /var/tmp zeppelin-0.7.1-bin-all/interpreter/spark/dep\nRUN curl -f -kLs \"https://s3.amazonaws.com/splicemachine/$sm_version-$dbaas_build/artifacts/jdk-8u121-linux-x64.tar.gz\" | tar -xz -C /usr/local\nRUN curl -f -kLs \"https://s3.amazonaws.com/splicemachine/$sm_version-$dbaas_build/artifacts/libmesos-bundle-1.9-argus-1.1.x-2.tar.gz\" | tar -xz -C /usr/local\nRUN cp /var/tmp/zeppelin-0.7.1-bin-all/interpreter/spark/dep/hbase_*.jar $SPARK_HOME/jars/\nRUN rm $SPARK_HOME/jars/*-SNAPSHOT*.jar && \\\n    rm /var/tmp/zeppelin-0.7.1-bin-all/interpreter/spark/dep/*\n\nCOPY ./target/splicemachine-jars/* $SPARK_HOME/jars/\nCOPY ./target/splice-tutorial-file-spark-$sm_version.jar /\nCOPY ./src/main/resources/scripts/* /\nCOPY ./src/main/resources/spark/conf/ $SPARK_HOME/conf/\n\nCOPY ./Docker/docker-entrypoint.sh /\nRUN chmod +x /docker-entrypoint.sh\nENTRYPOINT [\"/docker-entrypoint.sh\"]\n\n\nCMD [\"/start-spark-streaming.sh\"]"
}