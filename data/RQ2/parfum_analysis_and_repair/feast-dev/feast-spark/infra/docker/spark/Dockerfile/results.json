{
  "startTime": 1674249745695,
  "endTime": 1674249746867,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 33,
        "lineEnd": 33,
        "columnStart": 4,
        "columnEnd": 117
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 2,
        "lineEnd": 2,
        "columnStart": 22,
        "columnEnd": 56
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 2,
        "lineEnd": 2,
        "columnStart": 22,
        "columnEnd": 56
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM maven:3.6-jdk-11 as builder\n\nRUN apt-get update && apt-get install --no-install-recommends -y build-essential && rm -rf /var/lib/apt/lists/*;\nWORKDIR /build\n\nCOPY . .\nARG VERSION=dev\n\nRUN REVISION=$VERSION make build-ingestion-jar-no-tests\n\nFROM gcr.io/kf-feast/feast-spark-base:v3.1.3 as runtime\n\nARG VERSION=dev\n\nARG TFRECORD_VERSION=0.3.0\nARG GCS_CONNECTOR_VERSION=2.2.5\nARG BQ_CONNECTOR_VERSION=0.18.1\n\nCOPY --from=builder /build/spark/ingestion/target/feast-ingestion-spark-${VERSION}.jar /opt/spark/jars\n\nUSER root\nADD https://repo1.maven.org/maven2/com/linkedin/sparktfrecord/spark-tfrecord_2.12/${TFRECORD_VERSION}/spark-tfrecord_2.12-${TFRECORD_VERSION}.jar /opt/spark/jars\nADD https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop2-${GCS_CONNECTOR_VERSION}.jar /opt/spark/jars\nADD https://repo1.maven.org/maven2/com/google/cloud/spark/spark-bigquery-with-dependencies_2.12/${BQ_CONNECTOR_VERSION}/spark-bigquery-with-dependencies_2.12-${BQ_CONNECTOR_VERSION}.jar /opt/spark/jars\n\n# Fix arrow issue for jdk-11\nRUN mkdir -p /opt/spark/conf\nRUN echo 'spark.driver.extraJavaOptions=\"-Dio.netty.tryReflectionSetAccessible=true\"' >> $SPARK_HOME/conf/spark-defaults.conf\nRUN echo 'spark.driver.extraJavaOptions=\"-Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true\"' >> $SPARK_HOME/conf/spark-defaults.conf\nRUN echo 'spark.executor.extraJavaOptions=\"-Dio.netty.tryReflectionSetAccessible=true\"' >> $SPARK_HOME/conf/spark-defaults.conf\nRUN echo 'spark.executor.extraJavaOptions=\"-Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true\"' >> $SPARK_HOME/conf/spark-defaults.conf\n\n# python dependencies\nRUN pip3 install --no-cache-dir pandas==1.3.5 great-expectations==0.13.2 pyarrow==2.0.0 Jinja2==3.0.3 datadog==0.44.0 'numpy<1.20.0'\n\n# For logging to /dev/termination-log\nRUN mkdir -p /dev\n\n\nENTRYPOINT [ \"/opt/entrypoint.sh\" ]"
}