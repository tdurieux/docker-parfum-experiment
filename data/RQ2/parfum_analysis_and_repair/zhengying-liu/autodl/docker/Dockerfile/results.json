{
  "startTime": 1674254091293,
  "endTime": 1674254092144,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 10,
        "lineEnd": 10,
        "columnStart": 4,
        "columnEnd": 29
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 11,
        "lineEnd": 11,
        "columnStart": 4,
        "columnEnd": 30
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 12,
        "lineEnd": 12,
        "columnStart": 4,
        "columnEnd": 30
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 30
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 14,
        "lineEnd": 14,
        "columnStart": 4,
        "columnEnd": 28
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 15,
        "lineEnd": 15,
        "columnStart": 4,
        "columnEnd": 33
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 16,
        "lineEnd": 16,
        "columnStart": 4,
        "columnEnd": 36
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 17,
        "lineEnd": 17,
        "columnStart": 4,
        "columnEnd": 29
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 18,
        "lineEnd": 18,
        "columnStart": 4,
        "columnEnd": 29
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 19,
        "lineEnd": 19,
        "columnStart": 4,
        "columnEnd": 27
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 20,
        "lineEnd": 20,
        "columnStart": 4,
        "columnEnd": 28
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 21,
        "lineEnd": 21,
        "columnStart": 4,
        "columnEnd": 32
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 22,
        "lineEnd": 22,
        "columnStart": 4,
        "columnEnd": 30
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 23,
        "lineEnd": 23,
        "columnStart": 4,
        "columnEnd": 31
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 24,
        "lineEnd": 24,
        "columnStart": 4,
        "columnEnd": 29
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 25,
        "lineEnd": 25,
        "columnStart": 4,
        "columnEnd": 29
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 26,
        "lineEnd": 26,
        "columnStart": 4,
        "columnEnd": 31
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 27,
        "lineEnd": 27,
        "columnStart": 4,
        "columnEnd": 28
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 28,
        "lineEnd": 28,
        "columnStart": 4,
        "columnEnd": 34
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 32,
        "lineEnd": 32,
        "columnStart": 4,
        "columnEnd": 27
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 33,
        "lineEnd": 33,
        "columnStart": 4,
        "columnEnd": 27
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 34,
        "lineEnd": 34,
        "columnStart": 4,
        "columnEnd": 28
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 35,
        "lineEnd": 35,
        "columnStart": 4,
        "columnEnd": 29
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 36,
        "lineEnd": 36,
        "columnStart": 4,
        "columnEnd": 32
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 37,
        "lineEnd": 37,
        "columnStart": 4,
        "columnEnd": 35
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 55,
        "lineEnd": 55,
        "columnStart": 4,
        "columnEnd": 37
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 50,
        "lineEnd": 50,
        "columnStart": 22,
        "columnEnd": 52
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 50,
        "lineEnd": 50,
        "columnStart": 22,
        "columnEnd": 52
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM tensorflow/tensorflow:latest-gpu-py3\n# tensorflow==1.13.1\n\n# List of common Python packages installed in the Docker image used for this\n# challenge. Participants are welcome to suggest other popular Python packages\n# to be installed. If necessary, we'll update the Docker image to satisfy the\n# need for most participants.\n# In the case where you want to use less common packages, you can simply put\n# all these packages in the the same folder of your submission (together with\n# `model.py`) and the CodaLab platform should be able to find them.\nRUN pip install --no-cache-dir numpy==1.16.2\nRUN pip install --no-cache-dir pandas==0.24.2\nRUN pip install --no-cache-dir jupyter==1.0.0\nRUN pip install --no-cache-dir seaborn==0.9.0\nRUN pip install --no-cache-dir scipy==1.2.1\nRUN pip install --no-cache-dir matplotlib==3.0.3\nRUN pip install --no-cache-dir scikit-learn==0.20.3\nRUN pip install --no-cache-dir pyyaml==5.1.1\nRUN pip install --no-cache-dir psutil==5.6.3\nRUN pip install --no-cache-dir h5py==2.9.0\nRUN pip install --no-cache-dir keras==2.2.4\nRUN pip install --no-cache-dir playsound==1.2.2\nRUN pip install --no-cache-dir librosa==0.7.1\nRUN pip install --no-cache-dir protobuf==3.7.1\nRUN pip install --no-cache-dir xgboost==0.90\nRUN pip install --no-cache-dir pyyaml==5.1.1\nRUN pip install --no-cache-dir lightgbm==2.2.3\nRUN pip install --no-cache-dir torch==1.3.1\nRUN pip install --no-cache-dir torchvision==0.4.2\n\n# Packages from AutoNLP\n# More info: https://hub.docker.com/r/wahaha909/autonlp\nRUN pip install --no-cache-dir jieba==0.39\nRUN pip install --no-cache-dir nltk==3.4.4\nRUN pip install --no-cache-dir spacy==2.1.6\nRUN pip install --no-cache-dir gensim==3.8.0\nRUN pip install --no-cache-dir polyglot==16.7.4\nRUN pip install --no-cache-dir transformers==2.2.0\n# Embedding weights: fastText dim=300 Chinese and English, BERT\n# In order to make following commands work, run these commands (in docker/)\n# first to download corresponding weights files:\n#   curl -C - -O https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.zh.300.vec.gz\n#   curl -C - -O https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n#   curl -C - -O https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\nRUN mkdir -p /app && mkdir /app/embedding && cd /app/embedding\nCOPY cc.zh.300.vec.gz /app/embedding/\nCOPY cc.en.300.vec.gz /app/embedding/\nCOPY wwm_uncased_L-24_H-1024_A-16.zip /app/embedding/\n\n# Packages from AutoSpeech\nRUN apt-get update && apt-get -y --no-install-recommends install libsndfile1 && rm -rf /var/lib/apt/lists/*;\n\n# Packages to be activated: Following packages are demanded by one of the\n# participants. If another participant asks to install one of these packages,\n# we'll uncomment corresponding line and rebuild this image.\nRUN pip install --no-cache-dir tensorflow_hub==0.7.0\n# RUN pip install fastai\n# RUN pip install --extra-index-url https://developer.download.nvidia.com/compute/redist/cuda/10.0 nvidia-dali\n\nWORKDIR /app/codalab\nADD VERSION .\n"
}