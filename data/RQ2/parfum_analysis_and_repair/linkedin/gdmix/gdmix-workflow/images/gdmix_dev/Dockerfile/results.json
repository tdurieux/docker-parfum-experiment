{
  "startTime": 1674249631454,
  "endTime": 1674249632768,
  "originalSmells": [
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 11,
        "lineEnd": 11,
        "columnStart": 87,
        "columnEnd": 111
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 7,
        "lineEnd": 7,
        "columnStart": 4,
        "columnEnd": 49
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 9,
        "lineEnd": 9,
        "columnStart": 22,
        "columnEnd": 58
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 7,
        "lineEnd": 7,
        "columnStart": 4,
        "columnEnd": 49
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 7,
        "lineEnd": 7,
        "columnStart": 4,
        "columnEnd": 49
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 9,
        "lineEnd": 9,
        "columnStart": 22,
        "columnEnd": 58
      }
    }
  ],
  "repairedSmells": [
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 7,
        "lineEnd": 7,
        "columnStart": 4,
        "columnEnd": 73
      }
    }
  ],
  "repairedDockerfile": "FROM python:3.7\n\n# Install spark 2.4\nARG spark_version=2.4.8\nARG spark_pkg=spark-${spark_version}-bin-hadoop2.7\n\nRUN apt-get update\nRUN apt-get install --no-install-recommends software-properties-common -y && rm -rf /var/lib/apt/lists/*;\nRUN apt-add-repository 'deb http://security.debian.org/debian-security stretch/updates main'\nRUN apt-get update && apt-get install --no-install-recommends openjdk-8-jdk git -y && rm -rf /var/lib/apt/lists/*;\nRUN mkdir -p /opt/spark\nRUN wget https://downloads.apache.org/spark/spark-${spark_version}/${spark_pkg}.tgz && tar -xf ${spark_pkg}.tgz && \\\n    mv ${spark_pkg}/jars /opt/spark && \\\n    mv ${spark_pkg}/bin /opt/spark && \\\n    mv ${spark_pkg}/sbin /opt/spark && \\\n    mv ${spark_pkg}/examples /opt/spark && \\\n    mv ${spark_pkg}/data /opt/spark && \\\n    mv ${spark_pkg}/kubernetes/tests /opt/spark && \\\n    mv ${spark_pkg}/kubernetes/dockerfiles/spark/entrypoint.sh /opt/ && \\\n    mkdir -p /opt/spark/conf && \\\n    cp ${spark_pkg}/conf/log4j.properties.template /opt/spark/conf/log4j.properties && \\\n    sed -i 's/INFO/ERROR/g' /opt/spark/conf/log4j.properties && \\\n    chmod +x /opt/*.sh && \\\n    rm -rf spark-* && rm ${spark_pkg}.tgz\n\nENV SPARK_HOME=/opt/spark\nENV PATH=/opt/spark/bin:$PATH\nENV SPARK_CLASSPATH=$SPARK_CLASSPATH:/opt/spark/jars/\n\nRUN rm -rf ~/.gradle/caches/* ~/.cache/pip/*\n\n"
}