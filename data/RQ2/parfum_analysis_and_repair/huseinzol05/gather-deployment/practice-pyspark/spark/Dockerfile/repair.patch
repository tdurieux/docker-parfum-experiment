diff --git a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/huseinzol05/gather-deployment/practice-pyspark/spark/Dockerfile b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/huseinzol05/gather-deployment/practice-pyspark/spark/Dockerfile/repaired.Dockerfile
index 1b29f35..74058e3 100644
--- a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/huseinzol05/gather-deployment/practice-pyspark/spark/Dockerfile
+++ b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/huseinzol05/gather-deployment/practice-pyspark/spark/Dockerfile/repaired.Dockerfile
@@ -6,18 +6,18 @@ ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64
 
 RUN apt-get update
 
-RUN DEBIAN_FRONTEND=noninteractive TZ=Etc/UTC apt-get -y install tzdata
+RUN DEBIAN_FRONTEND=noninteractive TZ=Etc/UTC apt-get --no-install-recommends -y install tzdata && rm -rf /var/lib/apt/lists/*;
 
-RUN apt-get install -y \
+RUN apt-get install --no-install-recommends -y \
     openjdk-8-jdk \
     wget bzip2 \
-    python3-pip
+    python3-pip && rm -rf /var/lib/apt/lists/*;
 
 ENV HADOOP_HOME /opt/hadoop
 
 ENV HADOOP_VERSION 3.2.2
 
-RUN wget http://www-eu.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz && \
+RUN wget https://www-eu.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz && \
     tar -xzf hadoop-${HADOOP_VERSION}.tar.gz && \
     mv hadoop-${HADOOP_VERSION} $HADOOP_HOME && \
     for user in hadoop hdfs yarn mapred; do \
@@ -32,7 +32,7 @@ RUN wget http://www-eu.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/ha
     echo "export HDFS_SECONDARYNAMENODE_USER=root" >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh && \
     echo "export YARN_RESOURCEMANAGER_USER=root" >> $HADOOP_HOME/etc/hadoop/yarn-env.sh && \
     echo "export YARN_NODEMANAGER_USER=root" >> $HADOOP_HOME/etc/hadoop/yarn-env.sh && \
-    echo "PATH=$PATH:$HADOOP_HOME/bin" >> ~/.bashrc
+    echo "PATH=$PATH:$HADOOP_HOME/bin" >> ~/.bashrc && rm hadoop-${HADOOP_VERSION}.tar.gz
 
 ENV PYTHON_VERSION $PYTHON_VERSION
 ENV SCALA_VERSION 2.11.8
@@ -50,7 +50,7 @@ ENV PYTHONPATH /opt/spark/python/lib/py4j-0.10.9-src.zip:/opt/spark/python/lib/p
 ENV PYSPARK_PYTHON python3
 ENV PYSPARK_DRIVER_PYTHON python3
 
-RUN apt install screen unzip -y
+RUN apt install --no-install-recommends screen unzip -y && rm -rf /var/lib/apt/lists/*;
 
 RUN wget https://cdn.mysql.com/archives/mysql-connector-java-5.1/mysql-connector-java-5.1.49.zip -O mysql.zip && \
     unzip mysql.zip && \
@@ -76,11 +76,11 @@ RUN wget https://raw.githubusercontent.com/yahoo/TensorFlowOnSpark/master/lib/te
 
 ADD hive-site.xml $SPARK_HOME/conf
 
-RUN pip3 install pandas numpy matplotlib seaborn scipy jupyter importlib_metadata spark-nlp==3.3.4
+RUN pip3 install --no-cache-dir pandas numpy matplotlib seaborn scipy jupyter importlib_metadata spark-nlp==3.3.4
 
-RUN pip3 install delta-spark==1.0.0 --no-deps
+RUN pip3 install --no-cache-dir delta-spark==1.0.0 --no-deps
 
-RUN pip3 install tensorflowonspark tensorflow==2.5.0 tensorflow-datasets
+RUN pip3 install --no-cache-dir tensorflowonspark tensorflow==2.5.0 tensorflow-datasets
 
 ENV SHELL /bin/bash