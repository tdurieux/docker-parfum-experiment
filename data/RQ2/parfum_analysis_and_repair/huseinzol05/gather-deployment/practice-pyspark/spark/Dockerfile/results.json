{
  "startTime": 1674251845151,
  "endTime": 1674251846368,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 19,
        "lineEnd": 19,
        "columnStart": 4,
        "columnEnd": 109
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 78,
        "lineEnd": 78,
        "columnStart": 4,
        "columnEnd": 98
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 80,
        "lineEnd": 80,
        "columnStart": 4,
        "columnEnd": 45
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 82,
        "lineEnd": 82,
        "columnStart": 4,
        "columnEnd": 72
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 20,
        "lineEnd": 20,
        "columnStart": 4,
        "columnEnd": 44
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 4,
        "columnEnd": 71
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 10,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 15
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 52,
        "lineEnd": 52,
        "columnStart": 4,
        "columnEnd": 31
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 4,
        "columnEnd": 71
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 10,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 15
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 52,
        "lineEnd": 52,
        "columnStart": 4,
        "columnEnd": 31
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 4,
        "columnEnd": 71
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 10,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 15
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 52,
        "lineEnd": 52,
        "columnStart": 4,
        "columnEnd": 31
      }
    }
  ],
  "repairedSmells": [
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 4,
        "columnEnd": 95
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 10,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 15
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 52,
        "lineEnd": 52,
        "columnStart": 4,
        "columnEnd": 55
      }
    }
  ],
  "repairedDockerfile": "FROM ubuntu:20.04 AS base\n\nARG PYTHON_VERSION=3.8\n\nENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64\n\nRUN apt-get update\n\nRUN DEBIAN_FRONTEND=noninteractive TZ=Etc/UTC apt-get --no-install-recommends -y install tzdata && rm -rf /var/lib/apt/lists/*;\n\nRUN apt-get install --no-install-recommends -y \\\n    openjdk-8-jdk \\\n    wget bzip2 \\\n    python3-pip && rm -rf /var/lib/apt/lists/*;\n\nENV HADOOP_HOME /opt/hadoop\n\nENV HADOOP_VERSION 3.2.2\n\nRUN wget https://www-eu.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz && \\\n    tar -xzf hadoop-${HADOOP_VERSION}.tar.gz && \\\n    mv hadoop-${HADOOP_VERSION} $HADOOP_HOME && \\\n    for user in hadoop hdfs yarn mapred; do \\\n        useradd -U -M -d /opt/hadoop/ --shell /bin/bash ${user}; \\\n    done && \\\n    for user in root hdfs yarn mapred; do \\\n        usermod -G hadoop ${user}; \\\n    done && \\\n    echo \"export JAVA_HOME=$JAVA_HOME\" >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh && \\\n    echo \"export HDFS_DATANODE_USER=root\" >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh && \\\n    echo \"export HDFS_NAMENODE_USER=root\" >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh && \\\n    echo \"export HDFS_SECONDARYNAMENODE_USER=root\" >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh && \\\n    echo \"export YARN_RESOURCEMANAGER_USER=root\" >> $HADOOP_HOME/etc/hadoop/yarn-env.sh && \\\n    echo \"export YARN_NODEMANAGER_USER=root\" >> $HADOOP_HOME/etc/hadoop/yarn-env.sh && \\\n    echo \"PATH=$PATH:$HADOOP_HOME/bin\" >> ~/.bashrc && rm hadoop-${HADOOP_VERSION}.tar.gz\n\nENV PYTHON_VERSION $PYTHON_VERSION\nENV SCALA_VERSION 2.11.8\nENV SPARK_VERSION 3.1.2\nENV SPARK_BUILD \"spark-${SPARK_VERSION}-bin-hadoop2.7\"\nENV SPARK_BUILD_URL \"https://dist.apache.org/repos/dist/release/spark/spark-${SPARK_VERSION}/${SPARK_BUILD}.tgz\"\nRUN wget $SPARK_BUILD_URL -O /tmp/spark.tgz && \\\n    tar -C /opt -xf /tmp/spark.tgz && \\\n    mv /opt/$SPARK_BUILD /opt/spark && \\\n    rm /tmp/spark.tgz\nENV SPARK_HOME /opt/spark\nENV PATH $SPARK_HOME/bin:$PATH\nENV PYTHONPATH /opt/spark/python/lib/py4j-0.10.9-src.zip:/opt/spark/python/lib/pyspark.zip:$PYTHONPATH\n\nENV PYSPARK_PYTHON python3\nENV PYSPARK_DRIVER_PYTHON python3\n\nRUN apt install --no-install-recommends screen unzip -y && rm -rf /var/lib/apt/lists/*;\n\nRUN wget https://cdn.mysql.com/archives/mysql-connector-java-5.1/mysql-connector-java-5.1.49.zip -O mysql.zip && \\\n    unzip mysql.zip && \\\n    cp mysql-connector-java-5.1.49/mysql-connector-java-5.1.49.jar $SPARK_HOME/jars\n\nRUN wget https://jdbc.postgresql.org/download/postgresql-42.3.0.jar && \\\n    cp postgresql-42.3.0.jar $SPARK_HOME/jars\n\nRUN wget https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.1.2/spark-sql-kafka-0-10_2.12-3.1.2.jar && \\\n    cp spark-sql-kafka-0-10_2.12-3.1.2.jar $SPARK_HOME/jars\n\nRUN wget https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.1.2/spark-token-provider-kafka-0-10_2.12-3.1.2.jar && \\\n    cp spark-token-provider-kafka-0-10_2.12-3.1.2.jar $SPARK_HOME/jars\n\nRUN wget https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.6.0/kafka-clients-2.6.0.jar && \\\n    cp kafka-clients-2.6.0.jar $SPARK_HOME/jars\n\nRUN wget https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.6.2/commons-pool2-2.6.2.jar && \\\n    cp commons-pool2-2.6.2.jar $SPARK_HOME/jars\n\nRUN wget https://raw.githubusercontent.com/yahoo/TensorFlowOnSpark/master/lib/tensorflow-hadoop-1.0-SNAPSHOT.jar && \\\n    cp tensorflow-hadoop-1.0-SNAPSHOT.jar $SPARK_HOME/jars\n\nADD hive-site.xml $SPARK_HOME/conf\n\nRUN pip3 install --no-cache-dir pandas numpy matplotlib seaborn scipy jupyter importlib_metadata spark-nlp==3.3.4\n\nRUN pip3 install --no-cache-dir delta-spark==1.0.0 --no-deps\n\nRUN pip3 install --no-cache-dir tensorflowonspark tensorflow==2.5.0 tensorflow-datasets\n\nENV SHELL /bin/bash\n\nWORKDIR $SPARK_HOME\n\nCOPY . $SPARK_HOME"
}