diff --git a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/huseinzol05/gather-deployment/apache-stack/4.pyspark-jupyter/Dockerfile b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/huseinzol05/gather-deployment/apache-stack/4.pyspark-jupyter/Dockerfile/repaired.Dockerfile
index 3aaf9b2..f00172f 100644
--- a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/huseinzol05/gather-deployment/apache-stack/4.pyspark-jupyter/Dockerfile
+++ b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/huseinzol05/gather-deployment/apache-stack/4.pyspark-jupyter/Dockerfile/repaired.Dockerfile
@@ -4,21 +4,21 @@ ENV HADOOP_HOME /opt/hadoop
 ENV SPARK_HOME /opt/spark
 ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64
 
-RUN apt-get update && apt-get install -y \
+RUN apt-get update && apt-get install --no-install-recommends -y \
     python3 \
     python3-pip \
     python3-wheel \
     openjdk-8-jdk \
     ssh \
-    wget
+    wget && rm -rf /var/lib/apt/lists/*;
 
 RUN wget https://www-eu.apache.org/dist/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz && \
     tar -xzf spark-2.3.2-bin-hadoop2.7.tgz && \
-    mv spark-2.3.2-bin-hadoop2.7 $SPARK_HOME
+    mv spark-2.3.2-bin-hadoop2.7 $SPARK_HOME && rm spark-2.3.2-bin-hadoop2.7.tgz
 
-RUN pip3 install jupyter pyspark
+RUN pip3 install --no-cache-dir jupyter pyspark
 
-RUN wget http://www-eu.apache.org/dist/hadoop/common/hadoop-3.1.1/hadoop-3.1.1.tar.gz && \
+RUN wget https://www-eu.apache.org/dist/hadoop/common/hadoop-3.1.1/hadoop-3.1.1.tar.gz && \
     tar -xzf hadoop-3.1.1.tar.gz && \
     mv hadoop-3.1.1 $HADOOP_HOME && \
     for user in hadoop hdfs yarn mapred; do \
@@ -33,12 +33,12 @@ RUN wget http://www-eu.apache.org/dist/hadoop/common/hadoop-3.1.1/hadoop-3.1.1.t
     echo "export HDFS_SECONDARYNAMENODE_USER=root" >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh && \
     echo "export YARN_RESOURCEMANAGER_USER=root" >> $HADOOP_HOME/etc/hadoop/yarn-env.sh && \
     echo "export YARN_NODEMANAGER_USER=root" >> $HADOOP_HOME/etc/hadoop/yarn-env.sh && \
-    echo "PATH=$PATH:$HADOOP_HOME/bin" >> ~/.bashrc
+    echo "PATH=$PATH:$HADOOP_HOME/bin" >> ~/.bashrc && rm hadoop-3.1.1.tar.gz
 
-RUN apt-get install openssh-client -y && \
+RUN apt-get install --no-install-recommends openssh-client -y && \
     ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa && \
     cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys && \
-    chmod 0600 ~/.ssh/authorized_keys
+    chmod 0600 ~/.ssh/authorized_keys && rm -rf /var/lib/apt/lists/*;
 
 ADD *xml $HADOOP_HOME/etc/hadoop/
 
@@ -51,6 +51,6 @@ COPY . /app
 ENV LC_ALL C.UTF-8
 ENV LANG C.UTF-8
 
-RUN pip3 install pandas matplotlib seaborn
+RUN pip3 install --no-cache-dir pandas matplotlib seaborn
 
 RUN ln -s /usr/bin/python3 /usr/bin/python