{
  "startTime": 1674215387798,
  "endTime": 1674215388585,
  "originalSmells": [
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 26,
        "lineEnd": 26,
        "columnStart": 4,
        "columnEnd": 65
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# Spark 1.2.0\n# Version 1.0.0\n#\nFROM sequenceiq/hadoop-docker:2.6.0\n\n# Add config files and configure script\nADD files /root/spark_files\n\nENV SCALA_VERSION 2.11.4\nENV SPARK_VERSION 1.2.0\nENV SCALA_HOME /opt/scala-$SCALA_VERSION\nENV SPARK_HOME /opt/spark-$SPARK_VERSION\nENV PATH $SPARK_HOME:$SCALA_HOME/bin:$PATH\n\n# Spark settings default values\nENV SCALA_HOME /opt/scala-2.11.4\nENV SPARK_EXECUTOR_MEMORY 1500m\nENV SPARK_DRIVER_MEMORY 1500m\nENV SPARK_WORKER_MEMORY 1500m\nENV SPARK_MASTER_MEM 1500m\nENV HADOOP_HOME \"/etc/hadoop\"\nENV SPARK_LOCAL_DIR /tmp/spark\n\n# install a few other useful packages plus Open Jdk 7\n#RUN yum install -y wget unzip zip tar git \\\n#    java-1.6.0-openjdk-devel java-1.7.0-openjdk-devel\nRUN yum -y -q install java-1.8.0-openjdk java-1.8.0-openjdk-devel && rm -rf /var/cache/yum\nENV JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk\n\n#apt-get update && apt-get upgrade -y && apt-get install -y less openjdk-7-jre-headless net-tools vim-tiny sudo openssh-server iputils-ping python2.7\n\n# Install Scala\nADD http://www.scala-lang.org/files/archive/scala-$SCALA_VERSION.tgz /\nRUN (cd / && gunzip < scala-$SCALA_VERSION.tgz)|(cd /opt && tar -xvf -)\nRUN rm /scala-$SCALA_VERSION.tgz\n\n# Install Spark\nADD http://d3kbcqa49mib13.cloudfront.net/spark-$SPARK_VERSION-bin-hadoop2.4.tgz /\nRUN (cd / && gunzip < spark-$SPARK_VERSION-bin-hadoop2.4.tgz)|(cd /opt && tar -xvf -)\nRUN (ln -s /opt/spark-$SPARK_VERSION-bin-hadoop2.4 /opt/spark-$SPARK_VERSION && rm /spark-$SPARK_VERSION-bin-hadoop2.4.tgz)\nRUN (ln -s /opt/spark-$SPARK_VERSION-bin-hadoop2.4 spark)\n\n# Spark configuration\nRUN (rm -rf /opt/spark-$SPARK_VERSION/work)\nRUN (mkdir -p /opt/spark-$SPARK_VERSION/work)\nRUN (mkdir /tmp/spark)\nRUN (rm -rf /var/lib/hadoop/hdfs)\nRUN (mkdir -p /var/lib/hadoop/hdfs)\nRUN (rm -rf /opt/spark-$SPARK_VERSION/logs)\nRUN (mkdir -p /opt/spark-$SPARK_VERSION/logs)\nRUN (cp /root/spark_files/spark-env.sh /opt/spark-$SPARK_VERSION/conf/)\nRUN (cp /root/spark_files/log4j.properties /opt/spark-$SPARK_VERSION/conf/)"
}