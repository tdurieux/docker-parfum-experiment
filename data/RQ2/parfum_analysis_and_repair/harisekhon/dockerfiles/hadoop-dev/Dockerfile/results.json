{
  "startTime": 1674248565864,
  "endTime": 1674248567554,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 39,
        "lineEnd": 39,
        "columnStart": 4,
        "columnEnd": 194
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 40,
        "lineEnd": 40,
        "columnStart": 4,
        "columnEnd": 163
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 32,
        "lineEnd": 32,
        "columnStart": 4,
        "columnEnd": 64
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "#\n#  Author: Hari Sekhon\n#  Date: 2016-04-24 21:18:57 +0100 (Sun, 24 Apr 2016)\n#\n#  vim:ts=4:sts=4:sw=4:et\n#\n#  https://github.com/HariSekhon/Dockerfiles\n#\n#  If you're using my code you're welcome to connect with me on LinkedIn and optionally send me feedback\n#\n#  https://www.linkedin.com/in/HariSekhon\n#\n\n# nosemgrep: dockerfile.audit.dockerfile-source-not-pinned.dockerfile-source-not-pinned\nFROM harisekhon/github:centos\n\nARG HADOOP_VERSION=3.0.0\n\nLABEL org.opencontainers.image.description=\"Hadoop Dev\" \\\n      org.opencontainers.image.version=\"$HADOOP_VERSION\" \\\n      org.opencontainers.image.authors=\"Hari Sekhon (https://www.linkedin.com/in/HariSekhon)\" \\\n      org.opencontainers.image.url=\"https://ghcr.io/HariSekhon/hadoop-dev\" \\\n      org.opencontainers.image.documentation=\"https://hub.docker.com/r/harisekhon/hadoop-dev\" \\\n      org.opencontainers.image.source=\"https://github.com/HariSekhon/Dockerfiles\"\n\nARG TAR=hadoop-$HADOOP_VERSION.tar.gz\n\nENV PATH $PATH:/hadoop/bin\n\nWORKDIR /\n\nRUN set -eux && \\\n    yum install -y openssh-server openssh-clients wget tar which && rm -rf /var/cache/yum\n\nRUN set -eux && \\\n    yum install -y hostname && \\\n    # --max-redirect - some apache mirrors redirect a couple times and give you the latest version instead\n    #                  but this breaks stuff later because the link will not point to the right dir\n    #                  (and is also the wrong version for the tag)\n    wget -t 10 --max-redirect 1 --retry-connrefused -O \"$TAR\" \"https://www.apache.org/dyn/closer.lua?filename=hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-$HADOOP_VERSION.tar.gz&action=download\" || \\\n    wget -t 10 --max-redirect 1 --retry-connrefused -O \"$TAR\" \"https://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-$HADOOP_VERSION.tar.gz\" && \\\n    tar zxf \"$TAR\" && \\\n    # check tarball was extracted to the right place, helps ensure it's the right version and the link will work\n    test -d \"hadoop-$HADOOP_VERSION\" && \\\n    ln -sv \"hadoop-$HADOOP_VERSION\" hadoop && \\\n    mkdir /etc/hadoop && \\\n    ln -s /hadoop/etc/hadoop /etc/hadoop/conf && \\\n    rm -fv \"$TAR\" && \\\n    { rm -rf hadoop/share/doc; : ; } && \\\n    yum autoremove -y && \\\n    # gets autoremoved, ensure it's added back as Hadoop scripts need it\n    yum install -y hostname && \\\n    yum clean all && \\\n    rm -rf /var/cache/yum\n\nCOPY entrypoint.sh /\nCOPY conf/core-site.xml /hadoop/etc/hadoop/\nCOPY conf/hdfs-site.xml /hadoop/etc/hadoop/\nCOPY conf/yarn-site.xml /hadoop/etc/hadoop/\nCOPY conf/mapred-site.xml /hadoop/etc/hadoop/\nCOPY profile.d/hadoop.sh /etc/profile.d/\nCOPY ssh/config /root/.ssh/\n\nRUN set -eux && \\\n    # Hadoop 1.x\n    #/hadoop/bin/hadoop namenode -format && \\\n    # Hadoop 2.x\n    /hadoop/bin/hdfs namenode -format && \\\n    groupadd hadoop && \\\n    useradd -g hadoop hdfs && \\\n    useradd -g hadoop yarn && \\\n    mkdir -p /dfs/name && \\\n    mkdir -p /hadoop/logs && \\\n    chown -R hdfs:hadoop /dfs/name && \\\n    chgrp -R hadoop /hadoop/logs && \\\n    chmod -R 0770 /hadoop/logs && \\\n    mkdir -p /root/.ssh \\\n          /home/hdfs/.ssh \\\n          /home/yarn/.ssh && \\\n    chown hdfs /home/hdfs/.ssh && \\\n    chown yarn /home/yarn/.ssh && \\\n    chmod 0700 /root/.ssh \\\n               /home/hdfs/.ssh \\\n               /home/yarn/.ssh\n\nENV HDFS_NAMENODE_USER=hdfs\nENV HDFS_SECONDARYNAMENODE_USER=hdfs\nENV HDFS_DATANODE_USER=hdfs\nENV YARN_RESOURCEMANAGER_USER=yarn\nENV YARN_NODEMANAGER_USER=yarn\n\n#EXPOSE 8020 8042 8088 9000 10020 19888 50010 50020 50070 50075 50090\n# Hadoop 3.0 changed ports :-(\nEXPOSE 8020 8042 8088 9000 9868 9870 10020 19888 50010 50020 50090\n\nCMD [\"/entrypoint.sh\"]\n"
}