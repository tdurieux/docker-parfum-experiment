{
  "startTime": 1674248178899,
  "endTime": 1674248179341,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 42,
        "lineEnd": 42,
        "columnStart": 4,
        "columnEnd": 93
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "#\n#  Author: Hari Sekhon\n#  Date: 2016-01-16 09:58:07 +0000 (Sat, 16 Jan 2016)\n#\n#  vim:ts=4:sts=4:sw=4:et\n#\n#  https://github.com/HariSekhon/Dockerfiles\n#\n#  If you're using my code you're welcome to connect with me on LinkedIn and optionally send me feedback to help improve or steer this or other code I publish\n#\n#  https://www.linkedin.com/in/HariSekhon\n#\n\n#FROM harisekhon/centos-java:jre7\n# > 100MB smaller than centos\n# nosemgrep: dockerfile.audit.dockerfile-source-not-pinned.dockerfile-source-not-pinned\nFROM alpine:3.12\n\nARG SPARK_VERSION=1.6.2\nARG HADOOP_VERSION=2.6\n\nLABEL org.opencontainers.image.description=\"Apache Spark\" \\\n      org.opencontainers.image.version=\"$SPARK_VERSION\" \\\n      org.opencontainers.image.authors=\"Hari Sekhon (https://www.linkedin.com/in/HariSekhon)\" \\\n      org.opencontainers.image.url=\"https://ghcr.io/HariSekhon/spark\" \\\n      org.opencontainers.image.documentation=\"https://hub.docker.com/r/harisekhon/spark\" \\\n      org.opencontainers.image.source=\"https://github.com/HariSekhon/Dockerfiles\"\n\nARG TAR=spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz\n\nENV PATH $PATH:/spark/bin\n\n#COPY spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION /spark\n#ADD \"http://d3kbcqa49mib13.cloudfront.net/${TAR}\"\n\nWORKDIR /\n\nRUN set -eux && \\\n    apk add --no-cache bash openjdk8-jre-base\n\nRUN set -eux && \\\n    apk add --no-cache wget tar && \\\n    wget -t 100 --retry-connrefused -O \"${TAR}\" \"https://d3kbcqa49mib13.cloudfront.net/${TAR}\" && \\\n    tar zxf \"${TAR}\" && \\\n    rm -fv \"${TAR}\" && \\\n    ln -s \"spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION\" spark && \\\n    apk del wget tar\n\nRUN mkdir /var/run/sshd && chmod 0755 /var/run/sshd && \\\ncp -v /spark/conf/spark-env.sh.template /spark/conf/spark-env.sh\n\nCOPY entrypoint.sh /\n\nEXPOSE 4040 7077 8080 8081\n\nCMD [\"/entrypoint.sh\"]\n"
}