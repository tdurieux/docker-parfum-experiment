{
  "startTime": 1674255030661,
  "endTime": 1674255031448,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 40,
        "lineEnd": 40,
        "columnStart": 4,
        "columnEnd": 17
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 26,
        "lineEnd": 26,
        "columnStart": 40,
        "columnEnd": 69
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 26,
        "lineEnd": 26,
        "columnStart": 40,
        "columnEnd": 69
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# SPDX-FileCopyrightText: Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nARG FROM_IMAGE=gpuci/miniforge-cuda\nARG CUDA_VER=11.4\nARG LINUX_VER=ubuntu20.04\nARG TRITON_VER=r22.02\nFROM ${FROM_IMAGE}:${CUDA_VER}-runtime-${LINUX_VER} AS base\n\nWORKDIR /mlflow\n\nCOPY . ./\n\n# need to do an upgrade in case gpuci is stale for whatever reason\nRUN apt-get update && apt upgrade -y && apt-get install --no-install-recommends -y procps vim && rm -rf /var/lib/apt/lists/*;\nRUN /opt/conda/bin/conda env create -f docker/conda/mlflow-env.yml\nRUN sed -i 's/conda activate base/conda activate mlflow/g' ~/.bashrc\n\nSHELL [\"/opt/conda/bin/conda\", \"run\", \"-n\", \"mlflow\", \"/bin/bash\", \"-c\"]\n\nARG TRITON_DIR=/mlflow/triton-inference-server\nARG TRITON_VER=r21.12\n\nRUN mkdir ${TRITON_DIR} && \\\n    cd ${TRITON_DIR} && \\\n    git clone -b ${TRITON_VER} --depth 1 https://github.com/triton-inference-server/server && \\\n    source activate mlflow && \\\n    cd ${TRITON_DIR}/server/deploy/mlflow-triton-plugin && \\\n    pip install --no-cache-dir .\n\nRUN ln -sf ${TRITON_DIR}/server/deploy/mlflow-triton-plugin/scripts/publish_model_to_mlflow.py /mlflow && \\\n    mkdir /mlflow/artifacts\n\nENV MLFLOW_MODEL_REPO=/mlflow/artifacts\nENV MLFLOW_TRACKING_URI=sqlite:////tmp/mlflow-db.sqlite\n\n# Set the entrypoint to use the entrypoint.sh script which sets the conda env\nENTRYPOINT [ \"/opt/conda/bin/tini\", \"--\", \"docker/entrypoint.sh\" ]\n\nCMD [ \"/bin/bash\" ]\n"
}