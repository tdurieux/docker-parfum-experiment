{
  "startTime": 1674219571221,
  "endTime": 1674219572037,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 50
      }
    },
    {
      "rule": "npmCacheCleanAfterInstall",
      "position": {
        "lineStart": 41,
        "lineEnd": 41,
        "columnStart": 4,
        "columnEnd": 15
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 24,
        "lineEnd": 24,
        "columnStart": 4,
        "columnEnd": 130
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 24,
        "lineEnd": 24,
        "columnStart": 4,
        "columnEnd": 130
      }
    }
  ],
  "repairedSmells": [
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 24,
        "lineEnd": 24,
        "columnStart": 4,
        "columnEnd": 130
      }
    }
  ],
  "repairedDockerfile": "# Extend the base Python image\n# See https://hub.docker.com/_/python for version options\n# N.b., there are many options for Python images. We used the plain\n# version number in the pilot. YMMV. See this post for a discussion of\n# some options and their pros and cons:\n# https://pythonspeed.com/articles/base-image-python-docker-images/\nFROM python:3.8\n\n# Give ourselves some credit\nLABEL maintainer \"DataMade <info@datamade.us>\"\n\n# Add the NodeSource PPA\n# (see: https://github.com/nodesource/distributions/blob/master/README.md)\nRUN curl -f -sL https://deb.nodesource.com/setup_12.x | bash -\n\n# Install any additional OS-level packages you need via apt-get. RUN statements\n# add additional layers to your image, increasing its final size. Keep your\n# image small by combining related commands into one RUN statement, e.g.,\n#\n# RUN apt-get update && \\\n#     apt-get install -y python-pip\n#\n# Read more on Dockerfile best practices at the source:\n# https://docs.docker.com/develop/develop-images/dockerfile_best-practices\nRUN apt-get install -y --no-install-recommends postgresql-client nodejs{% if cookiecutter.postgis == 'True' %} gdal-bin{% endif %} && rm -rf /var/lib/apt/lists/*;\n\n# Inside the container, create an app directory and switch into it\nRUN mkdir /app\nWORKDIR /app\n\n# Copy the requirements file into the app directory, and install them. Copy\n# only the requirements file, so Docker can cache this build step. Otherwise,\n# the requirements must be reinstalled every time you build the image after\n# the app code changes. See this post for further discussion of strategies\n# for building lean and efficient containers:\n# https://blog.realkinetic.com/building-minimal-docker-containers-for-python-applications-37d0272c52f3\nCOPY ./requirements.txt /app/requirements.txt\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Install Node requirements\nCOPY ./package.json /app/package.json\nRUN npm install && npm cache clean --force;\n\n# Copy the contents of the current host directory (i.e., our app code) into\n# the container.\nCOPY . /app\n\n# Add a bogus env var for the Django secret key in order to allow us to run\n# the 'collectstatic' management command\nENV DJANGO_SECRET_KEY 'foobar'\n\n# Build static files into the container\nRUN python manage.py collectstatic --noinput\n"
}