{
  "startTime": 1674256220702,
  "endTime": 1674256223773,
  "originalSmells": [
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 9,
        "lineEnd": 10,
        "columnStart": 22,
        "columnEnd": 26
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# sgkit gwas validation docker image\nFROM jupyter/minimal-notebook:54462805efcb\nENV WORK_DIR=$HOME/work\nRUN mkdir $WORK_DIR/repos $WORK_DIR/auth $WORK_DIR/data $WORK_DIR/logs\n\nUSER root\n\n# Install Hail\nRUN mkdir -p /usr/share/man/man1 && \\\n    apt-get update && apt-get install --no-install-recommends -y \\\n    openjdk-8-jre-headless \\\n    && rm -rf /var/lib/apt/lists/*\nCOPY environment-hail.yml /tmp/\nRUN conda env create -p $CONDA_DIR/envs/hail -f /tmp/environment-hail.yml && \\\n    conda clean --all -f -y\nRUN $CONDA_DIR/envs/hail/bin/pip install hail==0.2.47\nRUN $CONDA_DIR/envs/hail/bin/python -m ipykernel install --user --name=hail\n\n# Install Glow\nCOPY environment-glow.yml /tmp/\nRUN conda env create -p $CONDA_DIR/envs/glow -f /tmp/environment-glow.yml && \\\n    conda clean --all -f -y\nRUN $CONDA_DIR/envs/glow/bin/pip install glow.py==0.5.0\nRUN $CONDA_DIR/envs/glow/bin/python -m ipykernel install --user --name=glow\n\n\n# Install base environment dependencies\nCOPY environment.yml environment-dev.yml /tmp/\nRUN conda env update -n base --file /tmp/environment.yml\nRUN conda env update -n base --file /tmp/environment-dev.yml\n\n# Install pysnptools separately (does not work as pip install with conda env update)\nRUN pip install --no-cache-dir pysnptools==0.4.19\n\n# Ensure this always occurs last before user switch\nRUN fix-permissions $CONDA_DIR && \\\n  fix-permissions /home/$NB_USER\n\nUSER $NB_UID\n\nENV PYTHONPATH=\"${PYTHONPATH}:$WORK_DIR/repos/sgkit\"\nENV PYTHONPATH=\"${PYTHONPATH}:$WORK_DIR/repos/sgkit-plink\"\n\nENV OMP_NUM_THREADS=1\nENV MKL_NUM_THREADS=1\nENV OPENBLAS_NUM_THREADS=1\n\nARG SPARK_DRIVER_MEMORY=64g\nENV SPARK_DRIVER_MEMORY=$SPARK_DRIVER_MEMORY\n\n# Set this as needed to avoid https://issues.apache.org/jira/browse/SPARK-29367\n# with any pyspark 2.4.x + pyarrow >= 0.15.x\n# See: https://spark.apache.org/docs/latest/sql-pyspark-pandas-with-arrow.html#compatibility-setting-for-pyarrow--0150-and-spark-23x-24x\nENV ARROW_PRE_0_15_IPC_FORMAT=1"
}