{
  "startTime": 1674215049560,
  "endTime": 1674215050612,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 40,
        "lineEnd": 40,
        "columnStart": 4,
        "columnEnd": 31
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM alpine AS builder\n\n## TODO: Build code and dependencies, and/or fetch model checkpoints.\n## We recommend fetching checkpoints in this build stage, since we don't want\n## the final image to carry along unnecessary packages like curl/wget. Also,\n## you can fetch checkpoints securely over SSL in this stage using private keys\n## which won't be included in the final build. See e.g. the RNNG Dockerfile in\n## LM Zoo for an example.\n#\n# RUN apk add curl\nRUN mkdir -p /opt/mylm\nRUN mkdir -p /opt/mylm/checkpoint\n# RUN cd /opt/mylm/checkpoint && \\\n#           curl -so model.ckpt https://me.com/mylm/model.ckpt &&\n#           curl -so vocab.txt https://me.com/mylm/vocab.txt\n\n\n## TODO: Pick a base image. Explicitly specify an image tag when possible (e.g.\n## `tensorflow/tensorflow:1.15.2`).\n##\n## Popular base images:\n# FROM pytorch/pytorch\n# FROM tensorflow/tensorflow\n# FROM continuumio/miniconda3\nFROM continuumio/miniconda3\n\n# Root of model directory relative to build context.\nARG MODEL_ROOT=models/_template\n\n## TODO: Install runtime dependencies.\n## Maybe copy over dependencies from build image,\n# COPY --from=builder /usr/local/my_dependency /usr/local/my_dependency\n## Or install via package manager\n# RUN apt-get update && apt-get install -y --no-install-recommends \\\n#         perl && \\\n#         rm -rf /var/lib/apt/lists/*\n\n## Add test dependencies. These are required for all images -- otherwise tests\n## will fail.\nRUN conda install -y numpy nomkl && conda clean -tipsy\nRUN pip install --no-cache-dir nose jsonschema\n\n## TODO: Fetch/copy model dependencies.\nCOPY --from=builder /opt/mylm /opt/mylm\nCOPY ${MODEL_ROOT}/vocab.txt /opt/mylm/checkpoint/vocab.txt\n\n## TODO: Copy in custom code wrapping the language model\nCOPY ${MODEL_ROOT}/get_word_surprisals.py /opt/mylm/get_word_surprisals.py\n\n## Copy external-facing scripts.\nCOPY ${MODEL_ROOT}/bin /opt/bin\n## LM Zoo provides standard scripts for some of the binaries. `unkify` output,\n## for example, can be computed automatically from the output of `tokenize` and\n## the language model's spec. The shared `unkify` script does just this for\n## you.\nCOPY shared/unkify /opt/bin/unkify\n## The LM Zoo shared spec script will automatically insert the language model's\n## vocabulary into a template spec. Handy!\nCOPY shared/spec /opt/bin/spec\n## If your image doesn't support certain features, copy in the shared script\n## ``unsupported`` for each of these features. This makes things easily\n## detectable from the LM Zoo API.\nCOPY shared/unsupported /opt/bin/get_predictions.hdf5\n\nENV PATH \"/opt/bin:${PATH}\"\n\n## Set the path to the language model's checkpoint data. The image user can\n## override this environment variable, in which case the corresponding new\n## checkpoint should be loaded. (This is a requirement of models which support\n## the `mount_checkpoint` feature.)\nENV LMZOO_CHECKPOINT_PATH /opt/mylm/checkpoint\n\n## State the path (relative to the checkpoint path) of the model's vocabulary.\n## It isn't necessary to do this, but in doing so we can use the shared LM Zoo\n## `spec` binary to auto-generate a spec output containing our vocabulary.\nENV LMZOO_VOCABULARY_PATH vocab.txt\n\n## Fix I/O encoding.\nENV PYTHONIOENCODING utf-8\n\n## Prepare language model specification. We'll take the template specification\n## and add information provided from a few Docker build args.\n# Current git commit of build repository\nARG COMMIT\n# sha1 checksum of build directory\nARG FILES_SHA1\n# Prepare spec.\nCOPY ${MODEL_ROOT}/spec.template.json /opt/spec.template.json\nRUN BUILD_DATETIME=\"$(date)\" sed -i \"s/<image\\.sha1>/$COMMIT/g; s/<image\\.files_sha1>/${FILES_SHA1}/g; s/<image\\.datetime>/${BUILD_DATETIME}/g\" /opt/spec.template.json\n\nWORKDIR /opt/bin\n"
}