{
  "startTime": 1674220718654,
  "endTime": 1674220719087,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 16,
        "lineEnd": 16,
        "columnStart": 4,
        "columnEnd": 35
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 17,
        "lineEnd": 17,
        "columnStart": 4,
        "columnEnd": 49
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM jupyter/pyspark-notebook:latest\n\nARG HADOOP_VERSION=3.3.1\nARG AWS_SDK_VERSION=1.11.901\n\nUSER root\n\nRUN wget -q \"https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/${HADOOP_VERSION}/hadoop-aws-${HADOOP_VERSION}.jar\" -P ${SPARK_HOME}/jars/ && \\\n    wget -q \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/${AWS_SDK_VERSION}/aws-java-sdk-bundle-${AWS_SDK_VERSION}.jar\" -P ${SPARK_HOME}/jars/\n\nRUN echo 'spark.serializer org.apache.spark.serializer.KryoSerializer' >> \"${SPARK_HOME}/conf/spark-defaults.conf\" && \\\n    echo 'spark.hadoop.fs.s3a.fast.upload True' >> \"${SPARK_HOME}/conf/spark-defaults.conf\" && \\\n    echo 'spark.hadoop.fs.s3a.impl org.apache.hadoop.fs.s3a.S3AFileSystem' >> \"${SPARK_HOME}/conf/spark-defaults.conf\"\n\nCOPY requirements.txt requirements.txt\n\nRUN pip install --no-cache-dir -r requirements.txt && \\\n    pip install --no-cache-dir \"jupyterlab>=3\" \"ipywidgets>=7.6\""
}