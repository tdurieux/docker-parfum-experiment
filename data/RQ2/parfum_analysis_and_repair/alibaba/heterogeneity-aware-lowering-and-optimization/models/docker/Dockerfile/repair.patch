diff --git a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/alibaba/heterogeneity-aware-lowering-and-optimization/models/docker/Dockerfile b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/alibaba/heterogeneity-aware-lowering-and-optimization/models/docker/Dockerfile/repaired.Dockerfile
index 2f1c271..2221792 100644
--- a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/alibaba/heterogeneity-aware-lowering-and-optimization/models/docker/Dockerfile
+++ b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/alibaba/heterogeneity-aware-lowering-and-optimization/models/docker/Dockerfile/repaired.Dockerfile
@@ -1,7 +1,7 @@
 # PyTorch Models
 FROM pytorch/pytorch AS PT
-RUN pip3 install scipy
-RUN apt update && apt install -y wget imagemagick
+RUN pip3 install --no-cache-dir scipy
+RUN apt update && apt install --no-install-recommends -y wget imagemagick && rm -rf /var/lib/apt/lists/*;
 COPY scripts/get_cls_model_from_pytorch.py /
 
 WORKDIR /models/vision/classification/alexnet
@@ -37,13 +37,13 @@ RUN convert 0test.png -resize 256x256 test.jpg && rm 0test.png
 FROM pytorch/pytorch:1.8.1-cuda11.1-cudnn8-devel AS HRNET
 SHELL [ "/bin/bash", "-c"]
 RUN mv /etc/apt/sources.list.d/{cuda,nvidia-ml}.list /tmp/
-RUN apt-get update && apt-get install -y curl && \
+RUN apt-get update && apt-get install --no-install-recommends -y curl && \
     curl -fsSL https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub | apt-key add - && \
-    mv /tmp/{cuda.list,nvidia-ml.list} /etc/apt/sources.list.d/
-RUN apt-get update && apt-get install -y git wget libgeos-dev gcc \
-    libglib2.0-dev libsm6 libxext6 libxrender-dev
-RUN pip3 install EasyDict==1.7 opencv-python==3.4.8.29 shapely==1.6.4 Cython \
-    pandas pyyaml json_tricks scikit-image yacs>=0.1.5 \
+    mv /tmp/{cuda.list,nvidia-ml.list} /etc/apt/sources.list.d/ && rm -rf /var/lib/apt/lists/*;
+RUN apt-get update && apt-get install --no-install-recommends -y git wget libgeos-dev gcc \
+    libglib2.0-dev libsm6 libxext6 libxrender-dev && rm -rf /var/lib/apt/lists/*;
+RUN pip3 install --no-cache-dir EasyDict==1.7 opencv-python==3.4.8.29 shapely==1.6.4 Cython \
+    pandas pyyaml json_tricks scikit-image yacs >=0.1.5 \
     tensorboardX==1.6 pycocotools gdown
 WORKDIR /tmp
 RUN mkdir -p images annot /models/vision/pose_estimation
@@ -63,12 +63,12 @@ RUN mv pose_hrnet_w32_256x256.onnx input.in output.in /models/vision/pose_estima
 WORKDIR /tmp
 ARG YOLOV5L_URI=https://github.com/ultralytics/yolov5
 ARG YOLOv5_VERSION=v6.1
-RUN apt install -y mesa-utils libgl1-mesa-glx
+RUN apt install --no-install-recommends -y mesa-utils libgl1-mesa-glx && rm -rf /var/lib/apt/lists/*;
 RUN git clone ${YOLOV5L_URI}
 WORKDIR yolov5
 RUN git checkout -b tmp 7043872
-RUN pip3 install -r requirements.txt  # base requirements
-RUN pip3 install coremltools>=4.1 onnx>=1.8.1 scikit-learn==0.19.2
+RUN pip3 install --no-cache-dir -r requirements.txt# base requirements
+RUN pip3 install --no-cache-dir coremltools >=4.1 onnx >=1.8.1 scikit-learn==0.19.2
 RUN PYTHONPATH=/tmp/yolov5 python3 export.py --include onnx \
     --weights ${YOLOV5L_URI}/releases/download/${YOLOv5_VERSION}/yolov5l.pt --img 640 --batch 1
 WORKDIR /models/vision/detection/yolo
@@ -76,7 +76,7 @@ RUN mv /tmp/yolov5/yolov5l.onnx .
 
 # ONNX models
 FROM alpine/git:v2.30.1 AS ONNX
-RUN apk add git-lfs
+RUN apk add --no-cache git-lfs
 WORKDIR /tmp
 RUN git clone https://github.com/onnx/models
 WORKDIR /tmp/models
@@ -124,7 +124,7 @@ RUN mv onnx/onnx/backend/test/data/node /unittests
 
 # MNIST Simple TF Model
 FROM tensorflow/tensorflow:1.14.0 AS TF
-RUN apt-get install -y wget
+RUN apt-get install --no-install-recommends -y wget && rm -rf /var/lib/apt/lists/*;
 WORKDIR mnist_simple
 COPY scripts/mnist_simple_train.py .
 RUN python mnist_simple_train.py
@@ -137,27 +137,27 @@ RUN wget -qO- https://web.archive.org/web/20160828233817/http://yann.lecun.com/e
 FROM curlimages/curl:7.76.0 As Data
 RUN mkdir -p /tmp/models/vision/test_images
 WORKDIR /tmp/models/vision/test_images
-RUN curl -o plane.jpg http://images.cocodataset.org/test2017/000000030207.jpg
-RUN curl -o food.jpg http://images.cocodataset.org/test2017/000000228503.jpg
-RUN curl -o sport.jpg http://images.cocodataset.org/test2017/000000133861.jpg
-RUN curl -o dog.jpg https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg
+RUN curl -f -o plane.jpg https://images.cocodataset.org/test2017/000000030207.jpg
+RUN curl -f -o food.jpg https://images.cocodataset.org/test2017/000000228503.jpg
+RUN curl -f -o sport.jpg https://images.cocodataset.org/test2017/000000133861.jpg
+RUN curl -f -o dog.jpg https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg
 RUN mkdir -p /tmp/models/detection
 WORKDIR /tmp/models/detection
-RUN curl -o test.jpg http://images.cocodataset.org/test2017/000000133861.jpg
+RUN curl -f -o test.jpg https://images.cocodataset.org/test2017/000000133861.jpg
 RUN mkdir -p /tmp/models/vision/classification/caffenet
 WORKDIR /tmp/models/vision/classification/caffenet
-RUN curl -o caffenet.prototxt https://raw.githubusercontent.com/BVLC/caffe/master/models/bvlc_reference_caffenet/deploy.prototxt
-RUN curl -o caffenet.caffemodel http://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel
+RUN curl -f -o caffenet.prototxt https://raw.githubusercontent.com/BVLC/caffe/master/models/bvlc_reference_caffenet/deploy.prototxt
+RUN curl -f -o caffenet.caffemodel https://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel
 RUN mkdir -p /tmp/models/vision/detection/yolo
 WORKDIR /tmp/models/vision/detection/yolo
-RUN curl -o test.jpg http://images.cocodataset.org/test2017/000000133861.jpg
-RUN curl -O https://raw.githubusercontent.com/AlexeyAB/darknet/master/data/person.jpg
-RUN curl -O https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/zidane.jpg
+RUN curl -f -o test.jpg https://images.cocodataset.org/test2017/000000133861.jpg
+RUN curl -f -O https://raw.githubusercontent.com/AlexeyAB/darknet/master/data/person.jpg
+RUN curl -f -O https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/zidane.jpg
 
 
 # Collect all Models & Data
 FROM alpine
-RUN apk add tree
+RUN apk add --no-cache tree
 COPY --from=PT /models /models
 COPY --from=ONNX /models /models
 COPY --from=HRNET /models /models