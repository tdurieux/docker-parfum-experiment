diff --git a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/aws/sagemaker-pytorch-inference-toolkit/docker/1.5.0/py3/Dockerfile.cpu b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/aws/sagemaker-pytorch-inference-toolkit/docker/1.5.0/py3/Dockerfile.cpu/repaired.Dockerfile
index 2c13e9e..7b982ec 100644
--- a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/aws/sagemaker-pytorch-inference-toolkit/docker/1.5.0/py3/Dockerfile.cpu
+++ b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/aws/sagemaker-pytorch-inference-toolkit/docker/1.5.0/py3/Dockerfile.cpu/repaired.Dockerfile
@@ -31,9 +31,9 @@ RUN apt-get update && apt-get install -y --no-install-recommends \
     openjdk-8-jdk-headless \
     vim \
     wget \
-    zlib1g-dev
+    zlib1g-dev && rm -rf /var/lib/apt/lists/*;
 
-RUN curl -L -o ~/miniconda.sh https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh \
+RUN curl -f -L -o ~/miniconda.sh https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh \
  && chmod +x ~/miniconda.sh \
  && ~/miniconda.sh -b -p /opt/conda \
  && rm ~/miniconda.sh \
@@ -58,14 +58,14 @@ RUN conda install -c \
     h5py==2.9.0 \
     requests==2.22.0 \
  && conda clean -ya \
- && pip install --upgrade pip --trusted-host pypi.org --trusted-host files.pythonhosted.org \
+ && pip install --no-cache-dir --upgrade pip --trusted-host pypi.org --trusted-host \
  && ln -s /opt/conda/bin/pip /usr/local/bin/pip3 \
- && pip install mxnet-model-server==$MMS_VERSION
+ && pip install --no-cache-dir mxnet-model-server==$MMS_VERSION
 
  # Uninstall and re-install torch and torchvision from the PyTorch website
 RUN pip uninstall -y torch \
  && pip uninstall -y torchvision \
- && pip install torch==$PYTORCH_VERSION+cpu torchvision==$TORCHVISION_VERSION+cpu -f https://download.pytorch.org/whl/torch_stable.html
+ && pip install --no-cache-dir torch==$PYTORCH_VERSION+cpu torchvision==$TORCHVISION_VERSION+cpu -f https://download.pytorch.org/whl/torch_stable.html
 
 RUN useradd -m model-server \
  && mkdir -p /home/model-server/tmp \
@@ -78,10 +78,10 @@ RUN chmod +x /usr/local/bin/dockerd-entrypoint.py
 
 RUN pip install --no-cache-dir "sagemaker-pytorch-inference<2"
 
-RUN curl https://aws-dlc-licenses.s3.amazonaws.com/pytorch-1.5.0/license.txt -o /license.txt
+RUN curl -f https://aws-dlc-licenses.s3.amazonaws.com/pytorch-1.5.0/license.txt -o /license.txt
 
 RUN conda install -y -c conda-forge pyyaml==5.3.1
-RUN pip install  sagemaker-containers==2.8.6 pillow==7.1.0 awscli
+RUN pip install --no-cache-dir sagemaker-containers==2.8.6 pillow==7.1.0 awscli
 
 EXPOSE 8080 8081
 ENTRYPOINT ["python", "/usr/local/bin/dockerd-entrypoint.py"]