{
  "startTime": 1674250729860,
  "endTime": 1674250730963,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 47,
        "lineEnd": 47,
        "columnStart": 4,
        "columnEnd": 100
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 100,
        "lineEnd": 100,
        "columnStart": 4,
        "columnEnd": 86
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 82,
        "lineEnd": 82,
        "columnStart": 4,
        "columnEnd": 91
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 84,
        "lineEnd": 84,
        "columnStart": 4,
        "columnEnd": 48
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 39,
        "lineEnd": 41,
        "columnStart": 4,
        "columnEnd": 18
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 19,
        "lineEnd": 36,
        "columnStart": 4,
        "columnEnd": 14
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 39,
        "lineEnd": 41,
        "columnStart": 4,
        "columnEnd": 18
      }
    }
  ],
  "repairedSmells": [
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 39,
        "lineEnd": 41,
        "columnStart": 4,
        "columnEnd": 18
      }
    }
  ],
  "repairedDockerfile": "FROM nvidia/cuda:10.1-cudnn7-devel-ubuntu16.04\n# NCCL_VERSION=2.4.7, CUDNN_VERSION=7.6.2.24\nLABEL maintainer=\"Amazon AI\"\nLABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n\n# Add arguments to achieve the version, python and url\nARG PYTHON_VERSION=3.6.6\nARG PYTORCH_VERSION=1.3.1\nARG TORCHVISION_VERSION=0.4.2\nARG MMS_VERSION=1.0.8\n\n# See http://bugs.python.org/issue19846\nENV LANG C.UTF-8\nENV LD_LIBRARY_PATH /opt/conda/lib/:$LD_LIBRARY_PATH\nENV PATH /opt/conda/bin:$PATH\nENV SAGEMAKER_SERVING_MODULE sagemaker_pytorch_serving_container.serving:main\nENV TEMP=/home/model-server/tmp\n\nRUN apt-get update \\\n && apt-get install -y --allow-downgrades --allow-change-held-packages --no-install-recommends \\\n    build-essential \\\n    ca-certificates \\\n    cmake \\\n    curl \\\n    git \\\n    jq \\\n    libgl1-mesa-glx \\\n    libglib2.0-0 \\\n    libgomp1 \\\n    libibverbs-dev \\\n    libsm6 \\\n    libxext6 \\\n    libxrender-dev \\\n    openjdk-8-jdk-headless \\\n    vim \\\n    wget \\\n    zlib1g-dev && rm -rf /var/lib/apt/lists/*;\n\n# Install OpenSSH. Allow OpenSSH to talk to containers without asking for confirmation\nRUN apt-get install -y --no-install-recommends \\\n    openssh-client \\\n    openssh-server \\\n && mkdir -p /var/run/sshd \\\n && cat /etc/ssh/ssh_config | grep -v StrictHostKeyChecking > /etc/ssh/ssh_config.new \\\n && echo \"    StrictHostKeyChecking no\" >> /etc/ssh/ssh_config.new \\\n && mv /etc/ssh/ssh_config.new /etc/ssh/ssh_configs && rm -rf /var/lib/apt/lists/*;\n\nRUN curl -f -o ~/miniconda.sh -O  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh \\\n && chmod +x ~/miniconda.sh \\\n && ~/miniconda.sh -b -p /opt/conda \\\n && rm ~/miniconda.sh \\\n && /opt/conda/bin/conda update conda \\\n && /opt/conda/bin/conda install -y \\\n    python=$PYTHON_VERSION \\\n    cython==0.29.12 \\\n    ipython==7.7.0 \\\n    mkl-include==2019.4 \\\n    mkl==2019.4 \\\n    numpy==1.16.4 \\\n    scipy==1.3.0 \\\n    typing==3.6.4 \\\n && /opt/conda/bin/conda clean -ya\n\nRUN conda install -c \\\n    pytorch magma-cuda100 \\\n && conda install -c \\\n    conda-forge \\\n    awscli==1.16.296 \\\n    opencv==4.0.1 \\\n && conda install -y \\\n    scikit-learn==0.21.2 \\\n    pandas==0.25.0 \\\n    pillow==6.2.1 \\\n    h5py==2.9.0 \\\n    requests==2.22.0 \\\n && conda install -c \\\n    pytorch \\\n    pytorch==$PYTORCH_VERSION \\\n    torchvision==$TORCHVISION_VERSION \\\n    cudatoolkit=10.0  \\\n && conda clean -ya \\\n && /opt/conda/bin/conda config --set ssl_verify False \\\n && pip install --no-cache-dir --upgrade pip --trusted-host pypi.org --trusted-host \\\n && ln -s /opt/conda/bin/pip /usr/local/bin/pip3 \\\n && pip install --no-cache-dir mxnet-model-server==$MMS_VERSION\n\nRUN useradd -m model-server \\\n && mkdir -p /home/model-server/tmp \\\n && chown -R model-server /home/model-server\n\nCOPY mms-entrypoint.py /usr/local/bin/dockerd-entrypoint.py\nCOPY config.properties /home/model-server\n\nRUN chmod +x /usr/local/bin/dockerd-entrypoint.py\n\nCOPY sagemaker_pytorch_inference.tar.gz /sagemaker_pytorch_inference.tar.gz\nRUN pip install --no-cache-dir \\\n    /sagemaker_pytorch_inference.tar.gz \\\n && rm /sagemaker_pytorch_inference.tar.gz\n\nRUN curl -f https://aws-dlc-licenses.s3.amazonaws.com/pytorch/license.txt -o /license.txt\n\nEXPOSE 8080 8081\nENTRYPOINT [\"python\", \"/usr/local/bin/dockerd-entrypoint.py\"]\nCMD [\"mxnet-model-server\", \"--start\", \"--mms-config\", \"/home/model-server/config.properties\"]\n"
}