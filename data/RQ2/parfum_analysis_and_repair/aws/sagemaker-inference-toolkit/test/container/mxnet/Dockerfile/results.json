{
  "startTime": 1674250520336,
  "endTime": 1674250521458,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 120,
        "lineEnd": 120,
        "columnStart": 4,
        "columnEnd": 94
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 92,
        "lineEnd": 92,
        "columnStart": 4,
        "columnEnd": 107
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 93,
        "lineEnd": 93,
        "columnStart": 4,
        "columnEnd": 107
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 94,
        "lineEnd": 94,
        "columnStart": 4,
        "columnEnd": 70
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 99,
        "lineEnd": 99,
        "columnStart": 4,
        "columnEnd": 105
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 100,
        "lineEnd": 100,
        "columnStart": 4,
        "columnEnd": 105
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 101,
        "lineEnd": 101,
        "columnStart": 4,
        "columnEnd": 70
      }
    },
    {
      "rule": "configureShouldUseBuildFlag",
      "position": {
        "lineStart": 43,
        "lineEnd": 43,
        "columnStart": 4,
        "columnEnd": 15
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 41,
        "lineEnd": 41,
        "columnStart": 4,
        "columnEnd": 39
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 47,
        "lineEnd": 55,
        "columnStart": 4,
        "columnEnd": 14
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM public.ecr.aws/e2s1w5p1/ubuntu:16.04\n\nLABEL maintainer=\"Amazon AI\"\n\n# Specify accept-bind-to-port LABEL for inference pipelines to use SAGEMAKER_BIND_TO_PORT\n# https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipeline-real-time.html\nLABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n# Specify multi-models LABEL to indicate container is capable of loading and serving multiple models concurrently\n# https://docs.aws.amazon.com/sagemaker/latest/dg/build-multi-model-build-container.html\nLABEL com.amazonaws.sagemaker.capabilities.multi-models=true\n\nARG MMS_VERSION=1.1.2\nARG MX_URL=https://aws-mxnet-pypi.s3-us-west-2.amazonaws.com/1.6.0/aws_mxnet_mkl-1.6.0-py2.py3-none-manylinux1_x86_64.whl\nARG PYTHON=python3\nARG PYTHON_PIP=python3-pip\nARG PIP=pip3\nARG PYTHON_VERSION=3.6.8\n\nENV PYTHONDONTWRITEBYTECODE=1 \\\n    PYTHONUNBUFFERED=1 \\\n    LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\" \\\n    PYTHONIOENCODING=UTF-8 \\\n    LANG=C.UTF-8 \\\n    LC_ALL=C.UTF-8 \\\n    TEMP=/home/model-server/tmp\n\nRUN apt-get update \\\n && apt-get -y install --no-install-recommends \\\n    build-essential \\\n    ca-certificates \\\n    curl \\\n    git \\\n    libopencv-dev \\\n    openjdk-8-jdk-headless \\\n    vim \\\n    wget \\\n    zlib1g-dev \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n\nRUN wget https://www.python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tgz \\\n && tar -xvf Python-$PYTHON_VERSION.tgz \\\n && cd Python-$PYTHON_VERSION \\\n && ./configure --build=\"$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)\" \\\n && make \\\n && make install \\\n && apt-get update \\\n && apt-get install -y --no-install-recommends \\\n    libreadline-gplv2-dev \\\n    libncursesw5-dev \\\n    libssl-dev \\\n    libsqlite3-dev \\\n    tk-dev \\\n    libgdbm-dev \\\n    libc6-dev \\\n    libbz2-dev \\\n && make \\\n && make install \\\n && rm -rf ../Python-$PYTHON_VERSION* \\\n && ln -s /usr/local/bin/pip3 /usr/bin/pip && rm Python-$PYTHON_VERSION.tgz && rm -rf /var/lib/apt/lists/*;\n\nRUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n\nRUN ${PIP} --no-cache-dir install --upgrade \\\n    pip \\\n    setuptools\n\nWORKDIR /\n\nCOPY mxnet/sagemaker_mxnet_inference.tar.gz /sagemaker_mxnet_inference.tar.gz\nCOPY mxnet/sagemaker_inference.tar.gz /sagemaker_inference.tar.gz\n\nRUN ${PIP} install --no-cache-dir \\\n    ${MX_URL} \\\n    git+https://github.com/dmlc/gluon-nlp.git@v0.9.0 \\\n    multi-model-server==$MMS_VERSION \\\n    keras-mxnet==2.2.4.1 \\\n    numpy==1.17.4 \\\n    onnx==1.4.1 \\\n    /sagemaker_mxnet_inference.tar.gz \\\n    /sagemaker_inference.tar.gz \\\n && rm /sagemaker_mxnet_inference.tar.gz /sagemaker_inference.tar.gz\n\n# This is here to make our installed version of OpenCV work.\n# https://stackoverflow.com/questions/29274638/opencv-libdc1394-error-failed-to-initialize-libdc1394\n# TODO: Should we be installing OpenCV in our image like this? Is there another way we can fix this?\nRUN ln -s /dev/null /dev/raw1394\n\n##################################\n# download models to model_store\n##################################\nWORKDIR /opt/ml/models/resnet_152/model\nRUN wget -O model-0000.params https://data.mxnet.io/models/imagenet/resnet/152-layers/resnet-152-0000.params \\\n && wget -O model-symbol.json https://data.mxnet.io/models/imagenet/resnet/152-layers/resnet-152-symbol.json \\\n && wget -O synset.txt https://data.mxnet.io/models/imagenet/synset.txt \\\n && echo '[{\"shape\": [1, 3, 224, 224], \"name\": \"data\"}]' > model-shapes.json \\\n && cd /\n\nWORKDIR /opt/ml/models/resnet_18/model\nRUN wget -O model-0000.params https://data.mxnet.io/models/imagenet/resnet/18-layers/resnet-18-0000.params \\\n && wget -O model-symbol.json https://data.mxnet.io/models/imagenet/resnet/18-layers/resnet-18-symbol.json \\\n && wget -O synset.txt https://data.mxnet.io/models/imagenet/synset.txt \\\n && echo '[{\"shape\": [1, 3, 224, 224], \"name\": \"data\"}]' > model-shapes.json \\\n && cd /\n\nWORKDIR /\n\nRUN useradd -m model-server \\\n && mkdir -p /home/model-server/tmp \\\n && chown -R model-server /home/model-server\n\nCOPY mxnet/mms_entrypoint.py /usr/local/bin/dockerd_entrypoint.py\nCOPY mxnet/config.properties /home/model-server\n\n# TEST: model_dir -> /opt/ml/models/<model_name>/inference.py\nCOPY mxnet/inference.py /opt/ml/models/resnet_18/code/inference.py\nCOPY mxnet/inference.py /opt/ml/models/resnet_152/code/inference.py\n\nRUN chmod +x /usr/local/bin/dockerd_entrypoint.py\n\nRUN curl -f https://aws-dlc-licenses.s3.amazonaws.com/aws-mxnet-1.6.0/license.txt -o /license.txt\n\nEXPOSE 8080 8081\nENTRYPOINT [\"python\", \"/usr/local/bin/dockerd_entrypoint.py\"]\nCMD [\"multi-model-server\", \"--start\", \"--mms-config\", \"/home/model-server/config.properties\"]\n"
}