{
  "startTime": 1674253353467,
  "endTime": 1674253354840,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 115,
        "lineEnd": 115,
        "columnStart": 4,
        "columnEnd": 108
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 79,
        "lineEnd": 79,
        "columnStart": 5,
        "columnEnd": 77
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# Expecting base image to be the image built by ./Dockerfile.e3.gpu\nARG BASE_IMAGE=\"\"\n\nFROM $BASE_IMAGE\n\nLABEL maintainer=\"Amazon AI\"\nLABEL dlc_major_version=\"1\"\n\nARG PYTHON=python3\nARG PYTHON_VERSION=3.8.10\nARG PYTHON_SHORT_VERSION=3.8\nARG METIS=metis-5.1.0\nARG RMM_VERSION=0.15.0\n\n# The smdebug pipeline relies for following format to perform string replace and trigger DLC pipeline for validating\n# the nightly builds. Therefore, while updating the smdebug version, please ensure that the format is not disturbed.\nARG SMDEBUG_VERSION=1.0.13\n\nENV SAGEMAKER_TRAINING_MODULE=sagemaker_pytorch_container.training:main\n\n# swap the pytorch training wheel with additional smdebug and smmdp features\nARG PT_TRAINING_URL=https://aws-pytorch-cicd-v3-binaries.s3.us-west-2.amazonaws.com/r1.10.2_aws_v3/20220209-025350/bea1183a47174ef43ab9874c643357fa77755932/gpu/torch-1.10.2%2Bcu113-cp38-cp38-manylinux1_x86_64.whl\nARG SMD_MODEL_PARALLEL_URL=https://sagemaker-distributed-model-parallel.s3.us-west-2.amazonaws.com/pytorch-1.10.0/build-artifacts/2022-04-14-03-58/smdistributed_modelparallel-1.8.1-cp38-cp38-linux_x86_64.whl\nARG SMDATAPARALLEL_BINARY=https://smdataparallel.s3.amazonaws.com/binary/pytorch/1.10.2/cu113/2022-02-18/smdistributed_dataparallel-1.4.0-cp38-cp38-linux_x86_64.whl\n# Install scikit-learn and pandas\nRUN conda install -y -c conda-forge \\\n    scikit-learn \\\n    pandas\n\nWORKDIR /\n\n# Install libboost from source. This package is needed for smdataparallel functionality [for networking asynchronous IO].\nRUN wget https://sourceforge.net/projects/boost/files/boost/1.73.0/boost_1_73_0.tar.gz/download -O boost_1_73_0.tar.gz \\\n  && tar -xzf boost_1_73_0.tar.gz \\\n  && cd boost_1_73_0 \\\n  && ./bootstrap.sh \\\n  && ./b2 threading=multi --prefix=/opt/conda -j 64 cxxflags=-fPIC cflags=-fPIC install || true \\\n  && cd .. \\\n  && rm -rf boost_1_73_0.tar.gz \\\n  && rm -rf boost_1_73_0 \\\n  && cd /opt/conda/include/boost\n\nWORKDIR /opt/pytorch\n\n# Copy workaround script for incorrect hostname\nCOPY changehostname.c /\nCOPY start_with_right_hostname.sh /usr/local/bin/start_with_right_hostname.sh\n\nWORKDIR /root\n\nRUN pip install --no-cache-dir -U \\\n    # smdebug==${SMDEBUG_VERSION} \\\n    smclarify \\\n    \"sagemaker>=2,<3\" \\\n    sagemaker-experiments==0.* \\\n    sagemaker-pytorch-training\n\n# Install smdebug from souce\nRUN cd /tmp \\\n  && git clone -b ${SMDEBUG_VERSION} https://github.com/awslabs/sagemaker-debugger \\\n  && cd sagemaker-debugger \\\n  && python setup.py install \\\n  && rm -rf /tmp/*\n\n# Install extra packages\n# numba 0.54 only works with numpy>=1.20. See https://github.com/numba/numba/issues/7339\nRUN pip install --no-cache-dir -U \\\n    \"bokeh>=2.3,<3\" \\\n    \"imageio>=2.9,<3\" \\\n    \"opencv-python>=4.3,<5\" \\\n    \"plotly>=5.1,<6\" \\\n    \"seaborn>=0.11,<1\" \\\n    \"numba<0.54\" \\\n    \"shap>=0.39,<1\" \\\n && pip uninstall -y torch \\\n && pip install --no-cache-dir -U ${PT_TRAINING_URL}\n\n# install metis\nRUN rm /etc/apt/sources.list.d/* \\\n  && wget -nv https://glaros.dtc.umn.edu/gkhome/fetch/sw/metis/${METIS}.tar.gz \\\n  && gunzip -f ${METIS}.tar.gz \\\n  && tar -xvf ${METIS}.tar \\\n  && cd ${METIS} \\\n  && apt-get update \\\n  && make config shared=1 \\\n  && make install \\\n  && cd .. \\\n  && rm -rf ${METIS}.tar* \\\n  && rm -rf ${METIS} \\\n  && rm -rf /var/lib/apt/lists/* \\\n  && apt-get clean\n\n# Install RAPIDSMemoryManager.\n# Requires cmake>=3.14.\nRUN  wget -nv https://github.com/rapidsai/rmm/archive/v${RMM_VERSION}.tar.gz \\\n  && tar -xvf v${RMM_VERSION}.tar.gz \\\n  && cd rmm-${RMM_VERSION} \\\n  && INSTALL_PREFIX=/usr/local ./build.sh librmm \\\n  && cd .. \\\n  && rm -rf v${RMM_VERSION}.tar* \\\n  && rm -rf rmm-${RMM_VERSION}\n\n# Install SM Distributed Modelparallel binary\nRUN pip install --no-cache-dir -U ${SMD_MODEL_PARALLEL_URL}\n\n# Install SM Distributed DataParallel binary\nRUN SMDATAPARALLEL_PT=1 pip install --no-cache-dir ${SMDATAPARALLEL_BINARY}\n\nENV LD_LIBRARY_PATH=\"/opt/conda/lib/python${PYTHON_SHORT_VERSION}/site-packages/smdistributed/dataparallel/lib:$LD_LIBRARY_PATH\"\n\nWORKDIR /\n\nRUN chmod +x /usr/local/bin/start_with_right_hostname.sh\n\nRUN HOME_DIR=/root \\\n && curl -f -o ${HOME_DIR}/oss_compliance.zip https://aws-dlinfra-utilities.s3.amazonaws.com/oss_compliance.zip \\\n && unzip ${HOME_DIR}/oss_compliance.zip -d ${HOME_DIR}/ \\\n && cp ${HOME_DIR}/oss_compliance/test/testOSSCompliance /usr/local/bin/testOSSCompliance \\\n && chmod +x /usr/local/bin/testOSSCompliance \\\n && chmod +x ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh \\\n && ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh ${HOME_DIR} ${PYTHON} \\\n && rm -rf ${HOME_DIR}/oss_compliance* \\\n && rm -rf /tmp/tmp*\n\nENTRYPOINT [\"bash\", \"-m\", \"start_with_right_hostname.sh\"]\nCMD [\"/bin/bash\"]\n"
}