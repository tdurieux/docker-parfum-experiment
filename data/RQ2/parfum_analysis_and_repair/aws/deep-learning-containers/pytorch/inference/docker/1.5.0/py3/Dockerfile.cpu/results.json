{
  "startTime": 1674251533414,
  "endTime": 1674251534232,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 40,
        "lineEnd": 40,
        "columnStart": 4,
        "columnEnd": 99
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 95,
        "lineEnd": 95,
        "columnStart": 4,
        "columnEnd": 92
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 114,
        "lineEnd": 114,
        "columnStart": 4,
        "columnEnd": 108
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 69,
        "lineEnd": 69,
        "columnStart": 4,
        "columnEnd": 91
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 71,
        "lineEnd": 71,
        "columnStart": 4,
        "columnEnd": 48
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 99,
        "lineEnd": 111,
        "columnStart": 4,
        "columnEnd": 22
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 21,
        "lineEnd": 38,
        "columnStart": 22,
        "columnEnd": 14
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM ubuntu:16.04\n\nLABEL maintainer=\"Amazon AI\"\nLABEL dlc_major_version=\"1\"\n# Specify accept-bind-to-port LABEL for inference pipelines to use SAGEMAKER_BIND_TO_PORT\n# https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipeline-real-time.html\nLABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n# Specify multi-models LABEL to indicate container is capable of loading and serving multiple models concurrently\n# https://docs.aws.amazon.com/sagemaker/latest/dg/build-multi-model-build-container.html\nLABEL com.amazonaws.sagemaker.capabilities.multi-models=true\n\nARG PYTHON_VERSION=3.6.13\nARG MMS_VERSION=1.1.2\n\n# See http://bugs.python.org/issue19846\nENV LANG C.UTF-8\nENV LD_LIBRARY_PATH /opt/conda/lib/:$LD_LIBRARY_PATH\nENV PATH /opt/conda/bin:$PATH\nENV SAGEMAKER_SERVING_MODULE sagemaker_pytorch_serving_container.serving:main\nENV TEMP=/home/model-server/tmp\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    build-essential \\\n    ca-certificates \\\n    cmake \\\n    curl \\\n    emacs \\\n    git \\\n    jq \\\n    libgl1-mesa-glx \\\n    libglib2.0-0 \\\n    libsm6 \\\n    libxext6 \\\n    libxrender-dev \\\n    openjdk-8-jdk-headless \\\n    vim \\\n    wget \\\n    unzip \\\n    zlib1g-dev && rm -rf /var/lib/apt/lists/*;\n\nRUN curl -f -L -o ~/miniconda.sh https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh \\\n && chmod +x ~/miniconda.sh \\\n && ~/miniconda.sh -b -p /opt/conda \\\n && rm ~/miniconda.sh \\\n && /opt/conda/bin/conda update conda \\\n && /opt/conda/bin/conda install -c conda-forge \\\n    python=$PYTHON_VERSION \\\n && /opt/conda/bin/conda install -y \\\n    # conda 4.9.2 requires ruamel_yaml to be installed. Currently pinned at latest.\n    ruamel_yaml==0.15.87 \\\n    cython==0.29.12 \\\n    ipython==7.7.0 \\\n    mkl-include==2019.4 \\\n    mkl==2019.4 \\\n    numpy==1.16.4 \\\n    scipy==1.3.0 \\\n    typing==3.6.4 \\\n    asn1crypto==1.3.0 \\\n && /opt/conda/bin/conda clean -ya\n\nRUN conda install -c \\\n    conda-forge \\\n    opencv==4.0.1 \\\n && conda install -y \\\n    scikit-learn==0.21.2 \\\n    pandas==0.25.0 \\\n    h5py==2.9.0 \\\n    requests==2.22.0 \\\n && conda clean -ya \\\n && pip install --no-cache-dir --upgrade pip --trusted-host pypi.org --trusted-host \\\n && ln -s /opt/conda/bin/pip /usr/local/bin/pip3 \\\n && pip install --no-cache-dir multi-model-server==$MMS_VERSION\n\n # Uninstall and re-install torch and torchvision from the PyTorch website\nRUN pip uninstall -y torch \\\n && pip install --no-cache-dir -U https://pytorch-aws.s3-us-west-2.amazonaws.com/pytorch-1.5.0/inference/cpu/torch-1.5.0-cp36-cp36m-manylinux1_x86_64.whl \\\n && pip uninstall -y torchvision \\\n && pip install --no-deps --no-cache-dir -U \\\n    https://torchvision-build.s3-us-west-2.amazonaws.com/1.5.0/cpu/torchvision-0.6.0%2Bcpu-cp36-cp36m-linux_x86_64.whl\n\nRUN useradd -m model-server \\\n && mkdir -p /home/model-server/tmp \\\n && chown -R model-server /home/model-server\n\nCOPY mms-entrypoint.py /usr/local/bin/dockerd-entrypoint.py\nCOPY config.properties /home/model-server\n\nRUN chmod +x /usr/local/bin/dockerd-entrypoint.py\n\nADD https://raw.githubusercontent.com/aws/deep-learning-containers/master/src/deep_learning_container.py /usr/local/bin/deep_learning_container.py\n\nRUN chmod +x /usr/local/bin/deep_learning_container.py\n\nRUN pip install --no-cache-dir \"sagemaker-pytorch-inference<2\"\n\nRUN curl -f https://aws-dlc-licenses.s3.amazonaws.com/pytorch-1.5.0/license.txt -o /license.txt\n\n# install PyYAML>=5.4,<5.5 to avoid conflict with latest awscli\nRUN conda install -y -c conda-forge \"PyYAML>=5.4,<5.5\"\nRUN pip install --no-cache-dir \\\n    pillow==7.1.0 \\\n    \"awscli<2\" \\\n\n    \"cryptography>=3.3.2\" \\\n    \"paramiko==2.7.1\" \\\n    \"Flask==1.1.1\" \\\n    \"boto3==1.17.34\" \\\n    \"click==7.1.2\" \\\n    \"gevent==20.5.0\" \\\n    \"gunicorn==20.0.4\" \\\n    \"inotify-simple==1.2.1\" \\\n    \"protobuf==3.11.3\"\n\nRUN HOME_DIR=/root \\\n && curl -f -o ${HOME_DIR}/oss_compliance.zip https://aws-dlinfra-utilities.s3.amazonaws.com/oss_compliance.zip \\\n && unzip ${HOME_DIR}/oss_compliance.zip -d ${HOME_DIR}/ \\\n && cp ${HOME_DIR}/oss_compliance/test/testOSSCompliance /usr/local/bin/testOSSCompliance \\\n && chmod +x /usr/local/bin/testOSSCompliance \\\n && chmod +x ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh \\\n && ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh ${HOME_DIR} ${PYTHON} \\\n && rm -rf ${HOME_DIR}/oss_compliance*\n\nEXPOSE 8080 8081\nENTRYPOINT [\"python\", \"/usr/local/bin/dockerd-entrypoint.py\"]\nCMD [\"multi-model-server\", \"--start\", \"--mms-config\", \"/home/model-server/config.properties\"]\n"
}