{
  "startTime": 1674248179851,
  "endTime": 1674248181464,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 56,
        "lineEnd": 56,
        "columnStart": 4,
        "columnEnd": 99
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 152,
        "lineEnd": 152,
        "columnStart": 4,
        "columnEnd": 108
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 160,
        "lineEnd": 160,
        "columnStart": 4,
        "columnEnd": 91
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 106,
        "lineEnd": 106,
        "columnStart": 4,
        "columnEnd": 91
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 108,
        "lineEnd": 111,
        "columnStart": 4,
        "columnEnd": 25
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 123,
        "lineEnd": 126,
        "columnStart": 4,
        "columnEnd": 21
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 131,
        "lineEnd": 131,
        "columnStart": 4,
        "columnEnd": 22
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 132,
        "lineEnd": 132,
        "columnStart": 4,
        "columnEnd": 39
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 133,
        "lineEnd": 133,
        "columnStart": 4,
        "columnEnd": 49
      }
    },
    {
      "rule": "configureShouldUseBuildFlag",
      "position": {
        "lineStart": 84,
        "lineEnd": 84,
        "columnStart": 4,
        "columnEnd": 39
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM ubuntu:20.04\n\nLABEL maintainer=\"Amazon AI\"\nLABEL dlc_major_version=\"1\"\nLABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\nLABEL com.amazonaws.sagemaker.capabilities.multi-models=true\n\nARG PYTHON=python3\nARG PYTHON_VERSION=3.8.10\nARG OPEN_MPI_VERSION=4.0.1\nARG TS_VERSION=0.5.3\nARG PT_INFERENCE_URL=https://pytorch-ei-binaries.s3.us-west-2.amazonaws.com/r1.9.1_inference/cpu/torch-1.9.1-cp38-cp38-manylinux1_x86_64.whl\nARG PT_TORCHVISION_URL=https://aws-pytorch-cicd-v3-binaries.s3.us-west-2.amazonaws.com/r1.9.1_aws_v3/torchvision/cpu/torchvision-0.10.1%2Bcpu-cp38-cp38-manylinux1_x86_64.whl\nARG PT_TORCHAUDIO_URL=https://pytorch-ei-binaries.s3.us-west-2.amazonaws.com/r1.9.1_inference/cpu/torchaudio-0.9.1-cp38-cp38-linux_x86_64.whl\n\nENV LANG C.UTF-8\nENV LD_LIBRARY_PATH /opt/conda/lib/:$LD_LIBRARY_PATH\nENV PATH /opt/conda/bin:$PATH\nENV SAGEMAKER_SERVING_MODULE sagemaker_pytorch_serving_container.serving:main\nENV TEMP=/home/model-server/tmp\n# Set MKL_THREADING_LAYER=GNU to prevent issues between torch and numpy/mkl\nENV MKL_THREADING_LAYER=GNU\n\nRUN apt-get update \\\n# TODO: Remove systemd upgrade once it is updated in base image\n && apt-get -y upgrade --only-upgrade systemd \\\n && apt-get install -y --no-install-recommends software-properties-common \\\n && add-apt-repository ppa:openjdk-r/ppa \\\n && apt-get update \\\n && apt-get install -y --no-install-recommends \\\n    build-essential \\\n    ca-certificates \\\n    cmake \\\n    curl \\\n    emacs \\\n    git \\\n    jq \\\n    libgl1-mesa-glx \\\n    libglib2.0-0 \\\n    libsm6 \\\n    libxext6 \\\n    libxrender-dev \\\n    openjdk-11-jdk \\\n    openssl \\\n    vim \\\n    wget \\\n    unzip \\\n    zlib1g-dev \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# https://github.com/docker-library/openjdk/issues/261 https://github.com/docker-library/openjdk/pull/263/files\nRUN keytool -importkeystore -srckeystore /etc/ssl/certs/java/cacerts -destkeystore /etc/ssl/certs/java/cacerts.jks -deststoretype JKS -srcstorepass changeit -deststorepass changeit -noprompt; \\\n    mv /etc/ssl/certs/java/cacerts.jks /etc/ssl/certs/java/cacerts; \\\n    /var/lib/dpkg/info/ca-certificates-java.postinst configure;\n\nRUN curl -f -L -o ~/miniconda.sh https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh \\\n && chmod +x ~/miniconda.sh \\\n && ~/miniconda.sh -b -p /opt/conda \\\n && rm ~/miniconda.sh \\\n && /opt/conda/bin/conda install -c conda-forge \\\n    python=$PYTHON_VERSION \\\n && /opt/conda/bin/conda install -y \\\n    # conda 4.10.0 requires ruamel_yaml to be installed. Currently pinned at latest.\n    ruamel_yaml==0.15.100 \\\n    cython \\\n    ipython \\\n    mkl-include \\\n    mkl \\\n    parso \\\n    scipy \\\n    typing \\\n && /opt/conda/bin/conda clean -ya \\\n && /opt/conda/bin/conda update conda\n\n# Conda installs links for libtinfo.so.6 and libtinfo.so.6.2 both\n# Which causes \"/opt/conda/lib/libtinfo.so.6: no version information available\" warning\n# Removing link for libtinfo.so.6. This change is needed only for ubuntu 20.04-conda, and can be reverted\n# once conda fixes the issue: https://github.com/conda/conda/issues/9680\nRUN rm -rf /opt/conda/lib/libtinfo.so.6\n\nRUN wget https://www.open-mpi.org/software/ompi/v4.0/downloads/openmpi-$OPEN_MPI_VERSION.tar.gz \\\n && gunzip -c openmpi-$OPEN_MPI_VERSION.tar.gz | tar xf - \\\n && cd openmpi-$OPEN_MPI_VERSION \\\n && ./configure --build=\"$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)\" --prefix=/home/.openmpi \\\n && make all install \\\n && cd .. \\\n && rm openmpi-$OPEN_MPI_VERSION.tar.gz \\\n && rm -rf openmpi-$OPEN_MPI_VERSION\n\n# The ENV variables declared below are changed in the previous section\n# Grouping these ENV variables in the first section causes\n# ompi_info to fail. This is only observed in CPU containers\nENV PATH=\"$PATH:/home/.openmpi/bin\"\nENV LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/home/.openmpi/lib/\"\nRUN ompi_info --parsable --all | grep mpi_built_with_cuda_support:value\n\nRUN conda install -y -c \\\n    conda-forge \\\n    opencv \\\n    scikit-learn \\\n    pandas \\\n    h5py \\\n    requests \\\n && conda clean -ya\n\nRUN pip install --no-cache-dir --upgrade pip --trusted-host pypi.org --trusted-host \\\n && ln -s /opt/conda/bin/pip /usr/local/bin/pip3 \\\n && pip install --no-cache-dir packaging==20.4 \\\n    enum-compat==0.0.3 \\\n    \"numpy>=1.22.2\" \\\n    \"cryptography>=3.3.2\"\n\n# Uninstall and re-install torch and torchvision from the PyTorch website\nRUN pip uninstall -y torch \\\n && pip install --no-cache-dir -U $PT_INFERENCE_URL \\\n && pip uninstall -y torchvision \\\n && pip install --no-deps --no-cache-dir -U $PT_TORCHVISION_URL \\\n && pip uninstall -y torchaudio \\\n && pip install --no-deps --no-cache-dir -U $PT_TORCHAUDIO_URL\n\n\nRUN conda install -y -c conda-forge \"pyyaml>=5.4,<5.5\"\nRUN pip install --no-cache-dir \\\n    \"Pillow>=9.0.1\" \\\n    \"awscli<2\" \\\n    \"urllib3>=1.26.5\"\n\nRUN pip install --no-cache-dir \"sagemaker-pytorch-inference==2.0.6\"\n\nRUN pip uninstall -y model-archiver multi-model-server \\\n && pip install --no-cache-dir captum \\\n && pip install --no-cache-dir torchserve==$TS_VERSION \\\n && pip install --no-cache-dir torch-model-archiver==$TS_VERSION\n\nRUN cd tmp/ \\\n && rm -rf tmp*\n\nRUN useradd -m model-server \\\n && mkdir -p /home/model-server/tmp /opt/ml/model \\\n && chown -R model-server /home/model-server /opt/ml/model\n\nCOPY torchserve-entrypoint.py /usr/local/bin/dockerd-entrypoint.py\nCOPY config.properties /home/model-server\n\nRUN chmod +x /usr/local/bin/dockerd-entrypoint.py\n\nCOPY deep_learning_container.py /usr/local/bin/deep_learning_container.py\n\nRUN chmod +x /usr/local/bin/deep_learning_container.py\n\nRUN HOME_DIR=/root \\\n && curl -f -o ${HOME_DIR}/oss_compliance.zip https://aws-dlinfra-utilities.s3.amazonaws.com/oss_compliance.zip \\\n && unzip ${HOME_DIR}/oss_compliance.zip -d ${HOME_DIR}/ \\\n && cp ${HOME_DIR}/oss_compliance/test/testOSSCompliance /usr/local/bin/testOSSCompliance \\\n && chmod +x /usr/local/bin/testOSSCompliance \\\n && chmod +x ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh \\\n && ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh ${HOME_DIR} ${PYTHON} \\\n && rm -rf ${HOME_DIR}/oss_compliance*\n\nRUN curl -f -o /license.txt https://aws-dlc-licenses.s3.amazonaws.com/pytorch-1.9/license.txt\n\nEXPOSE 8080 8081\nENTRYPOINT [\"python\", \"/usr/local/bin/dockerd-entrypoint.py\"]\nCMD [\"torchserve\", \"--start\", \"--ts-config\", \"/home/model-server/config.properties\", \"--model-store\", \"/home/model-server/\"]\n"
}