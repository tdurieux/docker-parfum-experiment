{
  "startTime": 1674248579594,
  "endTime": 1674248581029,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 148,
        "lineEnd": 148,
        "columnStart": 4,
        "columnEnd": 150
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 226,
        "lineEnd": 226,
        "columnStart": 4,
        "columnEnd": 108
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 234,
        "lineEnd": 234,
        "columnStart": 4,
        "columnEnd": 92
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 277,
        "lineEnd": 277,
        "columnStart": 4,
        "columnEnd": 108
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 181,
        "lineEnd": 181,
        "columnStart": 4,
        "columnEnd": 91
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 203,
        "lineEnd": 203,
        "columnStart": 4,
        "columnEnd": 22
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 204,
        "lineEnd": 204,
        "columnStart": 4,
        "columnEnd": 41
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 205,
        "lineEnd": 205,
        "columnStart": 4,
        "columnEnd": 51
      }
    },
    {
      "rule": "configureShouldUseBuildFlag",
      "position": {
        "lineStart": 127,
        "lineEnd": 127,
        "columnStart": 4,
        "columnEnd": 51
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "ARG PYTHON=python3\nARG PYTHON_VERSION=3.8.13\n\n# PyTorch Binaries\nARG PT_INFERENCE_URL=https://aws-pytorch-cicd-v3-binaries.s3.us-west-2.amazonaws.com/r1.11.0_v3_e3/20220316-044906/9a915205c493de013250347af38ad1083854bc09/gpu/torch-1.11.0%2Bcu115-cp38-cp38-linux_x86_64.whl\nARG PT_TORCHVISION_URL=https://download.pytorch.org/whl/cu115/torchvision-0.12.0%2Bcu115-cp38-cp38-linux_x86_64.whl\nARG PT_TORCHAUDIO_URL=https://download.pytorch.org/whl/cu115/torchaudio-0.11.0%2Bcu115-cp38-cp38-linux_x86_64.whl\nARG PT_TORCHDATA_URL=https://aws-pytorch-cicd-v3-binaries.s3.us-west-2.amazonaws.com/r1.11.0_v3_e3/aws-torchdata/torchdata-0.4.0-cp38-cp38-linux_x86_64.whl\n\n##############################################################################\n#  _____ _____   ___                              ____           _\n# | ____|___ /  |_ _|_ __ ___   __ _  __ _  ___  |  _ \\ ___  ___(_)_ __   ___\n# |  _|   |_ \\   | || '_ ` _ \\ / _` |/ _` |/ _ \\ | |_) / _ \\/ __| | '_ \\ / _ \\\n# | |___ ___) |  | || | | | | | (_| | (_| |  __/ |  _ <  __/ (__| | |_) |  __/\n# |_____|____/  |___|_| |_| |_|\\__,_|\\__, |\\___| |_| \\_\\___|\\___|_| .__/ \\___|\n#                                    |___/                        |_|\n##############################################################################\n\nFROM nvidia/cuda:11.5.1-base-ubuntu20.04 AS e3\n\nLABEL maintainer=\"Amazon AI\"\nLABEL dlc_major_version=\"1\"\n\nARG PYTHON\nARG PYTHON_VERSION\nARG MAMBA_VERSION=4.12.0-2\n\n# PyTorch Binaries\nARG PT_INFERENCE_URL\nARG PT_TORCHVISION_URL\nARG PT_TORCHAUDIO_URL\nARG PT_TORCHDATA_URL\n\nARG CUBLAS_VERSION=11.7.4.6\nARG OMPI_VERSION=4.1.1\nARG TS_VERSION=0.6.0\n\nARG DEBIAN_FRONTEND=noninteractive\n\n# See http://bugs.python.org/issue19846\nENV LANG C.UTF-8\nENV LD_LIBRARY_PATH=\"/opt/conda/lib:${LD_LIBRARY_PATH}\"\nENV PATH /opt/conda/bin:$PATH\nENV TEMP=/home/model-server/tmp\nENV TORCH_CUDA_ARCH_LIST=\"3.7 5.0 7.0+PTX 8.0\"\n\nENV NCCL_VERSION=2.11.4\nENV NVML_VERSION=11.5.50\n\n# Set MKL_THREADING_LAYER=GNU to prevent issues between torch and numpy/mkl\nENV MKL_THREADING_LAYER=GNU\nENV DLC_CONTAINER_TYPE=inference\n\n\nRUN apt-get update \\\n# TODO: Remove systemd upgrade once it is updated in base image\n && apt-get -y upgrade --only-upgrade systemd \\\n && apt-get install -y --no-install-recommends software-properties-common \\\n && add-apt-repository ppa:openjdk-r/ppa \\\n && apt-get update \\\n && apt-get install -y --allow-downgrades --allow-change-held-packages --no-install-recommends \\\n    build-essential \\\n    ca-certificates \\\n    cmake \\\n    cuda-command-line-tools-11-5 \\\n    cuda-cudart-11-5 \\\n    cuda-libraries-11-5 \\\n    cuda-libraries-dev-11-5 \\\n    curl \\\n    emacs \\\n    git \\\n    jq \\\n    libcublas-11-5=${CUBLAS_VERSION}-1 \\\n    libcublas-dev-11-5=${CUBLAS_VERSION}-1 \\\n    libcudnn8 \\\n    libcufft-dev-11-5 \\\n    libcurand-dev-11-5 \\\n    libcurl4-openssl-dev \\\n    libcusolver-dev-11-5 \\\n    libcusparse-dev-11-5 \\\n    cuda-nvml-dev-11-5=${NVML_VERSION}-1 \\\n    libgl1-mesa-glx \\\n    libglib2.0-0 \\\n    libgomp1 \\\n    libibverbs-dev \\\n    libnuma1 \\\n    libnuma-dev \\\n    libsm6 \\\n    libssl1.1 \\\n    libssl-dev \\\n    libxext6 \\\n    libxrender-dev \\\n    openjdk-11-jdk \\\n    openssl \\\n    vim \\\n    wget \\\n    unzip \\\n    zlib1g-dev \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# Install aws-sdk-cpp s3;transfer modules for torchdata\nRUN git clone --recurse-submodules https://github.com/aws/aws-sdk-cpp \\\n && cd aws-sdk-cpp/ \\\n && mkdir sdk-build \\\n && cd sdk-build \\\n && cmake .. -DCMAKE_BUILD_TYPE=Release -DBUILD_ONLY=\"s3;transfer\" -DAUTORUN_UNIT_TESTS=OFF \\\n && make \\\n && make install \\\n && cd ../.. \\\n && rm -rf aws-sdk-cpp\n\n# Install NCCL\nRUN cd /tmp \\\n && git clone https://github.com/NVIDIA/nccl.git -b v${NCCL_VERSION}-1 \\\n && cd nccl \\\n && make -j64 src.build BUILDDIR=/usr/local \\\n && rm -rf /tmp/nccl\n\n# https://github.com/docker-library/openjdk/issues/261 https://github.com/docker-library/openjdk/pull/263/files\nRUN keytool -importkeystore -srckeystore /etc/ssl/certs/java/cacerts -destkeystore /etc/ssl/certs/java/cacerts.jks -deststoretype JKS -srcstorepass changeit -deststorepass changeit -noprompt; \\\n    mv /etc/ssl/certs/java/cacerts.jks /etc/ssl/certs/java/cacerts; \\\n    /var/lib/dpkg/info/ca-certificates-java.postinst configure;\n\nRUN wget --quiet https://download.open-mpi.org/release/open-mpi/v4.1/openmpi-${OMPI_VERSION}.tar.gz \\\n && gunzip -c openmpi-${OMPI_VERSION}.tar.gz | tar xf - \\\n && cd openmpi-${OMPI_VERSION} \\\n && ./configure --build=\"$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)\" --prefix=/home/.openmpi --with-cuda \\\n && make all install \\\n && cd .. \\\n && rm openmpi-${OMPI_VERSION}.tar.gz \\\n && rm -rf openmpi-${OMPI_VERSION}\n\nENV PATH=\"$PATH:/home/.openmpi/bin\"\nENV LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/home/.openmpi/lib/\"\n\n# Install OpenSSH. Allow OpenSSH to talk to containers without asking for confirmation\nRUN apt-get update \\\n && apt-get install -y --no-install-recommends \\\n    openssh-client \\\n    openssh-server \\\n && mkdir -p /var/run/sshd \\\n && cat /etc/ssh/ssh_config | grep -v StrictHostKeyChecking > /etc/ssh/ssh_config.new \\\n && echo \"    StrictHostKeyChecking no\" >> /etc/ssh/ssh_config.new \\\n && mv /etc/ssh/ssh_config.new /etc/ssh/ssh_configs \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\nRUN curl -f -L -o ~/mambaforge.sh https://github.com/conda-forge/miniforge/releases/download/${MAMBA_VERSION}/Mambaforge-${MAMBA_VERSION}-Linux-x86_64.sh \\\n && chmod +x ~/mambaforge.sh \\\n && ~/mambaforge.sh -b -p /opt/conda \\\n && rm ~/mambaforge.sh \\\n && /opt/conda/bin/conda install -c conda-forge \\\n    python=$PYTHON_VERSION \\\n    cython \\\n    mkl \\\n    mkl-include \\\n    parso \\\n    scipy \\\n    typing \\\n    h5py \\\n    requests \\\n    libgcc \\\n    # Below 2 are included in miniconda base, but not mamba so need to install\n    conda-content-trust \\\n    charset-normalizer \\\n && /opt/conda/bin/conda install -c pytorch magma-cuda115=2.6.1 \\\n# Upstream conda looks to have moved to 4.13 which is incompatible with mamba 0.22.1 and will fail the conda-forge installs.\n# having \"conda update conda\" before the \"conda -c conda-forge\" commands will automatically update conda to 4.13.\n# Moving conda update conda\" after the \"conda -c conda-forge\" commands keep conda at 4.12 but will update other packages using\n# the current conda 4.12\n && /opt/conda/bin/conda update -y conda \\\n   && /opt/conda/bin/conda clean -ya\n\n# Conda installs links for libtinfo.so.6 and libtinfo.so.6.2 both\n# Which causes \"/opt/conda/lib/libtinfo.so.6: no version information available\" warning\n# Removing link for libtinfo.so.6. This change is needed only for ubuntu 20.04-conda, and can be reverted\n# once conda fixes the issue: https://github.com/conda/conda/issues/9680\nRUN rm -rf /opt/conda/lib/libtinfo.so.6\n\nRUN /opt/conda/bin/conda config --set ssl_verify False \\\n && pip install --no-cache-dir --upgrade pip --trusted-host pypi.org --trusted-host \\\n && ln -s /opt/conda/bin/pip /usr/local/bin/pip3\n\nWORKDIR /root\n\n# Install AWS-PyTorch, and other torch packages\nRUN pip install --no-cache-dir -U \\\n    \"awscli<2\" \\\n    boto3 \\\n    \"cryptography>3.2\" \\\n    enum-compat==0.0.3 \\\n    ipython==8.1.0 \\\n    numpy==1.22.2 \\\n    \"opencv-python>=4.6,<5\" \\\n    packaging \\\n    \"Pillow>=9.0.0\" \\\n    \"pyyaml>=5.4,<5.5\" \\\n && pip uninstall -y torch torchvision torchaudio torchdata \\\n && pip install --no-cache-dir -U ${PT_INFERENCE_URL} ${PT_TORCHVISION_URL} ${PT_TORCHAUDIO_URL} ${PT_TORCHDATA_URL}\n\n# TODO: revert torchserve-nightly back to torchserve once a compatible stable version is released\nRUN pip uninstall -y model-archiver multi-model-server \\\n && pip install --no-cache-dir captum \\\n && pip install --no-cache-dir torchserve==${TS_VERSION} \\\n && pip install --no-cache-dir torch-model-archiver==${TS_VERSION}\n\nWORKDIR /\n\nRUN cd tmp/ \\\n && rm -rf tmp*\n\nRUN useradd -m model-server \\\n && mkdir -p /home/model-server/tmp /opt/ml/model \\\n && chown -R model-server /home/model-server /opt/ml/model\n\nCOPY torchserve-e3-entrypoint.py /usr/local/bin/dockerd-entrypoint.py\nCOPY config.properties /home/model-server\n\nRUN chmod +x /usr/local/bin/dockerd-entrypoint.py\n\nCOPY deep_learning_container.py /usr/local/bin/deep_learning_container.py\n\nRUN chmod +x /usr/local/bin/deep_learning_container.py\n\nRUN HOME_DIR=/root \\\n && curl -f -o ${HOME_DIR}/oss_compliance.zip https://aws-dlinfra-utilities.s3.amazonaws.com/oss_compliance.zip \\\n && unzip ${HOME_DIR}/oss_compliance.zip -d ${HOME_DIR}/ \\\n && cp ${HOME_DIR}/oss_compliance/test/testOSSCompliance /usr/local/bin/testOSSCompliance \\\n && chmod +x /usr/local/bin/testOSSCompliance \\\n && chmod +x ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh \\\n && ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh ${HOME_DIR} ${PYTHON} \\\n && rm -rf ${HOME_DIR}/oss_compliance*\n\nRUN curl -f -o /license.txt https://aws-dlc-licenses.s3.amazonaws.com/pytorch-1.11/license.txt\n\nEXPOSE 8080 8081\nENTRYPOINT [\"python\", \"/usr/local/bin/dockerd-entrypoint.py\"]\nCMD [\"torchserve\", \"--start\", \"--ts-config\", \"/home/model-server/config.properties\", \"--model-store\", \"/home/model-server/\"]\n\n#################################################################\n#  ____                   __  __       _\n# / ___|  __ _  __ _  ___|  \\/  | __ _| | _____ _ __\n# \\___ \\ / _` |/ _` |/ _ \\ |\\/| |/ _` | |/ / _ \\ '__|\n#  ___) | (_| | (_| |  __/ |  | | (_| |   <  __/ |\n# |____/ \\__,_|\\__, |\\___|_|  |_|\\__,_|_|\\_\\___|_|\n#              |___/\n#  ___                              ____           _\n# |_ _|_ __ ___   __ _  __ _  ___  |  _ \\ ___  ___(_)_ __   ___\n#  | || '_ ` _ \\ / _` |/ _` |/ _ \\ | |_) / _ \\/ __| | '_ \\ / _ \\\n#  | || | | | | | (_| | (_| |  __/ |  _ <  __/ (__| | |_) |  __/\n# |___|_| |_| |_|\\__,_|\\__, |\\___| |_| \\_\\___|\\___|_| .__/ \\___|\n#                      |___/                        |_|\n#################################################################\n\nFROM e3 AS sagemaker\n\nLABEL maintainer=\"Amazon AI\"\nLABEL dlc_major_version=\"1\"\nLABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n\nARG PYTHON\n\nENV SAGEMAKER_SERVING_MODULE sagemaker_pytorch_serving_container.serving:main\n\n# Install scikit-learn and pandas\nRUN conda install -y -c conda-forge \\\n    scikit-learn \\\n    pandas\n\nRUN pip install --no-cache-dir \"sagemaker-pytorch-inference>=2\"\n\nCOPY torchserve-entrypoint.py /usr/local/bin/dockerd-entrypoint.py\n\nRUN chmod +x /usr/local/bin/dockerd-entrypoint.py\n\nRUN HOME_DIR=/root \\\n && curl -f -o ${HOME_DIR}/oss_compliance.zip https://aws-dlinfra-utilities.s3.amazonaws.com/oss_compliance.zip \\\n && unzip ${HOME_DIR}/oss_compliance.zip -d ${HOME_DIR}/ \\\n && cp ${HOME_DIR}/oss_compliance/test/testOSSCompliance /usr/local/bin/testOSSCompliance \\\n && chmod +x /usr/local/bin/testOSSCompliance \\\n && chmod +x ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh \\\n && ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh ${HOME_DIR} ${PYTHON} \\\n && rm -rf ${HOME_DIR}/oss_compliance*\n\nEXPOSE 8080 8081\nENTRYPOINT [\"python\", \"/usr/local/bin/dockerd-entrypoint.py\"]\nCMD [\"torchserve\", \"--start\", \"--ts-config\", \"/home/model-server/config.properties\", \"--model-store\", \"/home/model-server/\"]\n"
}