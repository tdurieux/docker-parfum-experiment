{
  "startTime": 1674215166622,
  "endTime": 1674215168084,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 103,
        "lineEnd": 103,
        "columnStart": 4,
        "columnEnd": 51
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 127,
        "lineEnd": 127,
        "columnStart": 4,
        "columnEnd": 53
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 147,
        "lineEnd": 147,
        "columnStart": 4,
        "columnEnd": 108
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 155,
        "lineEnd": 155,
        "columnStart": 4,
        "columnEnd": 93
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 103,
        "lineEnd": 103,
        "columnStart": 4,
        "columnEnd": 51
      }
    },
    {
      "rule": "configureShouldUseBuildFlag",
      "position": {
        "lineStart": 77,
        "lineEnd": 77,
        "columnStart": 4,
        "columnEnd": 15
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 75,
        "lineEnd": 75,
        "columnStart": 4,
        "columnEnd": 39
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM nvidia/cuda:11.2.1-base-ubuntu18.04\n\nLABEL maintainer=\"Amazon AI\"\nLABEL dlc_major_version=\"1\"\n\nARG PYTHON=python3.7\nARG PYTHON_PIP=python3-pip\nARG PIP=pip3\nARG PYTHON_VERSION=3.7.10\n\nARG TFS_SHORT_VERSION=2.5\nARG TFS_URL=https://aws-ei-tensorflow-binaries.s3-us-west-2.amazonaws.com/serving/r2.5_aws/20210517-110027/gpu/py37/tensorflow_model_server\n\nENV NCCL_VERSION=2.8.4-1+cuda11.2\nENV CUDNN_VERSION=8.1.0.77-1+cuda11.2\nENV TF_TENSORRT_VERSION=7.2.2\n\n# See http://bugs.python.org/issue19846\nENV LANG=C.UTF-8\nENV PYTHONDONTWRITEBYTECODE=1\n# Python wonâ€™t try to write .pyc or .pyo files on the import of source modules\nENV PYTHONUNBUFFERED=1\nENV MODEL_BASE_PATH=/models\n# The only required piece is the model name in order to differentiate endpoints\nENV MODEL_NAME=model\n# Fix for the interactive mode during an install in step 21\nENV DEBIAN_FRONTEND=noninteractive\n\n# allow unauthenticated and allow downgrades for special libcublas library\nRUN apt-get update \\\n # TODO: Remove systemd upgrade once it is updated in base image\n && apt-get -y upgrade --only-upgrade systemd \\\n && apt-get install -y --no-install-recommends --allow-unauthenticated --allow-downgrades\\\n    ca-certificates \\\n    cuda-command-line-tools-11-2 \\\n    cuda-nvrtc-11-2 \\\n    cuda-nvrtc-dev-11-2 \\\n    cuda-cudart-dev-11-2 \\\n    libcufft-dev-11-2 \\\n    libcurand-dev-11-2 \\\n    libcusolver-dev-11-2 \\\n    libcusparse-dev-11-2 \\\n    libbz2-dev \\\n    liblzma-dev \\\n    #cuda-cublas-dev not available with 10-1, install libcublas instead\n    libcublas-11-2 \\\n    libcublas-dev-11-2 \\\n    libcudnn8=${CUDNN_VERSION} \\\n    libcudnn8-dev=${CUDNN_VERSION} \\\n    libnccl2=${NCCL_VERSION} \\\n    libnccl-dev=${NCCL_VERSION}  \\\n    libgomp1 \\\n    libffi-dev \\\n    curl \\\n    emacs \\\n    git \\\n    wget \\\n    unzip \\\n    vim \\\n    build-essential \\\n    zlib1g-dev \\\n    openssl \\\n    libssl1.1 \\\n    libreadline-gplv2-dev \\\n    libncursesw5-dev \\\n    libssl-dev \\\n    libsqlite3-dev \\\n    tk-dev \\\n    libgdbm-dev \\\n    libc6-dev \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n\n# Install python3.7\nRUN wget https://www.python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tgz \\\n && tar -xvf Python-$PYTHON_VERSION.tgz \\\n && cd Python-$PYTHON_VERSION \\\n && ./configure --build=\"$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)\" && make && make install \\\n && rm -rf ../Python-$PYTHON_VERSION* && rm Python-$PYTHON_VERSION.tgz\n\nRUN ${PIP} --no-cache-dir install --upgrade \\\n    pip \\\n    setuptools\n\n\n# We don't install libnvinfer-dev since we don't need to build against TensorRT\n# cuda-x.x is CUDA version 10.2, 11.0, or 11.1 (for 11.2)\n# https://docs.nvidia.com/deeplearning/tensorrt/archives/tensorrt-722/install-guide/index.html\nRUN apt-get update \\\n && apt-get install -y --no-install-recommends --allow-unauthenticated  \\\n    libnvinfer7=${TF_TENSORRT_VERSION}-1+cuda11.1 \\\n    libnvinfer-plugin7=${TF_TENSORRT_VERSION}-1+cuda11.1 \\\n && rm -rf /var/lib/apt/lists/*\n\n# Some TF tools expect a \"python\" binary\nRUN ln -s $(which ${PYTHON}) /usr/local/bin/python \\\n && ln -s $(which ${PIP}) /usr/bin/pip\n\n# nginx + njs\nRUN apt-get update \\\n && apt-get -y install --no-install-recommends \\\n    curl \\\n    gnupg2 \\\n && curl -f -s https://nginx.org/keys/nginx_signing.key | apt-key add - \\\n && echo 'deb http://nginx.org/packages/ubuntu/ bionic nginx' >> /etc/apt/sources.list \\\n && apt-get update \\\n && apt-get -y install --no-install-recommends \\\n    nginx \\\n    nginx-module-njs \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n\n# cython, falcon, gunicorn, grpc\nRUN ${PIP} install -U --no-cache-dir \\\n    \"awscli<2\" \\\n    boto3 \\\n    cython==0.29.21 \\\n    falcon==2.0.0 \\\n    gunicorn==20.0.4 \\\n    gevent==21.1.1 \\\n    requests==2.25.1 \\\n    grpcio==1.34.1 \\\n    protobuf==3.14.0 \\\n# using --no-dependencies to avoid installing tensorflow binary\n && ${PIP} install --no-dependencies --no-cache-dir \\\n    tensorflow-serving-api-gpu==2.5.1\n\nRUN curl -f $TFS_URL -o /usr/bin/tensorflow_model_server \\\n && chmod 555 /usr/bin/tensorflow_model_server\n\n# Expose gRPC and REST port\nEXPOSE 8500 8501\n\n# Set where models should be stored in the container\nRUN mkdir -p ${MODEL_BASE_PATH}\n\n# Create a script that runs the model server so we can use environment variables\n# while also passing in arguments from the docker command line\nRUN echo '#!/bin/bash \\n\\n' > /usr/bin/tf_serving_entrypoint.sh \\\n && echo '/usr/bin/tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \"$@\"' >> /usr/bin/tf_serving_entrypoint.sh \\\n && chmod +x /usr/bin/tf_serving_entrypoint.sh\n\nCOPY deep_learning_container.py /usr/local/bin/deep_learning_container.py\n\nRUN chmod +x /usr/local/bin/deep_learning_container.py\n\nRUN HOME_DIR=/root \\\n && curl -f -o ${HOME_DIR}/oss_compliance.zip https://aws-dlinfra-utilities.s3.amazonaws.com/oss_compliance.zip \\\n && unzip ${HOME_DIR}/oss_compliance.zip -d ${HOME_DIR}/ \\\n && cp ${HOME_DIR}/oss_compliance/test/testOSSCompliance /usr/local/bin/testOSSCompliance \\\n && chmod +x /usr/local/bin/testOSSCompliance \\\n && chmod +x ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh \\\n && ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh ${HOME_DIR} ${PYTHON} \\\n && rm -rf ${HOME_DIR}/oss_compliance*\n\nRUN curl -f https://aws-dlc-licenses.s3.amazonaws.com/tensorflow-2.5/license.txt -o /license.txt\n\nCMD [\"/usr/bin/tf_serving_entrypoint.sh\"]\n"
}