{
  "startTime": 1674250748849,
  "endTime": 1674250749857,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 88,
        "lineEnd": 88,
        "columnStart": 4,
        "columnEnd": 132
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 95,
        "lineEnd": 95,
        "columnStart": 4,
        "columnEnd": 51
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 95,
        "lineEnd": 95,
        "columnStart": 4,
        "columnEnd": 51
      }
    },
    {
      "rule": "configureShouldUseBuildFlag",
      "position": {
        "lineStart": 70,
        "lineEnd": 70,
        "columnStart": 4,
        "columnEnd": 15
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 69,
        "lineEnd": 69,
        "columnStart": 4,
        "columnEnd": 39
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM nvidia/cuda:10.0-base-ubuntu16.04\n\nLABEL maintainer=\"Amazon AI\"\nLABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n\n# Add arguments to achieve the version, python and url\n# PYTHON=python for 2.7, PYTHON=python3 for 3.5, 3.6 is not available directly on 16.04\nARG PYTHON=python3\n#  PIP=pip for 2.7, PIP=pip3 for 3.5, 3.6 is not available directly on 16.04\nARG PIP=pip3\nARG PYTHON_VERSION=3.6.6\nARG TFS_SHORT_VERSION=1.13\n\n# See http://bugs.python.org/issue19846\nENV LANG C.UTF-8\nENV NCCL_VERSION=2.4.7-1+cuda10.0\nENV CUDNN_VERSION=7.5.1.10-1+cuda10.0\nENV TF_TENSORRT_VERSION=5.0.2\n# Python wonâ€™t try to write .pyc or .pyo files on the import of source modules\nENV PYTHONDONTWRITEBYTECODE=1\nENV PYTHONUNBUFFERED=1\nENV SAGEMAKER_TFS_VERSION=\"${TFS_SHORT_VERSION}\"\nENV PATH=\"$PATH:/sagemaker\"\nENV MODEL_BASE_PATH=/models\n# The only required piece is the model name in order to differentiate endpoints\nENV MODEL_NAME=model\n\nRUN apt-get update \\\n && apt-get install -y --no-install-recommends \\\n    ca-certificates \\\n    cuda-command-line-tools-10-0 \\\n    cuda-cublas-10-0 \\\n    cuda-cufft-10-0 \\\n    cuda-curand-10-0 \\\n    cuda-cusolver-10-0 \\\n    cuda-cusparse-10-0 \\\n    libcudnn7=${CUDNN_VERSION} \\\n    libnccl2=${NCCL_VERSION} \\\n    libgomp1 \\\n    curl \\\n    git \\\n    wget \\\n    vim \\\n    #next two lines are needed to add python-3.6 should be removed from ubuntu-16.10\n    build-essential \\\n    zlib1g-dev \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n\n# The 'apt-get install' of nvinfer-runtime-trt-repo-ubuntu1604-4.0.1-ga-cuda10.0\n# adds a new list which contains libnvinfer library, so it needs another\n# 'apt-get update' to retrieve that list before it can actually install the\n# library.\n# We don't install libnvinfer-dev since we don't need to build against TensorRT,\n# and libnvinfer4 doesn't contain libnvinfer.a static library.\nRUN apt-get update \\\n && apt-get install -y --no-install-recommends \\\n    nvinfer-runtime-trt-repo-ubuntu1604-${TF_TENSORRT_VERSION}-ga-cuda10.0 \\\n && apt-get update \\\n && apt-get install -y --no-install-recommends \\\n    libnvinfer5=${TF_TENSORRT_VERSION}-1+cuda10.0 \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/* \\\n && rm /usr/lib/x86_64-linux-gnu/libnvinfer_plugin* \\\n && rm /usr/lib/x86_64-linux-gnu/libnvcaffe_parser* \\\n && rm /usr/lib/x86_64-linux-gnu/libnvparsers* \\\n && rm -rf /var/lib/apt/lists/*\n\nRUN wget https://www.python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tgz \\\n && tar -xvf Python-$PYTHON_VERSION.tgz && cd Python-$PYTHON_VERSION \\\n && ./configure --build=\"$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)\" && make && make install \\\n && apt-get update && apt-get install -y --no-install-recommends \\\n    libreadline-gplv2-dev \\\n    libncursesw5-dev \\\n    libssl-dev \\\n    libsqlite3-dev \\\n    tk-dev libgdbm-dev \\\n    libc6-dev libbz2-dev \\\n && rm -rf /var/lib/apt/lists/* \\\n && make && make install \\\n && rm -rf ../Python-$PYTHON_VERSION* \\\n && ln -s /usr/local/bin/pip3 /usr/bin/pip && rm Python-$PYTHON_VERSION.tgz\n\nRUN ${PIP} --no-cache-dir install --upgrade pip setuptools\n\n# Some TF tools expect a \"python\" binary\nRUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n\nRUN curl -f https://s3-us-west-2.amazonaws.com/tensorflow-aws/1.13/Serving/GPU/tensorflow_model_server --output tensorflow_model_server && \\\nchmod 555 tensorflow_model_server && cp tensorflow_model_server /usr/bin/tensorflow_model_server && \\\nrm -f tensorflow_model_server\n\n# nginx + njs\nRUN apt-get update \\\n && apt-get -y install --no-install-recommends curl gnupg2 \\\n && curl -f -s https://nginx.org/keys/nginx_signing.key | apt-key add - \\\n && echo 'deb http://nginx.org/packages/ubuntu/ xenial nginx' >> /etc/apt/sources.list \\\n && apt-get update \\\n && apt-get -y install --no-install-recommends nginx nginx-module-njs \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n\n# cython, falcon, gunicorn, grpc\nRUN ${PIP} install -U --no-cache-dir \\\n    boto3 \\\n    awscli==1.16.130 \\\n    cython==0.29.10 \\\n    falcon==2.0.0 \\\n    gunicorn==19.9.0 \\\n    gevent==1.4.0 \\\n    requests==2.21.0 \\\n    grpcio==1.24.1 \\\n    protobuf==3.10.0 \\\n# using --no-dependencies to avoid installing tensorflow binary\n && ${PIP} install --no-dependencies --no-cache-dir \\\n    tensorflow-serving-api-gpu==1.13.0\n\nCOPY ./ /\n\n# Expose gRPC and REST port\nEXPOSE 8500 8501\n\n# Set where models should be stored in the container\nRUN mkdir -p ${MODEL_BASE_PATH}\n\n# Create a script that runs the model server so we can use environment variables\n# while also passing in arguments from the docker command line\nRUN echo '#!/bin/bash \\n\\n' > /usr/bin/tf_serving_entrypoint.sh \\\n && echo '/usr/bin/tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \"$@\"' >> /usr/bin/tf_serving_entrypoint.sh \\\n && chmod +x /usr/bin/tf_serving_entrypoint.sh\n\nCMD [\"/usr/bin/tf_serving_entrypoint.sh\"]\n"
}