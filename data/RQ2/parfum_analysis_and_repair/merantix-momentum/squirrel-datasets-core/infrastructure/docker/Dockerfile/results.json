{
  "startTime": 1674217057083,
  "endTime": 1674217057865,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 4,
        "columnEnd": 98
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 9,
        "lineEnd": 9,
        "columnStart": 4,
        "columnEnd": 30
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 10,
        "lineEnd": 10,
        "columnStart": 4,
        "columnEnd": 91
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 25,
        "lineEnd": 25,
        "columnStart": 4,
        "columnEnd": 50
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 3,
        "lineEnd": 3,
        "columnStart": 4,
        "columnEnd": 63
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM python:3.8.9-slim\n\nRUN apt-get update && \\\n    apt-get -y --no-install-recommends install git findutils build-essential unzip wget && \\\n    apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*\n\nADD . .\n\nRUN pip3 install --no-cache-dir keyrings.google-artifactregistry-auth==0.0.3 --index-url=https://pypi.org/simple/\nRUN pip3 install --no-cache-dir --upgrade pip && \\\n    pip3 install --no-cache-dir --require-hashes -r requirements.txt --no-deps --disable-pip-version-check && \\\n    pip3 cache purge\n\n# for testing to work, the base image has to have spark<=3.1, >=3.0\n# spark>=3.0 is required by python3.8\n# spark <=3.1 is required by pydeequ (deequ)\n\n# add java\nCOPY --from=adoptopenjdk/openjdk8 opt/java opt/java\nENV JAVA_HOME=/opt/java/openjdk\nENV PATH=$PATH:$JAVA_HOME/bin\n\n# add spark\nADD https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz .\nRUN rm -rf /opt/spark && \\\n    tar -xzf spark-3.2.0-bin-hadoop3.2.tgz -C /opt && \\\n    mv /opt/spark-3.2.0-bin-hadoop3.2/ /opt/spark && rm spark-3.2.0-bin-hadoop3.2.tgz\nENV SPARK_HOME=\"/opt/spark\"\n\n# add shaded gcs connector\nADD https://repo1.maven.org/maven2/com/google/cloud/bigdataoss/gcs-connector/hadoop3-2.2.2/gcs-connector-hadoop3-2.2.2-shaded.jar /opt/spark/jars/gcs-connector-hadoop3-latest.jar\n"
}