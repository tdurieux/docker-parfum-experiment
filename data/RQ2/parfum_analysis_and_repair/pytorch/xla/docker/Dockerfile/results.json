{
  "startTime": 1674255413027,
  "endTime": 1674255414204,
  "originalSmells": [
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 16,
        "lineEnd": 16,
        "columnStart": 4,
        "columnEnd": 54
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 16,
        "lineEnd": 16,
        "columnStart": 4,
        "columnEnd": 54
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 16,
        "lineEnd": 16,
        "columnStart": 4,
        "columnEnd": 54
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# Use nvidia/cuda:10.1-cudnn7-devel-ubuntu18.04 or later for CUDA.\n# Warning: All ARGs placed before FROM will only be scoped up unitl FROM statement.\n# https://github.com/docker/cli/blob/3c7ede6a68941f64c3a154c9a753eb7a9b1c2c3e/docs/reference/builder.md#understand-how-arg-and-from-interact\nARG base_image=\"debian:buster\"\nFROM \"${base_image}\"\n\nARG python_version=\"3.7\"\nARG release_version=\"nightly\"\nARG cuda=\"0\"\nARG cuda_compute=\"3.7,7.0,7.5,8.0\"\nARG cxx_abi=\"0\"\nARG tpuvm=\"\"\nARG bazel_jobs=\"\"\nARG git_clone=\"true\"\n\nRUN apt-get update && apt-get install --no-install-recommends -y git sudo python-pip python3-pip && rm -rf /var/lib/apt/lists/*;\nRUN git clone https://github.com/pytorch/pytorch\n\n# Disable CUDA for PyTorch\nENV USE_CUDA \"0\"\n\n# Enable CUDA for XLA\nENV XLA_CUDA \"${cuda}\"\nENV TF_CUDA_COMPUTE_CAPABILITIES \"${cuda_compute}\"\n\n# Whether to build torch and torch_xla libraries with CXX ABI\nENV _GLIBCXX_USE_CXX11_ABI \"${cxx_abi}\"\nENV CFLAGS \"${CFLAGS} -D_GLIBCXX_USE_CXX11_ABI=${cxx_abi}\"\nENV CXXFLAGS \"${CXXFLAGS} -D_GLIBCXX_USE_CXX11_ABI=${cxx_abi}\"\n\n# Whether to build for TPUVM mode\nENV TPUVM_MODE \"${tpuvm}\"\n\n# Maximum number of jobs to use for bazel build\nENV BAZEL_JOBS \"${bazel_jobs}\"\n\n# To get around issue of Cloud Build with recursive submodule update\n# clone recursively from pytorch/xla if building docker image with\n# cloud build. Otherwise, just use local.\n# https://github.com/GoogleCloudPlatform/cloud-builders/issues/435\nCOPY . /pytorch/xla\nRUN if [ \"${git_clone}\" = \"true\" ]; then github_branch=\"${release_version}\" && \\\n  if [ \"${release_version}\" = \"nightly\" ]; then github_branch=\"master\"; fi && \\\n  cd /pytorch && \\\n  rm -rf xla && \\\n  git clone -b \"${github_branch}\" --recursive https://github.com/pytorch/xla && \\\n  cd / && \\\n  git clone -b \"${github_branch}\" --recursive https://github.com/pytorch-tpu/examples tpu-examples; fi\n\nRUN cd /pytorch && bash xla/scripts/build_torch_wheels.sh ${python_version} ${release_version}\n\n# Set LD_PRELOAD to use tcmalloc if for tpuvm mode.\nENV LD_PRELOAD=${tpuvm:+\"/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\"}\n\n# Use conda environment on startup or when running scripts.\nRUN echo \"conda activate pytorch\" >> ~/.bashrc\nRUN echo \"export TF_CPP_LOG_THREAD_ID=1\" >> ~/.bashrc\nENV PATH /root/anaconda3/envs/pytorch/bin/:/root/bin:$PATH\n\n# Define entrypoint and cmd\nCOPY docker/docker-entrypoint.sh /usr/local/bin\nENTRYPOINT [\"docker-entrypoint.sh\"]\nCMD [\"bash\"]\n"
}