{
  "startTime": 1674218232402,
  "endTime": 1674218233504,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 79,
        "lineEnd": 79,
        "columnStart": 4,
        "columnEnd": 62
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 110,
        "lineEnd": 110,
        "columnStart": 4,
        "columnEnd": 117
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 119,
        "lineEnd": 119,
        "columnStart": 4,
        "columnEnd": 94
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 125,
        "lineEnd": 125,
        "columnStart": 4,
        "columnEnd": 50
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 101,
        "lineEnd": 101,
        "columnStart": 4,
        "columnEnd": 30
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 103,
        "lineEnd": 103,
        "columnStart": 4,
        "columnEnd": 21
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 104,
        "lineEnd": 104,
        "columnStart": 4,
        "columnEnd": 131
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 105,
        "lineEnd": 105,
        "columnStart": 4,
        "columnEnd": 23
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 106,
        "lineEnd": 106,
        "columnStart": 43,
        "columnEnd": 102
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 107,
        "lineEnd": 107,
        "columnStart": 4,
        "columnEnd": 28
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 108,
        "lineEnd": 108,
        "columnStart": 4,
        "columnEnd": 31
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 111,
        "lineEnd": 111,
        "columnStart": 4,
        "columnEnd": 40
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 115,
        "lineEnd": 115,
        "columnStart": 4,
        "columnEnd": 22
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 259,
        "lineEnd": 259,
        "columnStart": 4,
        "columnEnd": 66
      }
    },
    {
      "rule": "aptGetInstallUseY",
      "position": {
        "lineStart": 128,
        "lineEnd": 128,
        "columnStart": 4,
        "columnEnd": 21
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 128,
        "lineEnd": 128,
        "columnStart": 4,
        "columnEnd": 21
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 91,
        "lineEnd": 96,
        "columnStart": 4,
        "columnEnd": 18
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 128,
        "lineEnd": 128,
        "columnStart": 4,
        "columnEnd": 21
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 45,
        "lineEnd": 64,
        "columnStart": 22,
        "columnEnd": 12
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 67,
        "lineEnd": 68,
        "columnStart": 4,
        "columnEnd": 35
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 82,
        "lineEnd": 88,
        "columnStart": 22,
        "columnEnd": 22
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 91,
        "lineEnd": 96,
        "columnStart": 4,
        "columnEnd": 18
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 128,
        "lineEnd": 128,
        "columnStart": 4,
        "columnEnd": 21
      }
    }
  ],
  "repairedSmells": [
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 91,
        "lineEnd": 96,
        "columnStart": 4,
        "columnEnd": 18
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 129,
        "lineEnd": 129,
        "columnStart": 4,
        "columnEnd": 48
      }
    }
  ],
  "repairedDockerfile": "# Ubuntu 18.04 Python3 with CUDA 10 and the following:\n#  - Installs tf-nightly-gpu (this is TF 2.0)\n#  - Installs requirements.txt for tensorflow/models\n#\n# NOTE: Branched from Dockerfile_ubuntu_1804_tf_v2 with changes for\n# TFX benchmarks.\n\nFROM nvidia/cuda:10.0-base-ubuntu18.04 as base\nARG tensorflow_pip_spec=\"tf-nightly-gpu\"\nARG local_tensorflow_pip_spec=\"\"\nARG extra_pip_specs=\"\"\n\n# Specifies the default package version to use if no corresponding commit_id\n# override is specified.\n# If \"head\", uses the GitHub HEAD version.\n# If \"release\", uses the latest released version from PyPI, REGARDLESS of\n# package-compatibility requirements (e.g. even if tfx requires\n# tensorflow-model-analysis<0.22, if tensorflow-model-analysis==0.22.0 is\n# the latest released version on PyPI, we will install that).\n# Packages include: tfx, tensorflow-transform, tensorflow-model-analysis,\n# tensorflow-data-validation, tensorflow-metadata, tfx-bsl\nARG default_package_version=\"head\"\n\n# Specifies the package version to use for the corresponding packages.\n# If empty, uses the default specified by default_package_version.\n# If \"head\", uses the GitHub HEAD version.\n# If \"release\", uses the latest released version from PyPI, REGARDLESS of\n# package-compatibility requirements.\n# If \"github_commit:<commit id>\", uses the given commit ID from GitHub.\n# If \"github_tag:<tag>\" uses the given tag from GitHub.\n# If \"pypi:<version string>\", uses the given package version from PyPI.\nARG tfx_package_version=\"\"\nARG tensorflow_transform_package_version=\"\"\nARG tensorflow_model_analysis_package_version=\"\"\nARG tensorflow_data_validation_package_version=\"\"\nARG tensorflow_metadata_package_version=\"\"\nARG tfx_bsl_version=\"\"\n\n# setup.py passes the base path of local .whl file is chosen for the docker image.\n# Otherwise passes an empty existing file from the context.\nCOPY ${local_tensorflow_pip_spec} /${local_tensorflow_pip_spec}\n\n# Pick up some TF dependencies\n# cublas-dev and libcudnn7-dev only needed because of libnvinfer-dev which may not\n# really be needed.\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n        build-essential \\\n        cuda-command-line-tools-10-0 \\\n        cuda-cublas-10-0 \\\n        cuda-cublas-dev-10-0 \\\n        cuda-cufft-10-0 \\\n        cuda-curand-10-0 \\\n        cuda-cusolver-10-0 \\\n        cuda-cusparse-10-0 \\\n        libcudnn7=7.6.2.24-1+cuda10.0  \\\n        libcudnn7-dev=7.6.2.24-1+cuda10.0  \\\n        libfreetype6-dev \\\n        libhdf5-serial-dev \\\n        libzmq3-dev \\\n        libpng-dev \\\n        pkg-config \\\n        software-properties-common \\\n        unzip \\\n        lsb-core \\\n        curl && rm -rf /var/lib/apt/lists/*;\n\nRUN apt-get update && \\\n    apt-get install -y --no-install-recommends libnvinfer5=5.1.5-1+cuda10.0 \\\n    libnvinfer-dev=5.1.5-1+cuda10.0 \\\n    && apt-get clean && rm -rf /var/lib/apt/lists/*;\n\n# For CUDA profiling, TensorFlow requires CUPTI.\nENV LD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\n\n# See http://bugs.python.org/issue19846\nENV LANG C.UTF-8\n\n# Add google-cloud-sdk to the source list\nRUN echo \"deb http://packages.cloud.google.com/apt cloud-sdk-$(lsb_release -c -s) main\" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\nRUN curl -f https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n\n# Install extras needed by most models\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n      git \\\n      ca-certificates \\\n      wget \\\n      htop \\\n      zip \\\n      google-cloud-sdk && rm -rf /var/lib/apt/lists/*;\n\n# Install / update Python and Python3\nRUN apt-get install -y --no-install-recommends \\\n      python3 \\\n      python3-dev \\\n      python3-pip \\\n      python3-setuptools \\\n      python3-venv && rm -rf /var/lib/apt/lists/*;\n\n\n# Upgrade pip, need to use pip3 and then pip after this or an error\n# is thrown for no main found.\nRUN pip3 install --no-cache-dir --upgrade pip\n# setuptools upgraded to fix install requirements from model garden.\nRUN pip install --no-cache-dir wheel\nRUN pip install --no-cache-dir --upgrade setuptools google-api-python-client pyyaml google-cloud google-cloud-bigquery google-cloud-datastore mock\nRUN pip install --no-cache-dir absl-py\nRUN if [ ! -z \"${extra_pip_specs}\" ]; then \\\n pip install --no-cache-dir --upgrade --force-reinstall ${extra_pip_specs}; fi\nRUN pip install --no-cache-dir tfds-nightly\nRUN pip install --no-cache-dir -U scikit-learn\n\nRUN curl -f https://raw.githubusercontent.com/tensorflow/models/master/official/requirements.txt > /tmp/requirements.txt\nRUN pip install --no-cache-dir -r /tmp/requirements.txt\n\n# Install yolk3k, for getting package versions from PyPI (so we can pull\n# TFX from GitHub even when we need to install from the released version)\nRUN pip install --no-cache-dir yolk3k\n\n# Install protoc\nRUN PROTOC_ZIP=protoc-3.7.1-linux-x86_64.zip; \\\n    curl -f -OL https://github.com/protocolbuffers/protobuf/releases/download/v3.7.1/$PROTOC_ZIP; \\\n    unzip -o $PROTOC_ZIP -d /usr/local bin/protoc; \\\n    unzip -o $PROTOC_ZIP -d /usr/local 'include/*'; \\\n    rm -f $PROTOC_ZIP;\n\n# Install Bazel\nRUN curl -f https://bazel.build/bazel-release.pub.gpg | apt-key add -\nRUN echo \"deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\" | tee /etc/apt/sources.list.d/bazel.list\nRUN apt update\nRUN apt install -y --no-install-recommends bazel && rm -rf /var/lib/apt/lists/*;\n# Create symlink to \"python3\" binary under the name \"python\" so Bazel doesn't complain about \"python\" not being found\nRUN ln -s $(which python3) /usr/bin/python\n\nSHELL [\"/bin/bash\", \"-c\"]\nRUN \\\n  function install_package { \\\n    # e.g. \"head\" or \"release\" \\\n    default_version=\"$1\"; \\\n    # e.g \"tensorflow-model-analysis\" \\\n    package_name=\"$2\"; \\\n    # e.g \"model-analysis\" \\\n    package_repo_name=\"$3\"; \\\n    # How this package should be installed if pulled from GitHub. \\\n    # \"none\" for no extra installation steps required \\\n    # \"bdist_wheel\" for python setup.py bdist_wheel \\\n    package_install_type=$4; \\\n    # e.g. \"head\" or \"release\" or \"pypi:0.21.4\" or \"github:[commit hash]\" \\\n    package_version=\"$5\"; \\\n    \\\n    # e.g. \"tensorflow_model_analysis\" \\\n    package_name_underscores=${package_name//-/_}; \\\n    if [ \"$package_version\" == \"\" ]; then \\\n      package_version=\"$default_version\"; \\\n    fi; \\\n    \\\n    commit_id=\"\"; \\\n    pypi_version=\"\"; \\\n    if [ \"$package_version\" == \"head\" ]; then \\\n      commit_id=$(git ls-remote https://github.com/tensorflow/${package_repo_name} refs/heads/master | cut -f1); \\\n      echo ${package_name}: latest commit from GitHub: ${commit_id}; \\\n    elif [ \"$package_version\" == \"release\" ]; then \\\n      pypi_version=$(yolk -V $package_name | head -n 1 | cut -d' ' -f 2-); \\\n      echo ${package_name}: latest version from PyPI: ${pypi_version}; \\\n    elif [ \"${package_version:0:5}\" == \"pypi:\" ]; then \\\n      pypi_version=\"${package_version:5}\"; \\\n      echo ${package_name}: using specified PyPI version: ${pypi_version}; \\\n    elif [ \"${package_version:0:7}\" == \"github:\" ]; then \\\n      commit_id=\"${package_version:7}\"; \\\n      echo ${package_name}: using specified GitHub commit: ${commit_id}; \\\n    else \\\n      echo Unknown package version for ${package_name}: ${package_version}; \\\n      exit 1; \\\n    fi; \\\n    \\\n    if [ \"$commit_id\" != \"\" ]; then \\\n      if [ \"$package_install_type\" == \"none\" ]; then \\\n        # Package doesn't need extra installation steps - install directly from GitHub. \\\n        pip install -e git+https://github.com/tensorflow/${package_repo_name}.git@${commit_id}#egg=${package_name_underscores}; \\\n        install_commands+=(\"pip install --force --no-deps -e git+https://github.com/tensorflow/${package_repo_name}.git@${commit_id}#egg=${package_name_underscores}\"); \\\n        echo Installed ${package_name} from GitHub commit ${commit_id}; \\\n      elif [ \"$package_install_type\" == \"bdist_wheel\" ]; then \\\n        # Package needs extra installation steps. Clone from GitHub, then build and install. \\\n        git clone https://github.com/tensorflow/${package_repo_name}.git; \\\n        pushd ${package_repo_name}; \\\n        git checkout ${commit_id}; \\\n        if [ \"$package_name\" == \"tfx\" ]; then \\\n          echo Building TFX pip package from source; \\\n          sed -i 's@packages=packages,@packages=packages, package_data={package_name: [\"benchmarks/datasets/chicago_taxi/data/taxi_1M.tfrecords.gz\"]},@' setup.py; \\\n          package_build/initialize.sh; \\\n          python package_build/ml-pipelines-sdk/setup.py bdist_wheel; \\\n          python package_build/tfx/setup.py bdist_wheel; \\\n        else \\\n          echo Using python setup.py bdist_wheel to build package; \\\n          python setup.py bdist_wheel; \\\n        fi; \\\n        pip install dist/*.whl; \\\n        install_commands+=(\"pip install --force --no-deps ${PWD}/dist/*.whl\"); \\\n        popd; \\\n        echo Built and installed ${package_name} from GitHub commit ${commit_id}; \\\t\n      fi; \\\n      # Write GIT_COMMIT_ID attribute to the installed package. \\\n      package_path=$(python3 -c \"import ${package_name_underscores}; print(list(${package_name_underscores}.__path__)[0])\"); \\\n      echo \"GIT_COMMIT_ID='${commit_id}'\" >> ${package_path}/__init__.py; \\\n      install_commands+=(\"echo \\\"GIT_COMMIT_ID='${commit_id}'\\\" >> ${package_path}/__init__.py;\"); \\\n    elif [ \"$pypi_version\" != \"\" ]; then \\\n      if [ \"$package_name\" == \"tfx\" ]; then \\\n        # Special handling for TFX - we want to install from GitHub, and get \\\n        # the data files as well (they are not included in the pip package). \\\n        # Install from the corresponding tag in GitHub. \\\n        echo Special handling for tfx: will install tfx from GitHub tag for version ${pypi_version}; \\\n        git clone --depth 1 --branch v${pypi_version} https://github.com/tensorflow/tfx.git; \\\n        pushd tfx; \\\n        echo Building TFX pip package from source; \\\n        sed -i 's@packages=packages,@packages=packages, package_data={package_name: [\"benchmarks/datasets/chicago_taxi/data/taxi_1M.tfrecords.gz\"]},@' setup.py; \\\n        package_build/initialize.sh; \\\n        python package_build/ml-pipelines-sdk/setup.py bdist_wheel; \\\n        python package_build/tfx/setup.py bdist_wheel; \\\n        pip install dist/*.whl; \\\n        install_commands+=(\"pip install --force --no-deps ${PWD}/dist/*.whl\"); \\\n        popd; \\\n        echo Installed tfx from GitHub tag for version ${pypi_version}; \\\n      else \\\n        pip install ${package_name}==${pypi_version}; \\\n        install_commands+=(\"pip install --force --no-deps ${package_name}==${pypi_version}\"); \\\n        echo Installed ${package_name} from PyPI version ${pypi_version}; \\\n      fi; \\\n    else \\\n      echo Neither commit_id nor pypi_version was set for ${package_name}; \\\n      exit 1; \\\n    fi; \\\n  }; \\\n  \\\n  # Array of commands to run post-installation. This is for forcing \\\n  # installation of packages without regard to the requirements of other \\\n  # packages. \\\n  # The first round of installations installs the packages and their \\\n  # requirements. This may result in some packages being re-installed at \\\n  # versions other than the requested versions due to requirements from \\\n  # other packages. \\\n  # The second round of installations via install_commands \\\n  # forces installations of the packages at the desired versions, ignoring \\\n  # any dependencies of these packages or other packages. Note that if there \\\n  # are incompatible package dependencies (e.g. tfx depends on \\\n  # apache-beam==2.21 and tensorflow-transform depends on apache-beam==2.22 \\\n  # then either could be installed depending on the installation order). \\\n  install_commands=(); \\\n  install_package \"${default_package_version}\" \"tfx\" \"tfx\" \"bdist_wheel\" \"${tfx_package_version}\"; \\\n  install_package \"${default_package_version}\" \"tensorflow-transform\" \"transform\" \"none\" \"${tensorflow_transform_package_version}\"; \\\n  install_package \"${default_package_version}\" \"tensorflow-model-analysis\" \"model-analysis\" \"none\" \"${tensorflow_model_analysis_package_version}\"; \\\n  install_package \"${default_package_version}\" \"tensorflow-data-validation\" \"data-validation\" \"bdist_wheel\" \"${tensorflow_data_validation_package_version}\"; \\\n  install_package \"${default_package_version}\" \"tensorflow-metadata\" \"metadata\" \"bdist_wheel\" \"${tensorflow_metadata_package_version}\"; \\\n  install_package \"${default_package_version}\" \"tfx-bsl\" \"tfx-bsl\" \"bdist_wheel\" \"${tfx_bsl_package_version}\"; \\\n  for cmd in \"${install_commands[@]}\"; do \\\n    echo Running \"${cmd}\"; \\\n    eval $cmd; \\\n  done;\n\n# Uninstall the TensorFlow version that TFX / the TFX components installed, and\n# force install the version requested.\nRUN pip uninstall -y tensorflow\nRUN pip install --no-cache-dir --upgrade --force-reinstall ${tensorflow_pip_spec}\n\nRUN pip freeze\n"
}