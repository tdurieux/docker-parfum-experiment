{
  "startTime": 1674255871829,
  "endTime": 1674255872732,
  "originalSmells": [
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 22,
        "columnEnd": 83
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 22,
        "columnEnd": 83
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM ubuntu:14.04\n\nMAINTAINER thushear <lucas421634258@gmail.com>\n\nRUN echo \"deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse\" > /etc/apt/sources.list\nRUN echo \"deb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse\" >> /etc/apt/sources.list\nRUN echo \"deb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse\" >> /etc/apt/sources.list\nRUN echo \"deb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse\" >> /etc/apt/sources.list\nRUN echo \"deb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse\" >> /etc/apt/sources.list\n\nWORKDIR /root\n\n# install openssh-server, openjdk and wget\nRUN apt-get update && apt-get install --no-install-recommends -y openssh-server openjdk-7-jdk wget vim zip && rm -rf /var/lib/apt/lists/*;\n# install hadoop 2.7.2\nCOPY   hadoop-2.5.0-cdh5.3.6.tar.gz  /tmp/\nRUN   tar -xzvf /tmp/hadoop-2.5.0-cdh5.3.6.tar.gz -C /tmp/  && \\\n      rm  -rf /tmp/hadoop-2.5.0-cdh5.3.6/share/doc     && \\\n      mv /tmp/hadoop-2.5.0-cdh5.3.6 /usr/local/hadoop && \\\n      rm /tmp/hadoop-2.5.0-cdh5.3.6.tar.gz\n\n\n\n\nCOPY   hive-0.13.1-cdh5.3.6.tar.gz  /tmp/\nRUN   tar -xzvf /tmp/hive-0.13.1-cdh5.3.6.tar.gz -C /tmp/  && \\\n      mv /tmp/hive-0.13.1-cdh5.3.6 /usr/local/hive && \\\n      rm /tmp/hive-0.13.1-cdh5.3.6.tar.gz\n\nCOPY   mysql-connector-java-5.1.27-bin.jar  /tmp/\nRUN  mv /tmp/mysql-connector-java-5.1.27-bin.jar /usr/local/hive/lib\n\nCOPY   oozie-4.0.0-cdh5.3.6.tar.gz  /tmp/\nRUN   tar -xzvf /tmp/oozie-4.0.0-cdh5.3.6.tar.gz -C /tmp/  && \\\n      mv /tmp/oozie-4.0.0-cdh5.3.6 /usr/local/oozie-4.0.0-cdh5.3.6 && \\\n      rm /tmp/oozie-4.0.0-cdh5.3.6.tar.gz\nCOPY   ext-2.2.zip  /tmp/\n\nCOPY   spark-1.3.0-bin-2.5.0-cdh5.3.6.tgz  /tmp/\nRUN   tar -xzvf /tmp/spark-1.3.0-bin-2.5.0-cdh5.3.6.tgz -C /tmp/  && \\\n      mv /tmp/spark-1.3.0-bin-2.5.0-cdh5.3.6 /usr/local/spark-1.3.0-bin-2.5.0-cdh5.3.6 && \\\n      rm /tmp/spark-1.3.0-bin-2.5.0-cdh5.3.6.tgz\n\n\n\n\n#RUN wget https://github.com/kiwenlau/compile-hadoop/releases/download/2.7.2/hadoop-2.7.2.tar.gz && \\\n#    tar -xzvf hadoop-2.7.2.tar.gz && \\\n#    mv hadoop-2.7.2 /usr/local/hadoop && \\\n#    rm hadoop-2.7.2.tar.gz\n\n\n\n# ssh without key\nRUN ssh-keygen -t rsa -f ~/.ssh/id_rsa -P '' && \\\n    cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\n\n\nRUN mkdir -p ~/hdfs/namenode && \\\n    mkdir -p ~/hdfs/datanode && \\\n    mkdir $HADOOP_HOME/logs\n\nCOPY config/* /tmp/\nCOPY standalone/* /tmp/\nENV HADOOP_HOME /usr/local/hadoop\nENV PATH /usr/local/hadoop/bin:/usr/local/hadoop/sbin:$PATH\nRUN mv /tmp/ssh_config ~/.ssh/config && \\\n    mv /tmp/slaves $HADOOP_HOME/etc/hadoop/slaves && \\\n    mv /tmp/hadoop-env.sh /usr/local/hadoop/etc/hadoop/hadoop-env.sh && \\\n    mv /tmp/yarn-env.sh /usr/local/hadoop/etc/hadoop/yarn-env.sh && \\\n    mv /tmp/mapred-env.sh /usr/local/hadoop/etc/hadoop/mapred-env.sh && \\\n    mv /tmp/hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml && \\\n    mv /tmp/core-site.xml $HADOOP_HOME/etc/hadoop/core-site.xml && \\\n    mv /tmp/mapred-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml && \\\n    mv /tmp/yarn-site.xml $HADOOP_HOME/etc/hadoop/yarn-site.xml && \\\n    mv /tmp/start-hadoop.sh ~/start-hadoop.sh && \\\n    mv /tmp/run-wordcount.sh ~/run-wordcount.sh && \\\n    mv /tmp/slaves /usr/local/spark-1.3.0-bin-2.5.0-cdh5.3.6/conf/slaves && \\\n    mv /tmp/spark-env.sh /usr/local/spark-1.3.0-bin-2.5.0-cdh5.3.6/conf/spark-env.sh && \\\n    mv /tmp/spark-defaults.conf /usr/local/spark-1.3.0-bin-2.5.0-cdh5.3.6/conf/spark-defaults.conf\nCOPY conf/* /tmp/\nRUN mv /tmp/hive-env.sh /usr/local/hive/conf/hive-env.sh && \\\n    mv /tmp/hive-site.xml /usr/local/hive/conf/hive-site.xml && \\\n    mv /tmp/hive-log4j.properties /usr/local/hive/conf/hive-log4j.properties\n\n\nRUN chmod +x ~/start-hadoop.sh && \\\n    chmod +x ~/run-wordcount.sh && \\\n    chmod +x $HADOOP_HOME/sbin/start-dfs.sh && \\\n    chmod +x $HADOOP_HOME/sbin/start-yarn.sh && \\\n    chmod +x $HADOOP_HOME/sbin/mr-jobhistory-daemon.sh  && \\\n    chmod +x /usr/local/hive/bin/hive\n\n\n# set environment variable\n\nENV JAVA_HOME /usr/lib/jvm/java-7-openjdk-amd64\nENV PATH  /usr/lib/jvm/java-7-openjdk-amd64/bin:$PATH\nRUN echo $JAVA_HOME\nRUN echo $HADOOP_HOME\nRUN echo $PATH\n# format namenode\n#RUN /usr/local/hadoop/bin/hdfs namenode -format\nRUN mkdir /var/run/sshd\nRUN echo 'root:root' |chpasswd\nRUN sed -ri 's/^PermitRootLogin\\s+.*/PermitRootLogin yes/' /etc/ssh/sshd_config\nRUN sed -ri 's/UsePAM yes/#UsePAM yes/g' /etc/ssh/sshd_config\nEXPOSE 22\nCMD    [\"/usr/sbin/sshd\", \"-D\"]\n#CMD [ \"sh\", \"-c\", \"service ssh start; bash\"]\n\n"
}