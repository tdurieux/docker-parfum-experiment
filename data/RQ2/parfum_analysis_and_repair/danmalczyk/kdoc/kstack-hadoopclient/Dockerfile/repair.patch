diff --git a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/danmalczyk/kdoc/kstack-hadoopclient/Dockerfile b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/danmalczyk/kdoc/kstack-hadoopclient/Dockerfile/repaired.Dockerfile
index 0f61636..f2196b4 100644
--- a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/danmalczyk/kdoc/kstack-hadoopclient/Dockerfile
+++ b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/danmalczyk/kdoc/kstack-hadoopclient/Dockerfile/repaired.Dockerfile
@@ -9,7 +9,7 @@ MAINTAINER Daniel Malczyk <dmalczyk@gmail.com>
 #install hadoop, spark and Hive clients
 #------------
 #Hadoop client config
-RUN curl -s http://www.eu.apache.org/dist/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz | tar -xz -C /usr/local/
+RUN curl -f -s https://www.eu.apache.org/dist/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz | tar -xz -C /usr/local/
 
 #alternative to the command above
 #COPY hadoopclient/hadoop-2.7.1.tar.gz .
@@ -33,10 +33,10 @@ COPY conf/hdfs-site.xml $HADOOP_PREFIX/etc/hadoop/hdfs-site.xml
 
 #Install spark to /usr/local/spark
 #support for Hadoop 2.6.0
-RUN curl -s http://d3kbcqa49mib13.cloudfront.net/spark-1.6.1-bin-hadoop2.6.tgz | tar -xz -C /usr/local/
+RUN curl -f -s https://d3kbcqa49mib13.cloudfront.net/spark-1.6.1-bin-hadoop2.6.tgz | tar -xz -C /usr/local/
 
 #alternative to the command above
-#COPY hadoopclient/spark-1.6.1-bin-hadoop2.6.tgz . 
+#COPY hadoopclient/spark-1.6.1-bin-hadoop2.6.tgz .
 #RUN tar -xz -C /usr/local/ -f ./spark-1.6.1-bin-hadoop2.6.tgz
 
 RUN cd /usr/local && ln -s spark-1.6.1-bin-hadoop2.6 spark
@@ -45,7 +45,7 @@ ENV SPARK_HOME /usr/local/spark
 ENV PATH $SPARK_HOME/bin:$PATH
 
 # Install hive
-RUN curl -s http://apache.mirrors.spacedump.net/hive/hive-2.1.1/apache-hive-2.1.1-bin.tar.gz | tar -xz -C /usr/local/
+RUN curl -f -s https://apache.mirrors.spacedump.net/hive/hive-2.1.1/apache-hive-2.1.1-bin.tar.gz | tar -xz -C /usr/local/
 
 #alternative to the command above
 #COPY hadoopclient/apache-hive-2.1.1-bin.tar.gz .
@@ -72,8 +72,8 @@ RUN cp $HADOOP_PREFIX/etc/hadoop/core-site.xml $SPARK_HOME/conf
 RUN echo spark.yarn.jar hdfs://hadoopservice/spark/spark-assembly-1.6.0-hadoop2.6.0.jar > $SPARK_HOME/conf/spark-defaults.conf
 
 # Download mysql jdbc driver and prepare hive metastore.
-RUN curl -s -o $HIVE_HOME/lib/mysql-connector-java-5.1.41.jar http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.41/mysql-connector-java-5.1.41.jar
-RUN curl -s -o $HIVE_HOME/lib/mariadb-java-client-1.5.7.jar https://downloads.mariadb.com/Connectors/java/connector-java-1.5.7/mariadb-java-client-1.5.7.jar
+RUN curl -f -s -o $HIVE_HOME/lib/mysql-connector-java-5.1.41.jar https://central.maven.org/maven2/mysql/mysql-connector-java/5.1.41/mysql-connector-java-5.1.41.jar
+RUN curl -f -s -o $HIVE_HOME/lib/mariadb-java-client-1.5.7.jar https://downloads.mariadb.com/Connectors/java/connector-java-1.5.7/mariadb-java-client-1.5.7.jar
 # Make mysql driver available to kylo-spark-shell
 RUN cp $HIVE_HOME/lib/mysql-connector-java-5.1.41.jar $SPARK_HOME/lib
 RUN cp $HIVE_HOME/lib/mariadb-java-client-1.5.7.jar  $SPARK_HOME/lib