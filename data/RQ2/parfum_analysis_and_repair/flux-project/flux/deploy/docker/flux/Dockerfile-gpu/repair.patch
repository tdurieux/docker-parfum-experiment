diff --git a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/flux-project/flux/deploy/docker/flux/Dockerfile-gpu b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/flux-project/flux/deploy/docker/flux/Dockerfile-gpu/repaired.Dockerfile
index 5af505a..909f26d 100644
--- a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/flux-project/flux/deploy/docker/flux/Dockerfile-gpu
+++ b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/flux-project/flux/deploy/docker/flux/Dockerfile-gpu/repaired.Dockerfile
@@ -1,4 +1,4 @@
-FROM fluxproject/ros_base_gpu 
+FROM fluxproject/ros_base_gpu
 
 RUN apt-get update && apt-get install -y --no-install-recommends \
     locales bzip2 tree unzip xz-utils curl wget iproute2 sudo \
@@ -12,8 +12,8 @@ RUN apt-get update && apt-get install -y --no-install-recommends \
 RUN mkdir -p /etc/jupyterhub
 COPY jupyterhub_config.py /etc/jupyterhub/
 
-# Introduce flux user 
-RUN npm install -g configurable-http-proxy
+# Introduce flux user
+RUN npm install -g configurable-http-proxy && npm cache clean --force;
 RUN useradd -u 11111 -m -s /bin/bash flux
 RUN usermod -aG sudo flux
 RUN bash -c " echo flux:flux | chpasswd "
@@ -56,12 +56,12 @@ RUN bash -c "curl -s https://api.github.com/repos/valtech/ros_hadoop/releases/la
 RUN bash -c "if [ ! -f /opt/ros_hadoop/master/dist/hadoop-3.0.0.tar.gz ] ; then wget --no-check-certificate -O /opt/ros_hadoop/master/dist/hadoop-3.1.1.tar.gz -q https://www.eu.apache.org/dist/hadoop/common/hadoop-3.1.1/hadoop-3.1.1.tar.gz ; fi"
 RUN tar -xzf /opt/ros_hadoop/latest.tgz -C /opt/ros_hadoop/latest --strip-components=1 && rm /opt/ros_hadoop/latest.tgz
 RUN tar -xzf /opt/ros_hadoop/master/dist/hadoop-3.1.1.tar.gz -C /opt/apache && rm /opt/ros_hadoop/master/dist/hadoop-3.1.1.tar.gz
-RUN ln -s /opt/apache/hadoop-3.1.1 /opt/apache/hadoop 
+RUN ln -s /opt/apache/hadoop-3.1.1 /opt/apache/hadoop
 RUN bash -c "if [ ! -f /opt/ros_hadoop/latest/lib/rosbaginputformat.jar ] ; then ln -s /opt/ros_hadoop/master/lib/rosbaginputformat.jar /opt/ros_hadoop/latest/lib/rosbaginputformat.jar ; fi"
 
 ## for spark example tests
 RUN bash -c "if [ ! -f /opt/ros_spark/dist/spark-2.3.1-bin-hadoop2.7.tgz ] ; then wget --quiet -O /opt/ros_spark/dist/spark-2.3.1-bin-hadoop2.7.tgz http://apache.lauf-forum.at/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz ; fi"
-RUN tar -xzf /opt/ros_spark/dist/spark-2.3.1-bin-hadoop2.7.tgz -C /opt/apache && rm /opt/ros_spark/dist/spark-2.3.1-bin-hadoop2.7.tgz 
+RUN tar -xzf /opt/ros_spark/dist/spark-2.3.1-bin-hadoop2.7.tgz -C /opt/apache && rm /opt/ros_spark/dist/spark-2.3.1-bin-hadoop2.7.tgz
 
 RUN printf "<configuration>\n\n<property>\n<name>fs.defaultFS</name>\n<value>hdfs://localhost:9000</value>\n</property>\n</configuration>" > /opt/apache/hadoop/etc/hadoop/core-site.xml && \
     printf "<configuration>\n<property>\n<name>dfs.replication</name>\n<value>1</value>\n</property>\n</configuration>" > /opt/apache/hadoop/etc/hadoop/hdfs-site.xml && \
@@ -88,7 +88,7 @@ RUN bash -c "/start_hadoop.sh" && \
 RUN \
   mkdir -p /ope/ros_hadoop/latest/doc && \
   chmod -R 777 /opt/ros_hadoop
-  
+
 WORKDIR /opt/ros_hadoop/latest/doc/
 ENTRYPOINT ["/ros_hadoop.sh"]