{
  "startTime": 1674248809670,
  "endTime": 1674248810485,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 15,
        "lineEnd": 15,
        "columnStart": 4,
        "columnEnd": 113
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM ubuntu:18.04\n\nSHELL [\"/bin/bash\", \"-o\", \"pipefail\", \"-c\"]\n\nRUN apt-get update && apt-get install -y --no-install-recommends gosu sudo \\\n    build-essential wget ca-certificates libnss-wrapper openjdk-8-jdk \\\n    libgl-dev libosmesa6-dev libglu1-mesa-dev  && \\\n    wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh && \\\n    /bin/bash ~/miniconda.sh -b -p /opt/conda && \\\n    rm ~/miniconda.sh && \\\n    ln -s /opt/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh && \\\n    apt-get remove --purge -y && \\\n    rm -rf /var/lib/apt/lists/*\n\nRUN mkdir -p /opt/spark && \\\n    wget -qO- \"https://mirror.bit.edu.cn/apache/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop2.7.tgz\" | tar --strip-components=1 -xz -C /opt/spark && \\\n    chown -R root:root /opt/spark\n\nRUN . /opt/conda/etc/profile.d/conda.sh && \\\n    conda create -n arctern python=3.7 && \\\n    conda clean --all -y && \\\n    echo \". /opt/conda/etc/profile.d/conda.sh\" >> ~/.bashrc && \\\n    echo \"conda activate arctern\" >> ~/.bashrc\n"
}