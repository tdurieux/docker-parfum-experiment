diff --git a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/ucb-bar/onnxruntime-riscv/dockerfiles/Dockerfile.training b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/ucb-bar/onnxruntime-riscv/dockerfiles/Dockerfile.training/repaired.Dockerfile
index 6444b18..cf21111 100644
--- a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/ucb-bar/onnxruntime-riscv/dockerfiles/Dockerfile.training
+++ b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/ucb-bar/onnxruntime-riscv/dockerfiles/Dockerfile.training/repaired.Dockerfile
@@ -20,13 +20,13 @@ FROM nvidia/cuda:10.2-cudnn8-devel-ubuntu18.04 as builder
 WORKDIR /stage
 
 # install curl, git, ssh (required by MPI when running ORT tests)
-RUN apt-get -y update &&\
+RUN apt-get -y update && \
     apt-get -y --no-install-recommends install \
         curl \
         git \
         language-pack-en \
         openssh-client \
-        unattended-upgrades
+        unattended-upgrades && rm -rf /var/lib/apt/lists/*;
 
 # update existing packages to minimize security vulnerabilities
 RUN unattended-upgrade
@@ -48,12 +48,12 @@ ARG ONNX_VERSION
 RUN conda install -y \
         setuptools \
         cmake \
-        numpy=${NUMPY_VERSION} &&\
-    pip install \
+        numpy=${NUMPY_VERSION} && \
+    pip install --no-cache-dir \
         onnx=="${ONNX_VERSION}"
 
 # install cerberus for the new pytorch front-end
-RUN pip install cerberus
+RUN pip install --no-cache-dir cerberus
 
 # build ucx suite
 # note: openmpi will not select ucx without multithreading enabled
@@ -64,14 +64,14 @@ RUN apt-get -y update && apt-get -y --no-install-recommends install \
         libibverbs-dev \
         libnuma-dev &&\
     cd /stage && curl -fSsL ${UCX_URL} | tar xzf - &&\
-    cd ${UCX_TARNAME} &&\
-    ./configure \
+    cd ${UCX_TARNAME} && \
+    ./configure --build="$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)" \
 	--prefix=/opt/ucx \
         --with-cuda=/usr/local/cuda \
         --with-verbs=/usr/lib/x86_64-linux-gnu \
-        --enable-mt &&\
-    make -j"$(nproc)" &&\
-    make install
+        --enable-mt && \
+    make -j"$(nproc)" && \
+    make install && rm -rf /var/lib/apt/lists/*;
 
 # build openmpi (use --prefix /opt/openmpi-xxx to move to runtime image)
 # note: require --enable-orterun-prefix-by-default for Azure machine learning compute
@@ -82,26 +82,26 @@ ARG OPENMPI_TARNAME=openmpi-${OPENMPI_VERSION}
 ARG OPENMPI_URL=https://download.open-mpi.org/release/open-mpi/v%OMPI_BASE%/${OPENMPI_TARNAME}.tar.gz
 RUN export OMPI_BASE=${OPENMPI_VERSION%.*} &&\
     cd /stage && curl -fSsL `echo ${OPENMPI_URL} | sed s/%OMPI_BASE%/$OMPI_BASE/` | tar xzf - &&\
-    cd ${OPENMPI_TARNAME} &&\
-    ./configure \
+    cd ${OPENMPI_TARNAME} && \
+    ./configure --build="$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)" \
         --prefix=${OPENMPI_PATH} \
         --with-ucx=/opt/ucx \
         --without-verbs \
         --with-cuda=/usr/local/cuda \
         --enable-mpirun-prefix-by-default \
         --enable-orterun-prefix-by-default \
-        --enable-mca-no-build=btl-uct &&\
-    make -j"$(nproc)" install &&\
+        --enable-mca-no-build=btl-uct && \
+    make -j"$(nproc)" install && \
     ldconfig
 ENV PATH=${OPENMPI_PATH}/bin:$PATH
 ENV LD_LIBRARY_PATH=${OPENMPI_PATH}/lib:$LD_LIBRARY_PATH
 
 # install mpi4py (be sure to link existing /opt/openmpi-xxx)
-RUN CC=mpicc MPICC=mpicc pip install mpi4py --no-binary mpi4py
+RUN CC=mpicc MPICC=mpicc pip --no-cache-dir install mpi4py --no-binary mpi4py
 
 # install pytorch
 ARG PYTORCH_VERSION
-RUN pip install torch==${PYTORCH_VERSION}
+RUN pip install --no-cache-dir torch==${PYTORCH_VERSION}
 
 # in case you need to build pytorch:
 # note: if you want specific branch or to link system cuda libraries or MPI
@@ -147,11 +147,11 @@ RUN cd /stage && git clone https://github.com/microsoft/onnxruntime.git &&\
         --build_dir build \
         --build \
         --build_wheel \
-        --skip_tests &&\
-    pip install build/${BUILD_CONFIG}/dist/*.whl
+        --skip_tests && \
+    pip install --no-cache-dir build/${BUILD_CONFIG}/dist/*.whl
 
 # Install AzureML support and commonly used packages.
-RUN pip install azureml-defaults sentencepiece==0.1.92 transformers==2.11.0 msgpack==1.0.0 tensorboardX==1.8 tensorboard==2.3.0
+RUN pip install --no-cache-dir azureml-defaults sentencepiece==0.1.92 transformers==2.11.0 msgpack==1.0.0 tensorboardX==1.8 tensorboard==2.3.0
 
 # switch to cuda runtime environment
 # note: launch with --gpus all or nvidia-docker
@@ -179,8 +179,8 @@ RUN apt-get -y update && apt-get -y --no-install-recommends install \
         openssh-server \
         openssh-client \
         libibverbs-dev \
-        libnuma-dev &&\
-    ldconfig
+        libnuma-dev && \
+    ldconfig && rm -rf /var/lib/apt/lists/*;
 
 # copy conda environment (includes numpy, mpi4py, pytorch, onnxruntime)
 COPY --from=builder /opt/conda /opt/conda