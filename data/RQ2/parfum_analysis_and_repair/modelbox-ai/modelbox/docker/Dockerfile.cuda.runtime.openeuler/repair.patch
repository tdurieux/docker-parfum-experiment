diff --git a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/modelbox-ai/modelbox/docker/Dockerfile.cuda.runtime.openeuler b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/modelbox-ai/modelbox/docker/Dockerfile.cuda.runtime.openeuler/repaired.Dockerfile
index 290aea5..124d559 100644
--- a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/modelbox-ai/modelbox/docker/Dockerfile.cuda.runtime.openeuler
+++ b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/modelbox-ai/modelbox/docker/Dockerfile.cuda.runtime.openeuler/repaired.Dockerfile
@@ -32,18 +32,18 @@ RUN mkdir -p /root/.pip && \
     NVIDIA_GPGKEY_SUM=d1be581509378368edeec8c1eb2958702feedf3bc3d17011adbf24efacce4ab5 && \
     curl -fsSL https://developer.download.nvidia.com/compute/cuda/repos/rhel7/x86_64/7fa2af80.pub | sed '/^Version/d' > /etc/pki/rpm-gpg/RPM-GPG-KEY-NVIDIA && \
     echo "$NVIDIA_GPGKEY_SUM  /etc/pki/rpm-gpg/RPM-GPG-KEY-NVIDIA" | sha256sum -c --strict - && \
-    if [ "${CUDA_VERSION}" = "10.2" ]; then \
+    if [ "${CUDA_VERSION}" = "10.2" ];then \
         dnf install -y --nogpgcheck --setopt=obsoletes=0 \
             libcudnn8-8.0.0.180-1.cuda10.2 \
             libcublas10-10.2.2.89-1; \
     elif [ "${CUDA_VERSION}" = "11.2" ]; then \
-        curl -LO https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-linux-x86_64-2.6.0.tar.gz && \
+        curl -f -LO https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-linux-x86_64-2.6.0.tar.gz && \
         tar zxf libtensorflow-gpu-linux-x86_64-2.6.0.tar.gz -C /usr/local/ && \
         rm -rf /usr/local/include/tensorflow && \
         python3 -m pip install --no-cache-dir tensorflow-gpu==2.6.0 && \
         dnf install -y --nogpgcheck --setopt=obsoletes=0 \
             libcudnn8-8.1.1.33-1.cuda11.2 \
-            libcublas-11-2-11.4.1.1043;fi && \
+            libcublas-11-2-11.4.1.1043; rm libtensorflow-gpu-linux-x86_64-2.6.0.tar.gzfi && \
     find /usr/local -name "*.a"|xargs rm -f && \
     dnf clean all && rm -rf /var/cache/dnf/* /root/*
 
@@ -51,7 +51,7 @@ RUN dnf install -y --nogpgcheck --setopt=obsoletes=0 \
         cuda-nvtx-${CUDA_VER} \
         cuda-libraries-${CUDA_VER} && \
     ln -s cuda-${CUDA_VERSION} /usr/local/cuda && \
-    if [ -n "${TRT_VERSION}" ]; then \
+    if [ -n "${TRT_VERSION}" ];then \
         v="7.1.3-1.cuda10.2" && \
         dnf install -y --nogpgcheck --setopt=obsoletes=0 \
             libcudnn8-8.0.0.180-1.cuda10.2 \
@@ -60,9 +60,9 @@ RUN dnf install -y --nogpgcheck --setopt=obsoletes=0 \
             libnvparsers7-${v} \
             libnvinfer-plugin7-${v}; \
     elif [ -n "${TORCH_VERSION}" ]; then \
-        curl -LO https://download.pytorch.org/libtorch/cu102/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu102.zip && \
+        curl -f -LO https://download.pytorch.org/libtorch/cu102/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu102.zip && \
         unzip libtorch-*.zip -d /root >/dev/null 2>&1 && \
-        cp -af libtorch/lib /usr/local/;fi && \
+        cp -af libtorch/lib /usr/local/; fi && \
     find /usr/local -name "*.a"|xargs rm -f && \
     dnf clean all && rm -rf /var/cache/dnf/* /root/*