{
  "startTime": 1674255147350,
  "endTime": 1674255148674,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 106,
        "lineEnd": 107,
        "columnStart": 4,
        "columnEnd": 108
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 77,
        "lineEnd": 77,
        "columnStart": 4,
        "columnEnd": 23
      }
    },
    {
      "rule": "configureShouldUseBuildFlag",
      "position": {
        "lineStart": 99,
        "lineEnd": 99,
        "columnStart": 7,
        "columnEnd": 18
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# Copyright 2018 AT&T Intellectual Property.  All other rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Docker image to run Airflow on Kubernetes\nARG FROM=opensuse/leap:15.1\nFROM ${FROM}\n\nLABEL org.opencontainers.image.authors='airship-discuss@lists.airshipit.org, irc://#airshipit@freenode' \\\n      org.opencontainers.image.url='https://airshipit.org' \\\n      org.opencontainers.image.documentation='https://airship-shipyard.readthedocs.org' \\\n      org.opencontainers.image.source='https://opendev.org/airship/shipyard' \\\n      org.opencontainers.image.vendor='The Airship Authors' \\\n      org.opencontainers.image.licenses='Apache-2.0'\n\n# Do not prompt user for choices on installation/configuration of packages\n# Set port 8080 for Airflow Web\n# Set port 5555 for Airflow Flower\n# Set port 8793 for Airflow Worker\nENV container docker\nENV WEB_PORT 8080\nENV FLOWER_PORT 5555\nENV WORKER_PORT 8793\nENV SLUGIFY_USES_TEXT_UNIDECODE yes\n\n# Expose port for applications\nEXPOSE $WEB_PORT\nEXPOSE $FLOWER_PORT\nEXPOSE $WORKER_PORT\n\n# Set ARG for usage during build\nARG AIRFLOW_HOME=/usr/local/airflow\n# Moved celery to images/airflow/requirements.txt as apache-airflow uses a\n# version of celery incompatibile with the version of kombu needed by other\n# Airship components\nARG AIRFLOW_SRC=\"apache-airflow[crypto,postgres,hive,hdfs,jdbc]==1.10.5\"\nARG ctx_base=src/bin\n\n# Kubectl version\nARG KUBECTL_VERSION=1.16.2\n\n# Needed from apache-airflow 1.10.2, since core.airflow_home config is deprecated\nENV AIRFLOW_HOME=${AIRFLOW_HOME}\n\nRUN set -ex && \\\n    zypper -q update -y ;\\\n    zypper --non-interactive install --no-recommends \\\n        automake \\\n        ca-certificates \\\n        curl \\\n        git-core \\\n        gcc-c++ \\\n        libffi-devel \\\n        libopenssl-devel \\\n        libpqxx-devel \\\n        libtool \\\n        gcc-locale \\\n        netcat-openbsd \\\n        netcfg \\\n        which \\\n        python3 \\\n        python3-setuptools \\\n        python3-pip \\\n        python3-devel \\\n        python3-python-dateutil \\\n        make\n\nRUN pip3 install --no-cache-dir -U pip \\\n    && zypper clean -a \\\n    && rm -rf \\\n        /tmp/* \\\n        /var/tmp/* \\\n        /var/log/* \\\n        /usr/share/man \\\n        /usr/share/doc \\\n        /usr/share/doc-base\n\n# Explicitly need to create usergroup with same name in suse\nRUN useradd -U -ms /bin/bash -d ${AIRFLOW_HOME} airflow\n\n# Install LibYAML\nENV LD_LIBRARY_PATH=/usr/local/lib\n\nARG LIBYAML_VERSION=0.2.5\nRUN set -ex \\\n    && git clone https://github.com/yaml/libyaml.git \\\n    && cd libyaml \\\n    && git checkout $LIBYAML_VERSION \\\n    && ./bootstrap \\\n    && ./configure --build=\"$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)\" \\\n    && make \\\n    && make install \\\n    && cd .. \\\n    && rm -fr libyaml\n\n# Things that change mostly infrequently\nRUN curl -f -L -o /usr/local/bin/kubectl \\\n       https://storage.googleapis.com/kubernetes-release/release/v${KUBECTL_VERSION}/bin/linux/amd64/kubectl \\\n    && chmod +x /usr/local/bin/kubectl\n\n# Dependency requirements\n# Note - removing snakebite (python 2 vs. 3). See:\n#    https://github.com/puckel/docker-airflow/issues/77\nCOPY images/airflow/requirements.txt /tmp/\nRUN pip3 install -r /tmp/requirements.txt --no-cache-dir \\\n    && pip3 uninstall -y snakebite || true \\\n    && pip3 uninstall -y psycopg2 || true \\\n    && pip3 install --no-cache-dir --force-reinstall $(pip freeze | grep psycopg2-binary) || true\n\n# Copy scripts used in the container:\nCOPY images/airflow/script/*.sh ${AIRFLOW_HOME}/\n\n# Copy configuration (e.g. logging config for Airflow):\nCOPY images/airflow/config/*.py ${AIRFLOW_HOME}/config/\n\n# Change permissions\nRUN chown -R airflow:airflow ${AIRFLOW_HOME}\n\n# Setting the version explicitly for PBR\nENV PBR_VERSION 0.1a1\n\n# Shipyard\n#\n# Shipyard provides core functionality used by the Airflow plugins/operators\n# Since Shipyard and Airflow are built together as images, this should prevent\n# stale or out-of-date code between these parts.\n# Shipyard requirements, source and installation\nCOPY ${ctx_base}/shipyard_airflow/requirements.txt /tmp/api_requirements.txt\nRUN pip3 install -r /tmp/api_requirements.txt --no-cache-dir \\\n    && pip3 install $AIRFLOW_SRC --no-cache-dir\n\nCOPY ${ctx_base}/shipyard_airflow /tmp/shipyard/\nRUN cd /tmp/shipyard \\\n    && python3 setup.py install\n\n# Note: The value for the dags and plugins directories that are sourced\n# from the values.yaml of the Shipyard Helm chart need to align with these\n# directories. If they do not, airflow will not find the intended dags and\n# plugins.\n#\n# Note: In the case of building images using the provided Makefile, a test is\n# run against the built-in dags provided with Airflow. Since there is no Helm\n# chart to reconfigure the airflow.cfg with these directories, these dags and\n# plugins are not known to Airflow during the image test.\n#\n# Copy the plugins and dags that will be used by this Airflow image:\nCOPY ${ctx_base}/shipyard_airflow/shipyard_airflow/plugins ${AIRFLOW_HOME}/plugins/\nCOPY ${ctx_base}/shipyard_airflow/shipyard_airflow/dags ${AIRFLOW_HOME}/dags/\n\n# Set work directory\nUSER airflow\nWORKDIR ${AIRFLOW_HOME}\n\n# Execute entrypoint\nENTRYPOINT [\"./entrypoint.sh\"]\n"
}