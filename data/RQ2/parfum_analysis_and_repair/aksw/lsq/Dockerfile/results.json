{
  "startTime": 1674252989824,
  "endTime": 1674252990409,
  "originalSmells": [
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 27
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 27
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM maven:3-jdk-11 as build\n\nCOPY . .\nRUN mvn -Pdist,standalone clean install\n\n\n# Final running image\nFROM openjdk:11-jre-slim\n\n# Import the lsq-cli jar from the build step\nCOPY --from=build lsq-cli/target/lsq-cli-*-jar-with-dependencies.jar /app/lsq-cli.jar\n\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y wget && rm -rf /var/lib/apt/lists/*;\n\n# # Install Spark for standalone context in /opt\n# ENV APACHE_SPARK_VERSION=3.2.0\n# ENV HADOOP_VERSION=3.2\n# ENV SPARK_HOME=/opt/spark\n# ENV SPARK_OPTS=\"--driver-java-options=-Xms1024M --driver-java-options=-Xmx2048M --driver-java-options=-Dlog4j.logLevel=info\"\n# RUN wget -q -O spark.tgz https://archive.apache.org/dist/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz && \\\n#     tar xzf spark.tgz -C /opt && \\\n#     rm \"spark.tgz\" && \\\n#     ln -s \"/opt/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}\" $SPARK_HOME\n\n\n# Using /data as working directory that will be shared with host for input/output files\nWORKDIR /data\nVOLUME [ \"/data\" ]\n\nENTRYPOINT [\"java\",\"-jar\",\"/app/lsq-cli.jar\"]\nCMD [\"-h\"]\n\n# Usage:\n# docker run -it -v $(pwd):/data ghcr.io/aksw/lsq rx rdfize --endpoint=http://dbpedia.org/sparql virtuoso.dbpedia.log"
}