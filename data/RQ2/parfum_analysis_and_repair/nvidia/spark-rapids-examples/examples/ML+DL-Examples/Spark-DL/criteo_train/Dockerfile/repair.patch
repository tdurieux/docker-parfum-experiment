diff --git a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/nvidia/spark-rapids-examples/examples/ML+DL-Examples/Spark-DL/criteo_train/Dockerfile b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/nvidia/spark-rapids-examples/examples/ML+DL-Examples/Spark-DL/criteo_train/Dockerfile/repaired.Dockerfile
index 0e56925..62d9035 100644
--- a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/nvidia/spark-rapids-examples/examples/ML+DL-Examples/Spark-DL/criteo_train/Dockerfile
+++ b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/nvidia/spark-rapids-examples/examples/ML+DL-Examples/Spark-DL/criteo_train/Dockerfile/repaired.Dockerfile
@@ -40,7 +40,7 @@ ENV INSTALL_PREFIX=/usr
 RUN apt update -y --fix-missing && \
     apt upgrade -y && \
       apt install -y --no-install-recommends software-properties-common && \
-      apt update -y --fix-missing
+      apt update -y --fix-missing && rm -rf /var/lib/apt/lists/*;
 
 RUN apt install -y --no-install-recommends \
       git \
@@ -66,16 +66,16 @@ RUN apt install -y --no-install-recommends \
       libtool && \
     apt-get autoremove -y && \
     apt-get clean && \
-    rm -rf /var/lib/apt/lists/* 
+    rm -rf /var/lib/apt/lists/*
     #update-alternatives --install /usr/bin/python python /usr/bin/python3.8 1 && \
     #wget https://bootstrap.pypa.io/get-pip.py && \
     #python get-pip.py
 
 # Install cmake
-RUN wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2>/dev/null | gpg --dearmor - | tee /etc/apt/trusted.gpg.d/kitware.gpg >/dev/null && \
+RUN wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2>/dev/null | gpg --batch --dearmor - | tee /etc/apt/trusted.gpg.d/kitware.gpg >/dev/null && \
     apt-add-repository 'deb https://apt.kitware.com/ubuntu/ focal main' && \
     apt-get update && \
-    apt-get install -y cmake
+    apt-get install --no-install-recommends -y cmake && rm -rf /var/lib/apt/lists/*;
 
 # Install arrow from source
 ENV ARROW_HOME=/usr/local
@@ -83,7 +83,7 @@ RUN git clone --branch apache-arrow-4.0.1 --recurse-submodules https://github.co
     pushd build-env && \
       export PARQUET_TEST_DATA="${PWD}/cpp/submodules/parquet-testing/data" && \
       export ARROW_TEST_DATA="${PWD}/testing/data" && \
-      pip install -r python/requirements-build.txt && \
+      pip install --no-cache-dir -r python/requirements-build.txt && \
       mkdir cpp/release && \
       pushd cpp/release && \
         cmake -DCMAKE_INSTALL_PREFIX=${ARROW_HOME} \
@@ -114,7 +114,7 @@ RUN git clone --branch apache-arrow-4.0.1 --recurse-submodules https://github.co
         export PYARROW_WITH_ORC=ON && \
         export PYARROW_WITH_DATASET=ON && \
         python setup.py build_ext --build-type=release bdist_wheel && \
-        pip install dist/*.whl && \
+        pip install --no-cache-dir dist/*.whl && \
       popd && \
     popd && \
     rm -rf build-env
@@ -127,7 +127,7 @@ RUN git clone https://github.com/rapidsai/rmm.git build-env && cd build-env/ &&
     cd ..; \
     pushd build-env && \
     ./build.sh librmm && \
-    pip install python/. && \
+    pip install --no-cache-dir python/. && \
     popd && \
     rm -rf build-env
 
@@ -158,19 +158,19 @@ RUN apt-get update -y && \
 ENV PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION='python'
 
 
-RUN pip install pandas sklearn ortools nvtx-plugins pydot && \
+RUN pip install --no-cache-dir pandas sklearn ortools nvtx-plugins pydot && \
     pip cache purge
 
 # tf-nightly for performance test
 # more details: https://github.com/tensorflow/tensorflow/issues/44194
-RUN pip uninstall tensorflow -y; pip install tf-nightly==2.7.0.dev20210722
-RUN pip uninstall keras-nightly -y; pip install keras-nightly==2.7.0.dev2021072200
+RUN pip uninstall tensorflow -y; pip install --no-cache-dir tf-nightly==2.7.0.dev20210722
+RUN pip uninstall keras-nightly -y; pip install --no-cache-dir keras-nightly==2.7.0.dev2021072200
 
 
 RUN mkdir -p /usr/local/nvidia/lib64 && \
     ln -s /usr/local/cuda/lib64/libcusolver.so /usr/local/nvidia/lib64/libcusolver.so.10
 
-RUN pip install pybind11
+RUN pip install --no-cache-dir pybind11
 SHELL ["/bin/bash", "-c"]
 
 # prepare nccl
@@ -180,7 +180,7 @@ RUN wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86
     && apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub \
     && add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /" \
     && apt-get update \
-    && apt install libnccl2=2.8.4-1+cuda11.2 libnccl-dev=2.8.4-1+cuda11.2
+    && apt install -y --no-install-recommends libnccl2=2.8.4-1+cuda11.2 libnccl-dev=2.8.4-1+cuda11.2 && rm -rf /var/lib/apt/lists/*;
 
 # install Horovod
 RUN pip uninstall horovod -y
@@ -193,16 +193,16 @@ RUN git clone https://github.com/NVIDIA/NVTabular.git /nvtabular/ && \
     python setup.py develop --user;
 
 
-RUN pip install pynvml pytest graphviz sklearn scipy matplotlib
-RUN pip install nvidia-pyindex; pip install tritonclient[all] grpcio-channelz
-RUN pip install nvtx mpi4py==3.0.3 cupy-cuda112 cachetools typing_extensions fastavro
+RUN pip install --no-cache-dir pynvml pytest graphviz sklearn scipy matplotlib
+RUN pip install --no-cache-dir nvidia-pyindex; pip install --no-cache-dir tritonclient[all] grpcio-channelz
+RUN pip install --no-cache-dir nvtx mpi4py==3.0.3 cupy-cuda112 cachetools typing_extensions fastavro
 
-RUN apt-get update; apt-get install -y graphviz
+RUN apt-get update; apt-get install --no-install-recommends -y graphviz && rm -rf /var/lib/apt/lists/*;
 
-RUN pip uninstall numpy -y; pip install numpy
-RUN pip install dask==2021.04.1 distributed==2021.04.1 dask-cuda
-RUN pip install dask[dataframe]==2021.04.1
-RUN pip uninstall pandas -y; pip install pandas==1.1.5
+RUN pip uninstall numpy -y; pip install --no-cache-dir numpy
+RUN pip install --no-cache-dir dask==2021.04.1 distributed==2021.04.1 dask-cuda
+RUN pip install --no-cache-dir dask[dataframe]==2021.04.1
+RUN pip uninstall pandas -y; pip install --no-cache-dir pandas==1.1.5
 RUN echo $(du -h --max-depth=1 /)
 
 
@@ -213,7 +213,7 @@ RUN wget \
     && rm spark-3.1.2-bin-hadoop3.2.tgz
 
 ENV DEBIAN_FRONTEND=noninteractive
-RUN apt-get install openjdk-8-jdk openjdk-8-jre lsb-release -y --allow-downgrades --allow-change-held-packages --no-install-recommends
+RUN apt-get install openjdk-8-jdk openjdk-8-jre lsb-release -y --allow-downgrades --allow-change-held-packages --no-install-recommends && rm -rf /var/lib/apt/lists/*;
 ENV JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk-amd64
 ENV PATH $PATH:/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/bin:/usr/lib/jvm/java-1.8.0-openjdk-amd64/bin