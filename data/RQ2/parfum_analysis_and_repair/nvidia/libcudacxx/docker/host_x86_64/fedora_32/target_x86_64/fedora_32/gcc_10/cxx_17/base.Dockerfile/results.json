{
  "startTime": 1674252905022,
  "endTime": 1674252905996,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 19,
        "lineEnd": 19,
        "columnStart": 4,
        "columnEnd": 20
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 18,
        "lineEnd": 18,
        "columnStart": 4,
        "columnEnd": 101
      }
    },
    {
      "rule": "tarSomethingRmTheSomething",
      "position": {
        "lineStart": 105,
        "lineEnd": 105,
        "columnStart": 37,
        "columnEnd": 60
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# Dockerfile for libcudacxx_base:host_x86_64_fedora_32__target_x86_64_fedora_32__gcc_10_cxx_17\n\nFROM fedora:32\n\nMAINTAINER Bryce Adelstein Lelbach <blelbach@nvidia.com>\n\nARG LIBCUDACXX_SKIP_BASE_TESTS_BUILD\nARG LIBCUDACXX_COMPUTE_ARCHS\nARG COMPILER_CXX_DIALECT\n\nENV COMPILER_CXX_DIALECT=$COMPILER_CXX_DIALECT\n\n###############################################################################\n# BUILD: The following is invoked when the image is built.\n\nSHELL [\"/usr/bin/env\", \"bash\", \"-c\"]\n\nRUN yum -y updateinfo\\\n && yum -y install which findutils make gcc-c++ libstdc++-static llvm-devel clang python3 python3-pip \\\n && pip3 install --no-cache-dir lit \\\n && mkdir -p /sw/gpgpu/libcudacxx/build \\\n && mkdir -p /sw/gpgpu/libcudacxx/libcxx/build && rm -rf /var/cache/yum\n\n# Update CMake to 3.18\nADD https://github.com/Kitware/CMake/releases/download/v3.18.5/cmake-3.18.5-Linux-x86_64.sh /tmp/cmake.sh\nRUN sh /tmp/cmake.sh --skip-license --prefix=/usr\n\n# For debugging.\n#RUN yum -y install gdb strace vim\n\n# We use ADD here because it invalidates the cache for subsequent steps, which\n# is what we want, as we need to rebuild if the sources have changed.\n\n# Copy NVCC and the CUDA runtime from the source tree.\nADD bin /sw/gpgpu/bin\n\n\n# Copy libcu++ sources from the source tree.\nADD libcudacxx /sw/gpgpu/libcudacxx\n\n# List out everything in /sw before the build.\nRUN echo \"Contents of /sw:\" && cd /sw/ && find\n\n# Build libc++ and configure libc++ tests.\nRUN set -o pipefail; cd /sw/gpgpu/libcudacxx/libcxx/build\\\n && cmake ../..\\\n -DLIBCUDACXX_ENABLE_STATIC_LIBRARY=OFF\\\n -DLIBCUDACXX_ENABLE_LIBCUDACXX_TESTS=OFF\\\n -DLIBCUDACXX_ENABLE_LIBCXX_TESTS=ON\\\n -DLIBCXX_TEST_STANDARD_VER=c++$COMPILER_CXX_DIALECT\\\n -DCMAKE_CXX_COMPILER=g++\\\n -DCMAKE_CUDA_COMPILER=/sw/gpgpu/bin/x86_64_Linux_release/nvcc\\\n && make -j\\\n 2>&1 | tee /sw/gpgpu/libcudacxx/build/cmake_libcxx.log\n\n# Configure libcu++ tests.\nRUN set -o pipefail; cd /sw/gpgpu/libcudacxx/build\\\n && cmake ..\\\n -DCMAKE_CXX_COMPILER=g++\\\n -DCMAKE_CUDA_COMPILER=/sw/gpgpu/bin/x86_64_Linux_release/nvcc\\\n -DLIBCUDACXX_ENABLE_LIBCUDACXX_TESTS=ON\\\n -DLIBCUDACXX_ENABLE_LIBCXX_TESTS=OFF\\\n -DLIBCUDACXX_TEST_STANDARD_VER=c++$COMPILER_CXX_DIALECT\\\n 2>&1 | tee /sw/gpgpu/libcudacxx/build/cmake_libcudacxx.log\n\n# Build tests if requested.\n# NOTE: libc++ tests are disabled until we can setup libc++abi.\nRUN set -o pipefail; cd /sw/gpgpu/libcudacxx\\\n && LIBCUDACXX_COMPUTE_ARCHS=$LIBCUDACXX_COMPUTE_ARCHS\\\n LIBCUDACXX_SKIP_BASE_TESTS_BUILD=$LIBCUDACXX_SKIP_BASE_TESTS_BUILD\\\n /sw/gpgpu/libcudacxx/utils/nvidia/linux/perform_tests.bash\\\n --skip-tests-runs\\\n --skip-libcxx-tests\\\n 2>&1 | tee /sw/gpgpu/libcudacxx/build/build_lit_all.log\n\n# Build tests for sm6x if requested.\nRUN set -o pipefail; cd /sw/gpgpu/libcudacxx\\\n && LIBCUDACXX_COMPUTE_ARCHS=\"60 61 62\"\\\n LIBCUDACXX_SKIP_BASE_TESTS_BUILD=$LIBCUDACXX_SKIP_BASE_TESTS_BUILD\\\n /sw/gpgpu/libcudacxx/utils/nvidia/linux/perform_tests.bash\\\n --skip-tests-runs\\\n --skip-libcxx-tests\\\n 2>&1 | tee /sw/gpgpu/libcudacxx/build/build_lit_sm6x.log\n\n# Build tests for sm7x if requested.\nRUN set -o pipefail; cd /sw/gpgpu/libcudacxx\\\n && LIBCUDACXX_COMPUTE_ARCHS=\"70 72 75\"\\\n LIBCUDACXX_SKIP_BASE_TESTS_BUILD=$LIBCUDACXX_SKIP_BASE_TESTS_BUILD\\\n /sw/gpgpu/libcudacxx/utils/nvidia/linux/perform_tests.bash\\\n --skip-tests-runs\\\n --skip-libcxx-tests\\\n 2>&1 | tee /sw/gpgpu/libcudacxx/build/build_lit_sm7x.log\n\n# Build tests for sm8x if requested.\nRUN set -o pipefail; cd /sw/gpgpu/libcudacxx\\\n && LIBCUDACXX_COMPUTE_ARCHS=\"80\"\\\n LIBCUDACXX_SKIP_BASE_TESTS_BUILD=$LIBCUDACXX_SKIP_BASE_TESTS_BUILD\\\n /sw/gpgpu/libcudacxx/utils/nvidia/linux/perform_tests.bash\\\n --skip-tests-runs\\\n --skip-libcxx-tests\\\n 2>&1 | tee /sw/gpgpu/libcudacxx/build/build_lit_sm8x.log\n\n# Package the logs up, because `docker container cp` doesn't support wildcards,\n# and I want to limit the number of places we have to make changes when we ship\n# new architectures.\nRUN cd /sw/gpgpu/libcudacxx/build && tar -cvf logs.tar *.log && rm logs.tar\n\nWORKDIR /sw/gpgpu/libcudacxx\n\n"
}