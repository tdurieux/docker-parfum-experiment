diff --git a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/nvidia/deeplearningexamples/TensorFlow2/LanguageModeling/ELECTRA/Dockerfile b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/nvidia/deeplearningexamples/TensorFlow2/LanguageModeling/ELECTRA/Dockerfile/repaired.Dockerfile
index 5c095c4..44de6d2 100644
--- a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/nvidia/deeplearningexamples/TensorFlow2/LanguageModeling/ELECTRA/Dockerfile
+++ b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/nvidia/deeplearningexamples/TensorFlow2/LanguageModeling/ELECTRA/Dockerfile/repaired.Dockerfile
@@ -1,4 +1,3 @@
-# syntax = docker/dockerfile:1
 # Copyright (c) 2020 NVIDIA CORPORATION. All rights reserved.
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
@@ -23,7 +22,7 @@ RUN pip download tokenizers==0.7.0
 
 FROM quay.io/pypa/manylinux2014_aarch64 as tokenizers_arm64
 ARG PYVER=38
-RUN yum install -y openssl-devel
+RUN yum install -y openssl-devel && rm -rf /var/cache/yum
 RUN curl https://sh.rustup.rs -sSf | sh -s -- --default-toolchain nightly-2019-11-01 -y
 ENV PATH="/root/.cargo/bin:$PATH"
 ENV PYBIN=/opt/python/cp${PYVER}-cp${PYVER}/bin
@@ -47,7 +46,7 @@ FROM tokenizers_${TARGETARCH} AS tokenizers
 
 
 FROM ${FROM_IMAGE_NAME}
-RUN apt-get update && apt-get install -y pbzip2 pv bzip2 cabextract
+RUN apt-get update && apt-get install --no-install-recommends -y pbzip2 pv bzip2 cabextract && rm -rf /var/lib/apt/lists/*;
 
 RUN --mount=from=tokenizers,source=/wheelhouse,target=/tmp/wheelhouse \
     pip install --no-cache-dir /tmp/wheelhouse/tokenizers*.whl
@@ -63,5 +62,5 @@ RUN pip install --no-cache-dir tqdm boto3 requests six ipdb h5py nltk progressba
  git+https://github.com/NVIDIA/dllogger \
  nvidia-ml-py3==7.352.0
 
-RUN apt-get install -y iputils-ping
+RUN apt-get install --no-install-recommends -y iputils-ping && rm -rf /var/lib/apt/lists/*;
 COPY . .