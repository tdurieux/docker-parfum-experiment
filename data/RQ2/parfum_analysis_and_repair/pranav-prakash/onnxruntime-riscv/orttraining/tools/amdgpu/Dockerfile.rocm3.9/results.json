{
  "startTime": 1674220182651,
  "endTime": 1674220184541,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 4,
        "lineEnd": 4,
        "columnStart": 4,
        "columnEnd": 57
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 116,
        "lineEnd": 116,
        "columnStart": 4,
        "columnEnd": 62
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 137,
        "lineEnd": 137,
        "columnStart": 5,
        "columnEnd": 57
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 141,
        "lineEnd": 141,
        "columnStart": 4,
        "columnEnd": 100
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 4,
        "columnEnd": 32
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 9,
        "lineEnd": 15,
        "columnStart": 4,
        "columnEnd": 11
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 194,
        "lineEnd": 194,
        "columnStart": 4,
        "columnEnd": 30
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 4,
        "columnEnd": 32
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 9,
        "lineEnd": 15,
        "columnStart": 4,
        "columnEnd": 11
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 194,
        "lineEnd": 194,
        "columnStart": 4,
        "columnEnd": 30
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 8,
        "lineEnd": 8,
        "columnStart": 4,
        "columnEnd": 32
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 9,
        "lineEnd": 15,
        "columnStart": 4,
        "columnEnd": 11
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 72,
        "lineEnd": 72,
        "columnStart": 25,
        "columnEnd": 79
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 194,
        "lineEnd": 194,
        "columnStart": 4,
        "columnEnd": 30
      }
    }
  ],
  "repairedSmells": [
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 6,
        "lineEnd": 6,
        "columnStart": 4,
        "columnEnd": 56
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 7,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 11
      }
    },
    {
      "rule": "aptGetUpdatePrecedesInstall",
      "position": {
        "lineStart": 192,
        "lineEnd": 192,
        "columnStart": 4,
        "columnEnd": 54
      }
    }
  ],
  "repairedDockerfile": "FROM rocm/tensorflow:rocm3.9-tf2.3-dev\n\nRUN wget -q -O - https://repo.radeon.com/rocm/rocm.gpg.key | apt-key add -\nRUN echo 'deb [arch=amd64] http://repo.radeon.com/rocm/apt/3.9/ xenial main' | tee /etc/apt/sources.list.d/rocm.list\n\nRUN apt-get -y update\nRUN apt-get -y --no-install-recommends install apt-utils && rm -rf /var/lib/apt/lists/*;\nRUN apt-get -y --no-install-recommends install build-essential autotools-dev \\\n    make git curl vim wget rsync jq openssh-server openssh-client sudo \\\n    iputils-ping net-tools ethtool libcap2 \\\n    automake autoconf libtool flex doxygen \\\n    perl lsb-release iproute2 pciutils graphviz \\\n    bc tar git bash pbzip2 pv bzip2 cabextract \\\n    g++ gcc \\\n    && apt-get autoremove && rm -rf /var/lib/apt/lists/*;\n\n# sh\nRUN rm /bin/sh && ln -s /bin/bash /bin/sh\n\n# Labels for the docker\nLABEL description=\"This docker sets up the environment to run ORT Training with AMD GPU\"\n\n# CMake\nENV CMAKE_VERSION=3.18.2\nRUN cd /usr/local && \\\n    wget -q -O - https://github.com/Kitware/CMake/releases/download/v${CMAKE_VERSION}/cmake-${CMAKE_VERSION}-Linux-x86_64.tar.gz | tar zxf -\nENV PATH=/usr/local/cmake-${CMAKE_VERSION}-Linux-x86_64/bin:${PATH}\n\n# WORKSPACE_DIR\nENV WORKSPACE_DIR=/workspace\nRUN mkdir -p $WORKSPACE_DIR\nWORKDIR $WORKSPACE_DIR\n\n# Infiniband setup, openmpi installed under /usr/mpi/gcc/openmpi-4.0.4rc3 doesn't support multi-thread\nENV MOFED_VERSION=5.1-0.6.6.0\nENV MOFED_OS=ubuntu18.04\nENV MOFED_FILENAME=MLNX_OFED_LINUX-${MOFED_VERSION}-${MOFED_OS}-x86_64\nRUN curl -fSsL https://www.mellanox.com/downloads/ofed/MLNX_OFED-${MOFED_VERSION}/${MOFED_FILENAME}.tgz | tar -zxpf -\nRUN cd MLNX_OFED_LINUX-${MOFED_VERSION}-${MOFED_OS}-x86_64 && \\\n    ./mlnxofedinstall --force --user-space-only --without-fw-update --hpc && \\\n    cd .. && \\\n    rm -r MLNX_OFED_LINUX-${MOFED_VERSION}-${MOFED_OS}-x86_64\n\n# install miniconda (comes with python 3.9 default)\nARG CONDA_VERSION=4.7.10\nARG CONDA_URL=https://repo.anaconda.com/miniconda/Miniconda3-${CONDA_VERSION}-Linux-x86_64.sh\nRUN curl -fSsL --insecure ${CONDA_URL} -o install-conda.sh &&\\\n    /bin/bash ./install-conda.sh -b -p /opt/conda &&\\\n    /opt/conda/bin/conda clean -ya\nENV PATH=/opt/conda/bin:${PATH}\n\nARG NUMPY_VERSION=1.18.5\nARG ONNX_VERSION=1.7.0\nRUN conda install -y \\\n        numpy=${NUMPY_VERSION} \\\n        cmake \\\n        ninja \\\n        pyyaml \\\n        cffi \\\n        setuptools \\\n    && pip install --no-cache-dir wheel tqdm boto3 requests six ipdb h5py html2text nltk progressbar \\\n        git+https://github.com/NVIDIA/dllogger \\\n        onnx==\"${ONNX_VERSION}\"\n\n# GITHUB_DIR\nENV GITHUB_DIR=$WORKSPACE_DIR/github\nRUN mkdir -p $GITHUB_DIR\n\n# UCX\nWORKDIR $GITHUB_DIR\nRUN apt-get -y update && apt-get -y --no-install-recommends install libnuma-dev && rm -rf /var/lib/apt/lists/*;\nARG UCX_VERSION=1.9.0-rc3\nENV UCX_DIR=$WORKSPACE_DIR/ucx-$UCX_VERSION\nRUN git clone https://github.com/openucx/ucx.git \\\n  && cd ucx \\\n  && git checkout v$UCX_VERSION \\\n  && ./autogen.sh \\\n  && mkdir build \\\n  && cd build \\\n  && ../contrib/configure-opt --prefix=$UCX_DIR --without-rocm --without-knem --without-cuda \\\n  && make -j\"$(nproc)\" \\\n  && make install\n\n# OpenMPI\n# note: require --enable-orterun-prefix-by-default for Azure machine learning compute\n# note: disable verbs as we use ucx middleware and don't want btl openib warnings\nWORKDIR $GITHUB_DIR\nARG OPENMPI_BASEVERSION=4.0\nARG OPENMPI_VERSION=${OPENMPI_BASEVERSION}.5\nENV OPENMPI_DIR=$WORKSPACE_DIR/openmpi-${OPENMPI_VERSION}\nRUN git clone --recursive https://github.com/open-mpi/ompi.git \\\n  && cd ompi \\\n  && git checkout v$OPENMPI_VERSION \\\n  && ./autogen.pl \\\n  && mkdir build \\\n  && cd build \\\n  && ../configure --prefix=$OPENMPI_DIR --with-ucx=$UCX_DIR --without-verbs \\\n                  --enable-mpirun-prefix-by-default --enable-orterun-prefix-by-default \\\n                  --enable-mca-no-build=btl-uct --disable-mpi-fortran \\\n  && make -j\"$(nproc)\" \\\n  && make install \\\n  && ldconfig \\\n  && test -f ${OPENMPI_DIR}/bin/mpic++\n\nENV PATH=$OPENMPI_DIR/bin:${PATH}\nENV LD_LIBRARY_PATH=$OPENMPI_DIR/lib:${LD_LIBRARY_PATH}\n\n# Create a wrapper for OpenMPI to allow running as root by default\nRUN mv $OPENMPI_DIR/bin/mpirun $OPENMPI_DIR/bin/mpirun.real && \\\n    echo '#!/bin/bash' > $OPENMPI_DIR/bin/mpirun && \\\n    echo 'mpirun.real --allow-run-as-root \"$@\"' >> $OPENMPI_DIR/bin/mpirun && \\\n    chmod a+x $OPENMPI_DIR/bin/mpirun\n\n# install mpi4py (be sure to link existing /opt/openmpi-xxx)\nRUN CC=mpicc MPICC=mpicc pip --no-cache-dir install mpi4py --no-binary mpi4py\n\nARG CACHE_DATA=2020-12-06\n\n# ONNX Runtime\nWORKDIR $GITHUB_DIR\nENV ORT_DIR=$GITHUB_DIR/onnxruntime\nRUN git clone --recursive https://github.com/microsoft/onnxruntime.git \\\n  && cd onnxruntime \\\n  && python3 tools/ci_build/build.py \\\n    --cmake_extra_defines ONNXRUNTIME_VERSION=`cat ./VERSION_NUMBER` \\\n    --build_dir build \\\n    --config RelWithDebInfo \\\n    --parallel \\\n    --skip_tests \\\n    --build_wheel \\\n    --use_rocm --rocm_home /opt/rocm \\\n    --mpi_home $OPENMPI_DIR \\\n    --nccl_home /opt/rocm \\\n    --enable_training \\\n  && test -f $ORT_DIR/build/RelWithDebInfo/onnxruntime_training_bert \\\n  && pip install --no-cache-dir $ORT_DIR/build/RelWithDebInfo/dist/*.whl \\\n  && ldconfig\n\n# Instructions to pull and install the nightly ROCm3.8 PyTorch whl pacakge\nRUN pip3 install --no-cache-dir --pre torch -f https://download.pytorch.org/whl/nightly/rocm3.9/torch_nightly.html\n\n# ONNX Runtime Training Examples\nWORKDIR $GITHUB_DIR\nARG GPT2_DATASET=wikitext-103\nRUN git clone -b wezhan/amdgpu https://github.com/microsoft/onnxruntime-training-examples.git \\\n  && cd onnxruntime-training-examples \\\n  # Nvidia BERT\n  && git clone --no-checkout https://github.com/NVIDIA/DeepLearningExamples.git \\\n  && cd DeepLearningExamples \\\n  && git checkout cf54b787 \\\n  && cd .. \\\n  && mv DeepLearningExamples/PyTorch/LanguageModeling/BERT ${WORKSPACE_DIR} \\\n  && rm -rf DeepLearningExamples \\\n  && cp -r ./nvidia-bert/ort_addon/* ${WORKSPACE_DIR}/BERT \\\n  # GPT2 fine-tuning\n  && cd huggingface-gpt2 \\\n  && git clone https://github.com/huggingface/transformers.git \\\n  && cd transformers \\\n  && git checkout 9a0a8c1c6f4f2f0c80ff07d36713a3ada785eec5 \\\n  && cd .. \\\n  && mkdir -p ${WORKSPACE_DIR}/GPT2 \\\n  && cp -r transformers ${WORKSPACE_DIR}/GPT2 \\\n  && cd ${WORKSPACE_DIR}/GPT2/transformers \\\n  && git apply $GITHUB_DIR/onnxruntime-training-examples/huggingface-gpt2/ort_addon/src_changes.patch \\\n  && cp -r $GITHUB_DIR/onnxruntime-training-examples/huggingface-gpt2/ort_addon/ort_supplement/* ./ \\\n  && python3 -m pip install --no-cache-dir -e . \\\n  && python3 -m pip install --no-cache-dir -r examples/requirements.txt \\\n  && python3 -m pip install cerberus sympy packaging \\\n  && cd .. \\\n  && wget https://s3.amazonaws.com/research.metamind.io/wikitext/${GPT2_DATASET}-v1.zip \\\n  && unzip ${GPT2_DATASET}-v1.zip\n\nENV BERT_DIR=${WORKSPACE_DIR}/BERT\nENV GPT2_DIR=${WORKSPACE_DIR}/GPT2\nENV TRAIN_FILE=${WORKSPACE_DIR}/GPT2/${GPT2_DATASET}/wiki.train.tokens\nENV TEST_FILE=${WORKSPACE_DIR}/GPT2/${GPT2_DATASET}/wiki.test.tokens\n\n# Enable ssh access without password needed\nRUN sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/g' /etc/ssh/sshd_config\nRUN sed -i 's/#StrictModes yes/StrictModes no/g' /etc/ssh/sshd_config\nRUN sed -i 's/#PubkeyAuthentication yes/PubkeyAuthentication yes/g' /etc/ssh/sshd_config\nRUN sed -i 's/#PermitEmptyPasswords no/PermitEmptyPasswords yes/g' /etc/ssh/sshd_config\n\n# Start or Restart sshd service\nENTRYPOINT service ssh restart && /bin/bash\n\n# Add model and scripts\nADD model ${WORKSPACE_DIR}/model\nADD script ${WORKSPACE_DIR}/script\nRUN chmod a+x ${WORKSPACE_DIR}/script/run_bert.sh\n\n# add locale en_US.UTF-8\nRUN apt-get install --no-install-recommends -y locales && rm -rf /var/lib/apt/lists/*;\nRUN locale-gen en_US.UTF-8\n\n# Workaround an issue in AMD compiler which generates poor GPU ISA\n# when the type of kernel parameter is a structure and “pass-by-value” is used\nENV HSA_NO_SCRATCH_RECLAIM=1\n\n# Distributed training related environment variables\nENV HSA_FORCE_FINE_GRAIN_PCIE=1\nENV NCCL_DEBUG=INFO\n# ENV NCCL_DEBUG_SUBSYS=INIT,COLL\n\nWORKDIR ${WORKSPACE_DIR}/script\n"
}