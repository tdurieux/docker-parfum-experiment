{
  "startTime": 1674251588393,
  "endTime": 1674251589096,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 10,
        "lineEnd": 10,
        "columnStart": 4,
        "columnEnd": 110
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 18,
        "lineEnd": 18,
        "columnStart": 4,
        "columnEnd": 109
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 10,
        "lineEnd": 10,
        "columnStart": 4,
        "columnEnd": 110
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 18,
        "lineEnd": 18,
        "columnStart": 4,
        "columnEnd": 109
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# base image\nFROM openjdk:11\n\n# define spark and hadoop versions\nENV SPARK_VERSION=3.2.0\nENV HADOOP_VERSION=3.3.1\n\n# download and install hadoop\nRUN mkdir -p /opt && \\\n    cd /opt && \\\n    curl -f https://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz | \\\n        tar -zx hadoop-${HADOOP_VERSION}/lib/native && \\\n    ln -s hadoop-${HADOOP_VERSION} hadoop && \\\n    echo Hadoop ${HADOOP_VERSION} native libraries installed in /opt/hadoop/lib/native\n\n# download and install spark\nRUN mkdir -p /opt && \\\n    cd /opt && \\\n    curl -f https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop2.7.tgz | \\\n        tar -zx && \\\n    ln -s spark-${SPARK_VERSION}-bin-hadoop2.7 spark && \\\n    echo Spark ${SPARK_VERSION} installed in /opt\n\n# add scripts and update spark default config\nADD common.sh spark-master spark-worker /\nADD spark-defaults.conf /opt/spark/conf/spark-defaults.conf\nENV PATH $PATH:/opt/spark/bin\n\n# ABC"
}