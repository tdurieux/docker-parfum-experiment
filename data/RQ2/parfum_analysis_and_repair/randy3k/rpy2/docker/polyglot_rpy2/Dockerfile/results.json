{
  "startTime": 1674250887221,
  "endTime": 1674250887854,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 2,
        "columnEnd": 53
      }
    },
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 30,
        "lineEnd": 30,
        "columnStart": 2,
        "columnEnd": 130
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 15,
        "lineEnd": 25,
        "columnStart": 2,
        "columnEnd": 11
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM rpy2/jupyter:latest\n\nMAINTAINER Laurent Gautier <lgautier@gmail.com>\n\nARG CRAN_MIRROR=https://cran.revolutionanalytics.com/\nARG CRAN_MIRROR_TAG=-cran35\n\nUSER root\n\nARG LLVM_VERSION=6.0\n\nRUN \\\n  echo 'deb http://apt.llvm.org/'\"$(lsb_release -c -s)\"'/ llvm-toolchain-'\"$(lsb_release -c -s)\"'-6.0 main' >> /etc/apt/sources.list && \\\n  wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add - && \\\n  apt-get update -qq && \\\n  apt-get install --no-install-recommends -y \\\n                     clang-\"${LLVM_VERSION}\" \\\n\t\t\t\t\t\t\tlldb-\"${LLVM_VERSION}\" \\\n                     ed \\\n                     git \\\n\t\t\t\t\t\t\tlibcairo-dev \\\n\t\t\t\t\t\t\tlibcurl4-openssl-dev \\\n\t\t\t\t\t\t\tlibssl-dev \\\n\t\t\t\t\t\t\tlibedit-dev \\\n\t\t\t\t\t\t\tscala \\\n\t\t\t\t\t\t\twget && \\\n  rm -rf /var/lib/apt/lists/*\n\nARG SPARK_VERSION=2.4.0\nRUN \\\n  wget --progress=bar https://mirrors.ocf.berkeley.edu/apache/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop2.7.tgz && \\\n  tar -xzf spark-${SPARK_VERSION}-bin-hadoop2.7.tgz && \\\n  mv spark-${SPARK_VERSION}-bin-hadoop2.7 /opt/ && \\\n  rm spark-${SPARK_VERSION}-bin-hadoop2.7.tgz\n\nARG LLVMLITE_VERSION=0.24.0\nRUN \\\n  pip3 --no-cache-dir install wheel --upgrade && \\\n  pip3 --no-cache-dir install sqlalchemy && \\\n  rm -rf /root/.cache && \\\n  wget https://github.com/numba/llvmlite/archive/v${LLVMLITE_VERSION}.zip && \\\n  unzip v${LLVMLITE_VERSION}.zip && \\\n  cd llvmlite-${LLVMLITE_VERSION} && \\\n  LLVM_CONFIG=`which llvm-config-\"${LLVM_VERSION}\"` python3 setup.py install && \\\n  cd .. && rm -rf llvmlite-${LLVMLITE_VERSION} && rm v${LLVMLITE_VERSION}.zip && \\\n  pip3 --no-cache install numba && \\\n  pip3 --no-cache install findspark && \\\n  pip3 --no-cache install jupyter_dashboards && \\\n  jupyter dashboards quick-setup --sys-prefix && \\\n  rm -rf /root/.cache\n\nRUN \\\n  echo \"bigrquery\\n\\\n        glmnet\\n\\\n        gridExtra\\n\\\n        maps\\n\\\n        mapproj\\n\\\n        plotly\\n\\\n        RPostgreSQL\\n\\\n        party\\n\\\n        partykit\\n\\\n        svglite\" > rpacks.txt && \\\n  R -e 'install.packages(sub(\"(.+)\\\\\\\\n\",\"\\\\1\", scan(\"rpacks.txt\", \"character\")), repos=\"'\"${CRAN_MIRROR}\"'\")' && \\\n  rm rpacks.txt\n\nENV NB_USER jupyteruser\nENV SPARK_HOME /opt/spark-${SPARK_VERSION}-bin-hadoop2.7\n\nUSER $NB_USER\nRUN mkdir -p /home/$NB_USER/work\n\nWORKDIR /home/$NB_USER/work\n"
}