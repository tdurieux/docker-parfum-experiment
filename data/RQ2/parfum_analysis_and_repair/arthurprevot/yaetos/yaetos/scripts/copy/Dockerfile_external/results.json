{
  "startTime": 1674217822167,
  "endTime": 1674217822634,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 5,
        "lineEnd": 5,
        "columnStart": 4,
        "columnEnd": 41
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 7,
        "lineEnd": 7,
        "columnStart": 4,
        "columnEnd": 103
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 4,
        "lineEnd": 4,
        "columnStart": 22,
        "columnEnd": 44
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 4,
        "lineEnd": 4,
        "columnStart": 22,
        "columnEnd": 44
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM docker.io/bitnami/spark:3.1.2\nUSER root\n\n# Pip installs\nRUN apt-get update && apt-get install --no-install-recommends -y git && rm -rf /var/lib/apt/lists/*;\nRUN pip3 install --no-cache-dir --no-deps yaetos==0.9.23\n# Force latest version to avoid using previous ones.\nRUN pip3 install --no-cache-dir -r /opt/bitnami/python/lib/python3.6/site-packages/yaetos/scripts/requirements_alt.txt\n# TODO: check to put all yaetos requirements in package def to avoid having to call it separately.\n# Uncomment 2 lines below to install extra packages. Requires creating a requirements_extra.txt in conf/ file. Using local copy to tmp dir to allow checkpointing this step (no re-installs as long as requirements.txt doesn't change)\n# COPY conf/requirements_extra.txt /tmp/requirements_extra.txt\n# RUN pip3 install -r /tmp/requirements_extra.txt\n\n# Setup environment variables\nENV PYTHONPATH $SPARK_HOME/python:$SPARK_HOME/python/build:$PYTHONPATH\nENV YAETOS_JOBS_HOME /mnt/yaetos_jobs/\n\n# Expose ports for monitoring.\n# SparkContext web UI on 4040 -- only available for the duration of the application.\n# Spark masterâ€™s web UI on 8080.\n# Spark worker web UI on 8081.\n# Jupyter web UI on 8888.\nEXPOSE 4040 8080 8081 8888\n\n# CMD [\"/bin/bash\"] # commented so the command can be sent by docker run\n\n# Usage: docker run -it -p 4040:4040 -p 8080:8080 -p 8081:8081 -v ~/.aws:/root/.aws -h spark <image_id>\n# or update launch_env.sh and execute it.\n"
}