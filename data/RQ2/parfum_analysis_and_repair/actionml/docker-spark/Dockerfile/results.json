{
  "startTime": 1674250353705,
  "endTime": 1674250354629,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 28,
        "lineEnd": 29,
        "columnStart": 4,
        "columnEnd": 84
      }
    },
    {
      "rule": "gpgVerifyAscRmAsc",
      "position": {
        "lineStart": 31,
        "lineEnd": 31,
        "columnStart": 4,
        "columnEnd": 44
      }
    },
    {
      "rule": "gpgUseBatchFlag",
      "position": {
        "lineStart": 30,
        "lineEnd": 30,
        "columnStart": 4,
        "columnEnd": 79
      }
    },
    {
      "rule": "gpgUseHaPools",
      "position": {
        "lineStart": 30,
        "lineEnd": 30,
        "columnStart": 4,
        "columnEnd": 79
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM openjdk:8-alpine3.8\n## Spark standalone mode Dockerfile\n#\n\nARG version\nARG release\nARG GIT_HASH\nARG DATE_BUILD\nARG BRANCH\n\n\nLABEL com.actionml.spark.vendor=ActionML \\\n      com.actionml.spark.version=$version \\\n      com.actionml.spark.release=$release\n\nENV BRANCH=${BRANCH}\nENV GIT_HASH=${GIT_HASH}\nENV DATE_BUILD=${DATE_BUILD}\n\nENV SPARK_HOME=/spark \\\n    SPARK_PGP_KEYS=\"6EC5F1052DF08FF4 DCE4BFD807461E96\"\n\nRUN adduser -Ds /bin/bash -h ${SPARK_HOME} spark && \\\n    apk add --no-cache bash tini libc6-compat linux-pam krb5 krb5-libs && \\\n# download dist\n    apk add --virtual .deps --no-cache curl tar gnupg && \\\n    cd /tmp && export GNUPGHOME=/tmp && \\\n    file=spark-${version}-bin-hadoop2.7.tgz && \\\n    curl -f --remote-name-all -w \"%{url_effective} fetched\\n\" -sSL \\\n        https://archive.apache.org/dist/spark/spark-${version}/{${file},${file}.asc} && \\\n    gpg --batch --keyserver hkp://ha.pool.sks-keyservers.net --recv-keys ${SPARK_PGP_KEYS} && \\\n    gpg --batch --verify ${file}.asc ${file} && \\\n# create spark directories\n    mkdir -p ${SPARK_HOME}/work ${SPARK_HOME}/conf && chown spark:spark ${SPARK_HOME}/work && \\\n    tar -xzf ${file} --no-same-owner --strip-components 1 && \\\n    mv bin data examples jars sbin ${SPARK_HOME} && \\\n# cleanup\n    apk --no-cache del .deps && ls -A | xargs rm -rf && rm ${file}.asc\n\nCOPY entrypoint.sh /\nCOPY spark-env.sh ${SPARK_HOME}/conf/\n\nWORKDIR ${SPARK_HOME}/work\nENTRYPOINT [ \"/entrypoint.sh\" ]\n\n# Specify the User that the actual main process will run as\nUSER spark:spark\n"
}