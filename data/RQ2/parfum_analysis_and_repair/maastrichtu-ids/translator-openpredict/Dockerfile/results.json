{
  "startTime": 1674219364105,
  "endTime": 1674219364834,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 36,
        "lineEnd": 36,
        "columnStart": 4,
        "columnEnd": 35
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 67
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 67
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.8\n## Gunicorn image 3.39GB: https://github.com/tiangolo/uvicorn-gunicorn-docker/tree/master/docker-images\n\n# FROM jupyter/pyspark-notebook:python-3.8.8\n## Jupyter with Spark already installed 4.31GB\n\nLABEL org.opencontainers.image.source=\"https://github.com/MaastrichtU-IDS/translator-openpredict\"\n\n## Change the current user to root and the working directory to /app\nUSER root\nWORKDIR /app\n\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y build-essential curl vim openjdk-11-jdk wget && rm -rf /var/lib/apt/lists/*;\n\n## Install Spark for standalone context in /opt\nENV APACHE_SPARK_VERSION=3.2.0\nENV HADOOP_VERSION=3.2\nENV SPARK_HOME=/opt/spark\nENV SPARK_OPTS=\"--driver-java-options=-Xms1024M --driver-java-options=-Xmx2048M --driver-java-options=-Dlog4j.logLevel=info\"\nENV PATH=\"${PATH}:${SPARK_HOME}/bin\"\nRUN wget -q -O spark.tgz https://archive.apache.org/dist/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz && \\\n    tar xzf spark.tgz -C /opt && \\\n    rm \"spark.tgz\" && \\\n    ln -s \"/opt/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}\" $SPARK_HOME\n\n\n## Define some environment variables\nENV OPENPREDICT_DATA_DIR=/data/openpredict\nENV PYSPARK_PYTHON=/usr/local/bin/python3\nENV PYSPARK_DRIVER_PYTHON=/usr/local/bin/python3\n# ENV PYSPARK_PYTHON=/opt/conda/bin/python3\n# ENV PYSPARK_DRIVER_PYTHON=/opt/conda/bin/python3\n\n# Avoid to reinstall packages when no changes to requirements\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nARG INSTALL_DEV=false\nCOPY requirements-dev.txt .\nRUN bash -c \"if [ $INSTALL_DEV == 'true' ] ; then pip install -r requirements-dev.txt ; fi\"\n\n## Copy the source code (in the same folder as the Dockerfile)\nCOPY . .\n\n## Gunicorn config\nENV MODULE_NAME=openpredict.main\nENV VARIABLE_NAME=app\nENV PORT=8808\n\n## Install the pip package based on the source code\n\nRUN bash -c \"if [ $INSTALL_DEV == 'true' ] ; then pip install -e . ; else pip install . ; fi\"\n\nEXPOSE 8808\n\n# ENTRYPOINT [\"uvicorn\", \"openpredict.main:app\",  \"--host\", \"0.0.0.0\", \"--port\", \"8808\"]\n# ENTRYPOINT [ \"gunicorn\", \"-w\", \"8\", \"-k\", \"uvicorn.workers.UvicornWorker\", \"--bind\", \"0.0.0.0:8808\", \"openpredict.main:app\"]\n# ENTRYPOINT [ \"openpredict\", \"start-api\" ]\n"
}