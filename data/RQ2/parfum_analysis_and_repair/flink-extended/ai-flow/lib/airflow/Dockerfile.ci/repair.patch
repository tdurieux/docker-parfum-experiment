diff --git a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/flink-extended/ai-flow/lib/airflow/Dockerfile.ci b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/flink-extended/ai-flow/lib/airflow/Dockerfile.ci/repaired.Dockerfile
index f998a74..a2a55c2 100644
--- a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/flink-extended/ai-flow/lib/airflow/Dockerfile.ci
+++ b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/flink-extended/ai-flow/lib/airflow/Dockerfile.ci/repaired.Dockerfile
@@ -170,8 +170,8 @@ RUN mkdir -pv /usr/share/man/man1 \
 ARG DOCKER_CLI_VERSION=19.03.9
 ENV DOCKER_CLI_VERSION=${DOCKER_CLI_VERSION}
 
-RUN curl https://download.docker.com/linux/static/stable/x86_64/docker-${DOCKER_CLI_VERSION}.tgz \
-    |  tar -C /usr/bin --strip-components=1 -xvzf - docker/docker
+RUN curl -f https://download.docker.com/linux/static/stable/x86_64/docker-${DOCKER_CLI_VERSION}.tgz \
+    | tar -C /usr/bin --strip-components=1 -xvzf - docker/docker
 
 # Setup PIP
 # By default PIP install run without cache to make image smaller
@@ -204,21 +204,21 @@ ARG BATS_SUPPORT_VERSION="0.3.0"
 ARG BATS_ASSERT_VERSION="2.0.0"
 ARG BATS_FILE_VERSION="0.2.0"
 
-RUN curl -sSL https://github.com/bats-core/bats-core/archive/v${BATS_VERSION}.tar.gz -o /tmp/bats.tgz \
+RUN curl -f -sSL https://github.com/bats-core/bats-core/archive/v${BATS_VERSION}.tar.gz -o /tmp/bats.tgz \
     && tar -zxf /tmp/bats.tgz -C /tmp \
-    && /bin/bash /tmp/bats-core-${BATS_VERSION}/install.sh /opt/bats && rm -rf
+    && /bin/bash /tmp/bats-core-${BATS_VERSION}/install.sh /opt/bats && rm -rf && rm /tmp/bats.tgz
 
 RUN mkdir -p /opt/bats/lib/bats-support \
-    && curl -sSL https://github.com/bats-core/bats-support/archive/v${BATS_SUPPORT_VERSION}.tar.gz -o /tmp/bats-support.tgz \
-    && tar -zxf /tmp/bats-support.tgz -C /opt/bats/lib/bats-support --strip 1 && rm -rf /tmp/*
+    && curl -f -sSL https://github.com/bats-core/bats-support/archive/v${BATS_SUPPORT_VERSION}.tar.gz -o /tmp/bats-support.tgz \
+    && tar -zxf /tmp/bats-support.tgz -C /opt/bats/lib/bats-support --strip 1 && rm -rf /tmp/* && rm /tmp/bats-support.tgz
 
 RUN mkdir -p /opt/bats/lib/bats-assert \
-    && curl -sSL https://github.com/bats-core/bats-assert/archive/v${BATS_ASSERT_VERSION}.tar.gz -o /tmp/bats-assert.tgz \
-    && tar -zxf /tmp/bats-assert.tgz -C /opt/bats/lib/bats-assert --strip 1 && rm -rf /tmp/*
+    && curl -f -sSL https://github.com/bats-core/bats-assert/archive/v${BATS_ASSERT_VERSION}.tar.gz -o /tmp/bats-assert.tgz \
+    && tar -zxf /tmp/bats-assert.tgz -C /opt/bats/lib/bats-assert --strip 1 && rm -rf /tmp/* && rm /tmp/bats-assert.tgz
 
 RUN mkdir -p /opt/bats/lib/bats-file \
-    && curl -sSL https://github.com/bats-core/bats-file/archive/v${BATS_FILE_VERSION}.tar.gz -o /tmp/bats-file.tgz \
-    && tar -zxf /tmp/bats-file.tgz -C /opt/bats/lib/bats-file --strip 1 && rm -rf /tmp/*
+    && curl -f -sSL https://github.com/bats-core/bats-file/archive/v${BATS_FILE_VERSION}.tar.gz -o /tmp/bats-file.tgz \
+    && tar -zxf /tmp/bats-file.tgz -C /opt/bats/lib/bats-file --strip 1 && rm -rf /tmp/* && rm /tmp/bats-file.tgz
 
 RUN echo "export PATH=/opt/bats/bin:${PATH}" >> /root/.bashrc
 
@@ -271,14 +271,14 @@ ENV INSTALL_FROM_DOCKER_CONTEXT_FILES=${INSTALL_FROM_DOCKER_CONTEXT_FILES}
 ARG INSTALL_FROM_PYPI="true"
 ENV INSTALL_FROM_PYPI=${INSTALL_FROM_PYPI}
 
-RUN pip install --upgrade "pip==${PIP_VERSION}"
+RUN pip install --no-cache-dir --upgrade "pip==${PIP_VERSION}"
 
 # In case of CI builds we want to pre-install master version of airflow dependencies so that
 # We do not have to always reinstall it from the scratch.
 # This can be reinstalled from latest master by increasing PIP_DEPENDENCIES_EPOCH_NUMBER.
 # And is automatically reinstalled from the scratch every time patch release of python gets released
 RUN if [[ ${AIRFLOW_PRE_CACHED_PIP_PACKAGES} == "true" ]]; then \
-        pip install \
+        pip install --no-cache-dir \
             "https://github.com/${AIRFLOW_REPO}/archive/${AIRFLOW_BRANCH}.tar.gz#egg=apache-airflow[${AIRFLOW_EXTRAS}]" \
                 --constraint "${AIRFLOW_CONSTRAINTS_LOCATION}" \
                 && pip uninstall --yes apache-airflow; \
@@ -297,7 +297,7 @@ RUN ln -sf /usr/bin/dumb-init /usr/local/bin/dumb-init
 # Rather than after setup.py is added.
 COPY airflow/www/yarn.lock airflow/www/package.json ${AIRFLOW_SOURCES}/airflow/www/
 
-RUN yarn --cwd airflow/www install --frozen-lockfile --no-cache
+RUN yarn --cwd airflow/www install --frozen-lockfile --no-cache && yarn cache clean;
 
 # Note! We are copying everything with airflow:airflow user:group even if we use root to run the scripts
 # This is fine as root user will be able to use those dirs anyway.
@@ -321,10 +321,12 @@ ENV UPGRADE_TO_LATEST_CONSTRAINTS=${UPGRADE_TO_LATEST_CONSTRAINTS}
 # and push the constraints if everything is successful
 RUN if [[ ${INSTALL_FROM_PYPI} == "true" ]]; then \
         if [[ "${UPGRADE_TO_LATEST_CONSTRAINTS}" != "false" ]]; then \
-            pip install -e ".[${AIRFLOW_EXTRAS}]" --upgrade --upgrade-strategy eager; \
+            pip install --no-cache-dir -e ".[${AIRFLOW_EXTRAS}]" --upgrade --upgrade-strategy eager; \
         else \
-            pip install -e ".[${AIRFLOW_EXTRAS}]" --upgrade --upgrade-strategy only-if-needed; \
-        fi; \
+            pip install --no-cache-dir -e ".[${AIRFLOW_EXTRAS}]" --upgrade --upgrade-strategy only-if-needed; \
+        fi; else \
+            pip install --no-cache-dir -e ".[${AIRFLOW_EXTRAS}]" --upgrade --upgrade-strategy only-if-needed; \
+        fi \
     fi
 
 # If wheel files are found in /docker-context-files during installation
@@ -333,8 +335,8 @@ COPY docker-context-files/ /docker-context-files/
 
 RUN if [[ ${INSTALL_FROM_DOCKER_CONTEXT_FILES} != "true" ]]; then \
         if ls /docker-context-files/*.{whl,tar.gz} 1> /dev/null 2>&1; then \
-            pip install --no-deps /docker-context-files/*.{whl,tar.gz}; \
-        fi ; \
+            pip install --no-cache-dir --no-deps /docker-context-files/*.{whl,tar.gz}; \
+        fi; \
     fi
 
 # Copy all the www/ files we need to compile assets. Done as two separate COPY
@@ -369,14 +371,14 @@ ARG HELM_VERSION="v3.2.4"
 
 RUN SYSTEM=$(uname -s | tr '[:upper:]' '[:lower:]') \
     && HELM_URL="https://get.helm.sh/helm-${HELM_VERSION}-${SYSTEM}-amd64.tar.gz" \
-    && curl --location "${HELM_URL}" | tar -xvz -O "${SYSTEM}"-amd64/helm > /usr/local/bin/helm \
+    && curl -f --location "${HELM_URL}" | tar -xvz -O "${SYSTEM}"-amd64/helm > /usr/local/bin/helm \
     && chmod +x /usr/local/bin/helm
 
 # Additional python deps to install
 ARG ADDITIONAL_PYTHON_DEPS=""
 
 RUN if [[ -n "${ADDITIONAL_PYTHON_DEPS}" ]]; then \
-        pip install ${ADDITIONAL_PYTHON_DEPS}; \
+        pip install --no-cache-dir ${ADDITIONAL_PYTHON_DEPS}; \
     fi
 
 WORKDIR ${AIRFLOW_SOURCES}