{
  "startTime": 1674255261374,
  "endTime": 1674255262060,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 9,
        "lineEnd": 9,
        "columnStart": 4,
        "columnEnd": 80
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 25,
        "lineEnd": 25,
        "columnStart": 4,
        "columnEnd": 99
      }
    },
    {
      "rule": "curlUseHttpsUrl",
      "position": {
        "lineStart": 9,
        "lineEnd": 9,
        "columnStart": 4,
        "columnEnd": 80
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 3,
        "lineEnd": 3,
        "columnStart": 4,
        "columnEnd": 40
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 4,
        "columnEnd": 67
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM ubuntu:trusty\n\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y -q curl bzip2 git && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Install CDH5 in a single node: Pseudo Distributed\n# Docs: http://www.cloudera.com/content/www/en-us/documentation/enterprise/latest/topics/cdh_qs_yarn_pseudo.html\nADD docker-files/cloudera.pref /etc/apt/preferences.d/cloudera.pref\nRUN curl -f -s https://archive.cloudera.com/cdh5/ubuntu/trusty/amd64/cdh/archive.key | apt-key add - && \\\n    echo 'deb [arch=amd64] http://archive.cloudera.com/cdh5/ubuntu/trusty/amd64/cdh trusty-cdh5 contrib' > /etc/apt/sources.list.d/cloudera.list && \\\n    echo 'deb-src http://archive.cloudera.com/cdh5/ubuntu/trusty/amd64/cdh trusty-cdh5 contrib' >> /etc/apt/sources.list.d/cloudera.list && \\\n    apt-get update && \\\n    apt-get install --no-install-recommends -y -q openjdk-7-jre-headless hadoop-conf-pseudo && \\\n    sudo -u hdfs hdfs namenode -format -force && \\\n    for x in `cd /etc/init.d ; ls hadoop-hdfs-*` ; do sudo service $x start ; done && \\\n    bash /usr/lib/hadoop/libexec/init-hdfs.sh && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Needed for hdfs3\nENV LIBHDFS3_CONF /etc/hadoop/conf/hdfs-site.xml\n\n# Install conda & build conda environments:\n# py35 is root environment\n# py27 gets own environment\nRUN curl -f https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -o /tmp/miniconda.sh && \\\n    /bin/bash /tmp/miniconda.sh -b -p /opt/conda && \\\n    rm /tmp/miniconda.sh && \\\n    /opt/conda/bin/conda install -y -q libhdfs3 pytest flake8 -c conda-forge && \\\n    /opt/conda/bin/conda create -y -n py27 python=2.7 && \\\n    /opt/conda/bin/conda install -y -q -n py27 libhdfs3 pytest -c conda-forge\n\nENV PATH /opt/conda/bin:$PATH\n\nEXPOSE 8020 50070\n\nVOLUME /hdfs3\nWORKDIR /hdfs3\n\nADD docker-files/start.sh /tmp/start.sh\nCMD [\"bash\", \"/tmp/start.sh\", \"-d\"]\n"
}