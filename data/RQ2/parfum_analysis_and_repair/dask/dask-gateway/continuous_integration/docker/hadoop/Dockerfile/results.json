{
  "startTime": 1674252366181,
  "endTime": 1674252367027,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 50,
        "lineEnd": 50,
        "columnStart": 4,
        "columnEnd": 117
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# See continuous_integration/docker/README.md for details about this and other\n# Dockerfiles under the continuous_integration/docker folder on their purpose\n# and how to work with them.\n#\nFROM ghcr.io/dask/dask-gateway-ci-base:latest\n\n# Set labels based on the Open Containers Initiative (OCI):\n# https://github.com/opencontainers/image-spec/blob/main/annotations.md#pre-defined-annotation-keys\n#\nLABEL org.opencontainers.image.url=\"https://github.com/dask/dask-gateway/blob/HEAD/continuous_integration/docker/hadoop/Dockerfile\"\n\n# Notify dask-gateway tests that Yarn (part of Hadoop) is available\nENV TEST_DASK_GATEWAY_YARN true\n\n\n\n# Install hadoop\n#\n# 1. Create hadoop users and groups.\n#\nRUN groupadd --system hadoop \\\n && useradd yarn --system --no-create-home --groups=hadoop \\\n && useradd hdfs --system --no-create-home --groups=hadoop \\\n && useradd mapred --system --no-create-home --groups=hadoop\n#\n# 2. Install hadoop v3 dependencies\n#\n# - Java 8+ (java-1.8.0-openjdk, java-11-openjdk)\n#\n# - OpenSSL 1.1 (openssl 1.0 comes with centos:7, found via epel-release repo)\n#\nRUN yum install -y \\\n        epel-release \\\n && yum install -y \\\n        java-1.8.0-openjdk \\\n        openssl11-libs \\\n && yum clean all \\\n && rm -rf /var/cache/yum\nENV JAVA_HOME /usr/lib/jvm/jre-openjdk\n#\n# 3. Download and unpack hadoop\n#\n#    hadoop versions:  https://dlcdn.apache.org/hadoop/common/\n#    hadoop changelog: https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/release/\n#\n#    We set the owner user:group to root:hadoop and declare the setuid and\n#    setgid bits for this directory so that folders created in it become owned\n#    by root:hadoop as well.\n#\nRUN INSTALL_HADOOP_VERSION=3.3.2 \\\n && curl -f -sL /tmp/hadoop.tar.gz https://dlcdn.apache.org/hadoop/common/stable/hadoop-${INSTALL_HADOOP_VERSION}.tar.gz \\\n  | tar -xvz --directory /opt \\\n && mv /opt/hadoop-* /opt/hadoop \\\n && chown -R root:hadoop /opt/hadoop \\\n && chmod ug+s /opt/hadoop\n#\n# 4. Configure HADOOP_ environment variables\n#\n#   - HADOOP_CONF_DIR, HADOOP_COMMON_HOME, HADOOP_HDFS_HOME, and\n#     HADOOP_YARN_HOME are referenced by `skein` who loads a default hadoop\n#     classpath refenrecing these variables in the same way we have declared\n#     them in yarn-site.yaml container-executor.cfg.\n#\nENV HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop \\\n    HADOOP_COMMON_HOME=/opt/hadoop \\\n    HADOOP_HDFS_HOME=/opt/hadoop \\\n    HADOOP_YARN_HOME=/opt/hadoop\n#\n# 5. Update PATH environment variable\n#\n#    Note that this PATH environment will be preserved when sudo is used to\n#    switch to other users thanks to changes to /etc/sudoers.d/preserve_path,\n#    which is configured in the base Dockerfile.\n#\nENV PATH=/opt/hadoop/sbin:/opt/hadoop/bin:$PATH\n#\n# 6. Copy our hadoop configurations\n#\n#    The permissions are important for function! As we copy additional files to\n#    these folders later and want them to have root:hadoop ownership for\n#    readability, we \"chmod ug+s\" as well on the folder.\n#\nCOPY --chown=root:hadoop ./files/etc/hadoop /etc/hadoop/\nRUN chmod -R ug+s /etc/hadoop/\n#\n# 7. Copy our setup script and run it\n#\nCOPY ./files/scripts/setup-hadoop.sh /scripts/\nCOPY ./files/scripts/init-hdfs.sh /scripts/\nRUN /scripts/setup-hadoop.sh\n\n\n\n# Install kerberos\n#\n# 1. Install yum packages\n#\nRUN yum install -y \\\n        krb5-libs \\\n        krb5-server \\\n        krb5-workstation \\\n && yum clean all \\\n && rm -rf /var/cache/yum\n#\n# 2. Copy our kerberos configuration\n#\nCOPY ./files/etc/krb5.conf /etc/\nCOPY ./files/var/kerberos/krb5kdc /var/kerberos/krb5kdc/\n#\n# 3. Copy our setup script and run it\n#\nCOPY ./files/scripts/setup-kerb.sh /scripts/\nRUN /scripts/setup-kerb.sh\n\n\n\n# Install supervisor\n#\n# - supervisord will be the entrypoint of the container, configured to start\n#   multiple services via provided files.\n# - /etc/supervisor.conf declares that /etc/supervisor.d/* should be included\n#   among other things.\n# - /etc/supervisor.d/* declares a few supervisor programs, running the\n#   following commands as specified user:\n#\n#   COMMAND              | USER | LOGFILE\n#   -------------------- | ---- | -----------------------------------------------------\n#   hdfs datanode        | hdfs | /var/log/supervisor/hdfs-datanode.log\n#   hdfs namenode        | hdfs | /var/log/supervisor/hdfs-namenode.log\n#   krb5kdc              | root | /var/log/supervisor/krb5kdc.log\n#   kadmind              | root | /var/log/supervisor/kadmind.log\n#   yarn nodemanager     | yarn | /var/log/supervisor/yarn-nodemanager.log\n#   yarn resourcemanager | yarn | /var/log/supervisor/yarn-resourcemanager.log\n#\n# 1. Install supervisor (which requires already installed epel-release).\n#\nRUN yum install -y \\\n        supervisor \\\n && yum clean all \\\n && rm -rf /var/cache/yum\n#\n# 2. Initialize logfiles as required\n#\nRUN touch \\\n        /var/log/supervisor/kadmind.log \\\n        /var/log/supervisor/krb5kdc.log \\\n        /var/log/supervisor/krb5libs.log\n#\n# 3. Copy files used by supervisor\n#\nCOPY ./files/etc/supervisord.d /etc/supervisord.d/\nCOPY ./files/etc/supervisord.conf /etc/\n#\n# 4. Configure the container to start supervisord with our configuration.\n#\nENTRYPOINT [\"/usr/bin/supervisord\", \"--configuration\", \"/etc/supervisord.conf\"]\n"
}