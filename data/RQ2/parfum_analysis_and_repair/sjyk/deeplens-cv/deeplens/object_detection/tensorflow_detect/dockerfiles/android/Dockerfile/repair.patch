diff --git a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/sjyk/deeplens-cv/deeplens/object_detection/tensorflow_detect/dockerfiles/android/Dockerfile b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/sjyk/deeplens-cv/deeplens/object_detection/tensorflow_detect/dockerfiles/android/Dockerfile/repaired.Dockerfile
index cb5e0ba..ff475d4 100644
--- a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/sjyk/deeplens-cv/deeplens/object_detection/tensorflow_detect/dockerfiles/android/Dockerfile
+++ b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/sjyk/deeplens-cv/deeplens/object_detection/tensorflow_detect/dockerfiles/android/Dockerfile/repaired.Dockerfile
@@ -25,19 +25,19 @@ RUN git clone --depth 1 https://github.com/tensorflow/models.git && \
 # https://cloud.google.com/sdk/docs/quickstart-debian-ubuntu
 RUN export CLOUD_SDK_REPO="cloud-sdk-$(lsb_release -c -s)" && \
     echo "deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && \
-    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - && \
-    apt-get update -y && apt-get install google-cloud-sdk -y
+    curl -f https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - && \
+    apt-get update -y && apt-get install --no-install-recommends google-cloud-sdk -y && rm -rf /var/lib/apt/lists/*;
 
 
 # Install the Tensorflow Object Detection API from here
 # https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md
 
 # Install object detection api dependencies
-RUN apt-get install -y protobuf-compiler python-pil python-lxml python-tk && \
-    pip install Cython && \
-    pip install contextlib2 && \
-    pip install jupyter && \
-    pip install matplotlib
+RUN apt-get install --no-install-recommends -y protobuf-compiler python-pil python-lxml python-tk && \
+    pip install --no-cache-dir Cython && \
+    pip install --no-cache-dir contextlib2 && \
+    pip install --no-cache-dir jupyter && \
+    pip install --no-cache-dir matplotlib && rm -rf /var/lib/apt/lists/*;
 
 # Install pycocoapi
 RUN git clone --depth 1 https://github.com/cocodataset/cocoapi.git && \
@@ -48,7 +48,7 @@ RUN git clone --depth 1 https://github.com/cocodataset/cocoapi.git && \
     rm -rf cocoapi
 
 # Get protoc 3.0.0, rather than the old version already in the container
-RUN curl -OL "https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip" && \
+RUN curl -f -OL "https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip" && \
     unzip protoc-3.0.0-linux-x86_64.zip -d proto3 && \
     mv proto3/bin/* /usr/local/bin && \
     mv proto3/include/* /usr/local/include && \
@@ -64,7 +64,7 @@ ENV PYTHONPATH $PYTHONPATH:/tensorflow/models/research:/tensorflow/models/resear
 
 # Install wget (to make life easier below) and editors (to allow people to edit
 # the files inside the container)
-RUN apt-get install -y wget vim emacs nano
+RUN apt-get install --no-install-recommends -y wget vim emacs nano && rm -rf /var/lib/apt/lists/*;
 
 
 # Grab various data files which are used throughout the demo: dataset,
@@ -74,19 +74,19 @@ RUN apt-get install -y wget vim emacs nano
 # Pets example dataset
 RUN mkdir -p /tmp/pet_faces_tfrecord/ && \
     cd /tmp/pet_faces_tfrecord && \
-    curl "http://download.tensorflow.org/models/object_detection/pet_faces_tfrecord.tar.gz" | tar xzf -
+    curl -f "https://download.tensorflow.org/models/object_detection/pet_faces_tfrecord.tar.gz" | tar xzf -
 
 # Pretrained model
 # This one doesn't need its own directory, since it comes in a folder.
 RUN cd /tmp && \
-    curl -O "http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync_2018_07_03.tar.gz" && \
+    curl -f -O "http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync_2018_07_03.tar.gz" && \
     tar xzf ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync_2018_07_03.tar.gz && \
     rm ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync_2018_07_03.tar.gz
 
 # Trained TensorFlow Lite model. This should get replaced by one generated from
 # export_tflite_ssd_graph.py when that command is called.
 RUN cd /tmp && \
-    curl -L -o tflite.zip \
+    curl -f -L -o tflite.zip \
     https://storage.googleapis.com/download.tensorflow.org/models/tflite/frozengraphs_ssd_mobilenet_v1_0.75_quant_pets_2018_06_29.zip && \
     unzip tflite.zip -d tflite && \
     rm tflite.zip
@@ -104,7 +104,7 @@ ENV PATH ${PATH}:${ANDROID_HOME}/tools:${ANDROID_HOME}/tools/bin:${ANDROID_HOME}
 
 # Install SDK tools
 RUN cd /opt && \
-    curl -OL https://dl.google.com/android/repository/sdk-tools-linux-4333796.zip && \
+    curl -f -OL https://dl.google.com/android/repository/sdk-tools-linux-4333796.zip && \
     unzip sdk-tools-linux-4333796.zip -d ${ANDROID_HOME} && \
     rm sdk-tools-linux-4333796.zip
 
@@ -124,13 +124,13 @@ RUN yes | sdkmanager \
 
 # Install Android NDK (r14b)
 RUN cd /opt && \
-    curl -L -o android-ndk.zip http://dl.google.com/android/repository/android-ndk-r14b-linux-x86_64.zip && \
+    curl -f -L -o android-ndk.zip https://dl.google.com/android/repository/android-ndk-r14b-linux-x86_64.zip && \
     unzip -q android-ndk.zip && \
     rm -f android-ndk.zip
 
 # Configure the build to use the things we just downloaded
 RUN cd /tensorflow && \
-    printf '\n\nn\ny\nn\nn\nn\ny\nn\nn\nn\nn\nn\nn\n\ny\n%s\n\n\n' ${ANDROID_HOME}|./configure
+    printf '\n\nn\ny\nn\nn\nn\ny\nn\nn\nn\nn\nn\nn\n\ny\n%s\n\n\n' ${ANDROID_HOME} | ./configure --build="$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)"
 
 
 WORKDIR /tensorflow