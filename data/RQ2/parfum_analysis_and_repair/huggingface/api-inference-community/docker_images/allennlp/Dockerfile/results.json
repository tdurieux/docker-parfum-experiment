{
  "startTime": 1674248111748,
  "endTime": 1674248112525,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 9,
        "lineEnd": 9,
        "columnStart": 4,
        "columnEnd": 21
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM tiangolo/uvicorn-gunicorn:python3.8\nLABEL maintainer=\"me <me@example.com>\"\n\n# Add any system dependency here\n# RUN apt-get update -y && apt-get install libXXX -y\n\nCOPY ./requirements.txt /app\nRUN pip install --no-cache-dir -r requirements.txt\n\nRUN pip install --no-cache-dir spacy && python -m spacy download en_core_web_sm\nCOPY ./prestart.sh /app/\n\n\n# Most DL models are quite large in terms of memory, using workers is a HUGE\n# slowdown because of the fork and GIL with python.\n# Using multiple pods seems like a better default strategy.\n# Feel free to override if it does not make sense for your library.\nARG max_workers=1\nENV MAX_WORKERS=$max_workers\nENV ALLENNLP_CACHE_ROOT=/data\nENV NLTK_DATA=/data\nENV HOME=/data\n\n# Necessary on GPU environment docker.\n# TIMEOUT env variable is used by nvcr.io/nvidia/pytorch:xx for another purpose\n# rendering TIMEOUT defined by uvicorn impossible to use correctly\n# We're overriding it to be renamed UVICORN_TIMEOUT\n# UVICORN_TIMEOUT is a useful variable for very large models that take more\n# than 30s (the default) to load in memory.\n# If UVICORN_TIMEOUT is too low, uvicorn will simply never loads as it will\n# kill workers all the time before they finish.\nRUN sed -i 's/TIMEOUT/UVICORN_TIMEOUT/g' /gunicorn_conf.py\nCOPY ./app /app/app\n"
}