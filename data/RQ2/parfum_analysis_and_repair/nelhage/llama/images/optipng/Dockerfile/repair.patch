diff --git a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/nelhage/llama/images/optipng/Dockerfile b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/nelhage/llama/images/optipng/Dockerfile/repaired.Dockerfile
index aabfba8..ef10376 100644
--- a/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfiles/nelhage/llama/images/optipng/Dockerfile
+++ b/Users/tdurieux/git/dinghy-experiment/data/evaluation/dockerfile_repair_results/nelhage/llama/images/optipng/Dockerfile/repaired.Dockerfile
@@ -18,8 +18,8 @@ ENTRYPOINT ["/llama_runtime"]
 # Install the packages we need. It's important that we also grab
 # `ca-certificates` so the Llama can find a CA store to talk to S3.
 RUN apt-get update && \
-        apt-get -y install optipng ca-certificates && \
-        apt-get clean
+        apt-get -y --no-install-recommends install optipng ca-certificates && \
+        apt-get clean && rm -rf /var/lib/apt/lists/*;
 
 # If we specify a CMD, llama will respect it, in a very similar manner
 # to `docker run`; without the CMD, any command-line to `llama invoke`