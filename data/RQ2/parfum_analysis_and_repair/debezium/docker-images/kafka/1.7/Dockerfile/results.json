{
  "startTime": 1674252376408,
  "endTime": 1674252377774,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 39,
        "lineEnd": 39,
        "columnStart": 34,
        "columnEnd": 107
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM debezium/base\n\nLABEL maintainer=\"Debezium Community\"\n\n#\n# Set the version, home directory, and MD5 hash.\n# MD5 hash taken from http://kafka.apache.org/downloads.html for this version of Kafka\n# These argument defaults can be overruled during build time but compatibility cannot be guaranteed when the defaults are not used.\n#\nARG KAFKA_VERSION=2.8.1\nARG SCALA_VERSION=2.12\nARG SHA512HASH=\"287CF3B43CC723E9A2DACC83E153152A74CF9C39D86EB0702CC8D237BE95577098E0B984687F3F7EA37BB2782F7DF23DD597FD618AF03A48460E6B3F4931B6C2\"\n\nENV KAFKA_VERSION=$KAFKA_VERSION \\\n    SCALA_VERSION=$SCALA_VERSION \\\n    KAFKA_HOME=/kafka \\\n    SHA512HASH=$SHA512HASH \\\n    KAFKA_URL_PATH=kafka/$KAFKA_VERSION/kafka_$SCALA_VERSION-$KAFKA_VERSION.tgz\n\nENV KAFKA_DATA=$KAFKA_HOME/data\n\n#\n# Create a user and home directory for Kafka\n#\nUSER root\nRUN groupadd -r kafka -g 1001 && useradd -u 1001 -r -g kafka -m -d $KAFKA_HOME -s /sbin/nologin -c \"Kafka user\" kafka && \\\n    chmod 755 $KAFKA_HOME\nRUN mkdir $KAFKA_DATA && \\\n    mkdir $KAFKA_HOME/logs\n\n#\n# Change ownership and switch user\n#\nRUN chown -R kafka $KAFKA_HOME && \\\n    chgrp -R kafka $KAFKA_HOME\n\n#\n# Download Kafka\n#\nRUN curl -fSL -o /tmp/kafka.tgz $( curl -f --stderr /dev/null https://www.apache.org/dyn/closer.cgi\\?as_json\\=1 | sed -rn 's/.*\"preferred\":.*\"(.*)\"/\\1/p')$KAFKA_URL_PATH || curl -fSL -o /tmp/kafka.tgz https://archive.apache.org/dist/$KAFKA_URL_PATH\n\n#\n# Verify the contents and then install ...\n#\nRUN echo \"$SHA512HASH /tmp/kafka.tgz\" | sha512sum -c - &&\\\n    tar -xzf /tmp/kafka.tgz -C $KAFKA_HOME --strip-components 1 &&\\\n    rm -f /tmp/kafka.tgz\n\n#\n# CVE-2021-4104/DBZ-4447 CVE-2019-17571 Remove potentially exploitable classes\n#\nRUN zip -d /kafka/libs/log4j-1.2.17.jar org/apache/log4j/net/JMSAppender.class org/apache/log4j/net/SocketServer.class\n\nCOPY ./log4j.properties $KAFKA_HOME/config/log4j.properties\nRUN mkdir $KAFKA_HOME/config.orig &&\\\n    mv $KAFKA_HOME/config/* $KAFKA_HOME/config.orig &&\\\n    chown -R kafka:kafka $KAFKA_HOME/config.orig\n\n# Remove unnecessary files\nRUN rm -f $KAFKA_HOME/libs/*-{sources,javadoc,scaladoc}.jar* &&\\\n    rm -r $KAFKA_HOME/site-docs\n\n#\n# The kafka-run-class.sh script generates the classpath for launching Kafka-related JVM, with entries\n# containing the pattern \"/bin/../libs\", which fails to be resolved properly in some\n# environments; the CLASSPATH is filled from \"base_dir\" environment variable that contains the relative\n# path so it it is modified to contain absolute path using \"realpath\" command.\n#\nRUN sed -i 's/base_dir=\\$(dirname \\$0)\\/../base_dir=\\$(realpath \\$(dirname \\$0)\\/..)/' $KAFKA_HOME/bin/kafka-run-class.sh\n\n#\n# Allow random UID to use Kafka\n#\nRUN chmod -R g+w,o+w $KAFKA_HOME\n\nUSER kafka\n\n# Set the working directory to the Kafka home directory\nWORKDIR $KAFKA_HOME\n\n#\n# Expose the ports and set up volumes for the data and logs directories\n#\nEXPOSE 9092\nVOLUME [\"/kafka/data\",\"/kafka/logs\",\"/kafka/config\"]\n\nCOPY ./docker-entrypoint.sh /\nENTRYPOINT [\"/docker-entrypoint.sh\"]\nCMD [\"start\"]\n"
}