{
  "startTime": 1674252309092,
  "endTime": 1674252309892,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 56,
        "lineEnd": 56,
        "columnStart": 4,
        "columnEnd": 32
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# ---------- 1st stage ----------\n# The first stage adds the necessary libraries to build native add-ons (eg. bcrypt) and then installs\n# the server dependencies\nFROM node:16-alpine as builder\n\n# By default, `alpine` images don't have necessary tools to install native add-ons, so we use the\n# multistage build to install the necessary tools, and build the dependencies which will then be\n# copied over to the next stage (this stage will be discarded, along with the installed tools, to\n# make the image lighter).\nRUN apk add --no-cache python3 make g++ git\n\n# Ensure that we don't spend time installing dependencies that are only needed for the client\n# application.\nENV SB_SERVER_ONLY=1\n\n# Set the working directory to where we want to install the dependencies; this directory doesn't\n# really matter as it will not be present in the final image, but keeping the path short makes\n# copying from it easier in the next stage.\nWORKDIR /shieldbattery\n\n# Copy the whole repository to the image, *except* the stuff marked in the `.dockerignore` file\nCOPY . .\n\n# Install only the root folder's dependencies (`app` dependencies should be built into the\n# Electron app). Note that we specifically install non-production dependencies here so that we can\n# use them to build the client code. They will be pruned out in a later step.\nRUN yarn\n\n# Prebuild the web client assets so we can simply copy them over\nENV NODE_ENV=production\nRUN yarn run build-web-client\n\n# Then prune the server deps to only the production ones\nRUN yarn\n\n# Clone the `wait-for-it` repository which contains a script we'll copy over to our final image, and\n# use it to control our services startup order\nRUN git clone https://github.com/vishnubob/wait-for-it.git\n\n# Clone the `s3cmd` repository which contains a script we'll copy over to our final image, and use\n# it to sync our public assets to the cloud\nRUN git clone https://github.com/s3tools/s3cmd.git\n\n# ---------- 2nd stage ----------\n# Second stage copies the built dependencies from first stage and runs the app in production mode\nFROM node:16-alpine\nENV NODE_ENV=production\n# Tell the server not to try and run webpack\nENV SB_PREBUILT_ASSETS=true\n\n# Since we're executing some bash scripts (eg. `wait-for-it.sh`) before running the containers using\n# this image, we need to install it explicitly because alpine-based images don't have it by default.\n# Also, we need python to execute some python scripts (e.g. `s3cmd`).\nRUN apk add --no-cache bash logrotate jq python3 py-pip\n\n# Install the dependencies of the `s3cmd` python script\nRUN pip3 install --no-cache-dir python-dateutil\n\n# Set up log rotation\nCOPY --from=builder /shieldbattery/server/deployment_files/logrotate.conf /etc/logrotate.d/shieldbattery\n\n# Give the logrotate status file to the node user since that's what crond will be running under\nRUN touch /var/lib/logrotate.status && chown node:node /var/lib/logrotate.status\n\n# Set the user to `node` for any subsequent `RUN` and `CMD` instructions\nUSER node\n\n# Set the working directory to the home directory of the `node` user\nWORKDIR /home/node/shieldbattery\n\n# Copy just the sources the server needs\nCOPY --chown=node:node --from=builder /shieldbattery/node_modules ./node_modules\nCOPY --chown=node:node --from=builder /shieldbattery/common ./common\nCOPY --chown=node:node --from=builder /shieldbattery/server ./server\nCOPY --chown=node:node --from=builder /shieldbattery/package.json /shieldbattery/babel.config.json ./\nCOPY --chown=node:node --from=builder /shieldbattery/babel-register.js /shieldbattery/babel-register.js ./\n\n# Copy the installed dependencies from the first stage\nCOPY --chown=node:node --from=builder /shieldbattery/wait-for-it/wait-for-it.sh tools/wait-for-it.sh\nCOPY --chown=node:node --from=builder /shieldbattery/s3cmd/s3cmd tools/s3cmd/s3cmd\nCOPY --chown=node:node --from=builder /shieldbattery/s3cmd/S3 tools/s3cmd/S3\n\n# Allow the various scripts to be run (necessary when building on Linux)\nRUN chmod +x ./server/update_server.sh\nRUN chmod +x ./server/testing/run_mailgun.sh\n\nCOPY --chown=node:node --from=builder /shieldbattery/server/deployment_files/entrypoint.sh /entrypoint.sh\nRUN chmod +x /entrypoint.sh\n\n# Make the various volume locations as the right user (if we let Docker do it they end up owned by\n# root and not writeable)\nRUN mkdir ./server/logs && mkdir ./server/uploaded_files && mkdir ./server/bw_sprite_data\n\nRUN touch /var/lib/logrotate.status\n\n# http (generally reverse-proxied to)\nEXPOSE 5555/tcp\n\nCMD /entrypoint.sh\n"
}