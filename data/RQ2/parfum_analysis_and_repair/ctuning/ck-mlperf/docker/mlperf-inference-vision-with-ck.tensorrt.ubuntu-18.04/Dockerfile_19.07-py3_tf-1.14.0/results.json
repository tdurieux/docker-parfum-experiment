{
  "startTime": 1674219326223,
  "endTime": 1674219327484,
  "originalSmells": [
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 15,
        "lineEnd": 15,
        "columnStart": 4,
        "columnEnd": 28
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 17,
        "lineEnd": 22,
        "columnStart": 4,
        "columnEnd": 4
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 15,
        "lineEnd": 15,
        "columnStart": 4,
        "columnEnd": 28
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 17,
        "lineEnd": 22,
        "columnStart": 4,
        "columnEnd": 4
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM nvcr.io/nvidia/tensorrt:19.07-py3\n\nLABEL maintainer=\"Anton Lokhmotov <anton@dividiti.com>\"\n\n# Use the Bash shell.\nSHELL [\"/bin/bash\", \"-c\"]\n\n# Allow stepping into the Bash shell interactively.\nENTRYPOINT [\"/bin/bash\", \"-c\"]\n\n# Install known system dependencies and immediately clean up to make the image smaller.\n# CK needs: git, wget, zip.\n# TF needs: curl.\n# TF Object Detection API needs ProtoBuf 3.0 which needs CMake.\nRUN apt update -y \\\n && apt install --no-install-recommends -y apt-utils \\\n && apt upgrade -y \\\n && apt install --no-install-recommends -y \\\n git wget zip libz-dev \\\n curl \\\n cmake \\\n python3 python3-pip \\\n vim \\\n && apt clean && rm -rf /var/lib/apt/lists/*;\n\n# Create a non-root user with a fixed group id 1500 and a fixed user id 2000\n# (hopefully distinct from any host user id for security reasons).\n# See the README for the gory details.\nRUN groupadd -g 1500 dvdtg\nRUN useradd -u 2000 -g dvdtg --create-home --shell /bin/bash dvdt\nUSER dvdt:dvdtg\nWORKDIR /home/dvdt\n\n# Install Collective Knowledge (CK). Make it group-executable.\nENV CK_ROOT=/home/dvdt/CK \\\n    CK_REPOS=/home/dvdt/CK_REPOS \\\n    CK_TOOLS=/home/dvdt/CK_TOOLS \\\n    PATH=${CK_ROOT}/bin:/home/dvdt/.local/bin:${PATH} \\\n    CK_CC=gcc \\\n    CK_PYTHON=python3 \\\n    GIT_USER=\"dividiti\" \\\n    GIT_EMAIL=\"info@dividiti.com\" \\\n    LANG=C.UTF-8\nRUN mkdir -p ${CK_ROOT} ${CK_REPOS} ${CK_TOOLS}\nRUN git config --global user.name ${GIT_USER} && git config --global user.email ${GIT_EMAIL}\nRUN git clone https://github.com/ctuning/ck.git ${CK_ROOT}\nRUN cd ${CK_ROOT}\\\n && ${CK_PYTHON} setup.py install --user\\\n && ${CK_PYTHON} -c \"import ck.kernel as ck; print ('Collective Knowledge v%s' % ck.__version__)\"\\\n && chmod -R g+rx /home/dvdt/.local\n\n# Explicitly create a CK experiment entry, a folder that will be mounted\n# (with '--volume=<folder_for_results>:/home/dvdt/CK_REPOS/local/experiment').\n# as a shared volume between the host and the container, and make it group-writable.\n# For consistency, use the \"canonical\" uid from ck-analytics:module:experiment.\nRUN ck create_entry --data_uoa=experiment --data_uid=bc0409fb61f0aa82 --path=${CK_REPOS}/local\\\n && chmod -R g+w ${CK_REPOS}/local/experiment\n\n# Pull CK repositories (including ck-mlperf, ck-env, ck-autotuning, ck-tensorflow, ck-docker).\nRUN ck pull repo:ck-object-detection\n\n# Use generic Linux settings with dummy frequency setting scripts.\nRUN ck detect platform.os --platform_init_uoa=generic-linux-dummy\n\n# Detect C/C++ compiler (gcc).\nRUN ck detect soft:compiler.gcc --full_path=`which ${CK_CC}`\n\n# Detect Python.\nRUN ck detect soft:compiler.python --full_path=`which ${CK_PYTHON}`\n# Install the latest Python package installer (pip) and some dependencies.\nRUN ${CK_PYTHON} -m pip install --ignore-installed pip setuptools --user\n\n\n#-----------------------------------------------------------------------------#\n# Step 1. Install prebuilt TensorFlow v1.14 (via pip).\n# NB: We cannot install prebuilt TensorFlow v1.14 with CUDA support,\n# as it needs CUDA 10.0.\n#-----------------------------------------------------------------------------#\nRUN ck install package --tags=lib,tensorflow,vcpu,vprebuilt,v1.14\n#-----------------------------------------------------------------------------#\n\n\n#-----------------------------------------------------------------------------#\n# Step 2. Install TensorFlow v1.14 with CUDA/TensorRT support from sources.\n#-----------------------------------------------------------------------------#\n# Install TF dependencies that currently have no CK packages.\nRUN ${CK_PYTHON} -m pip install gast --user\nRUN ${CK_PYTHON} -m pip install protobuf --user\nRUN ${CK_PYTHON} -m pip install absl-py --user\nRUN ${CK_PYTHON} -m pip install wrapt --user\nRUN ${CK_PYTHON} -m pip install astor --user\nRUN ${CK_PYTHON} -m pip install termcolor --user\nRUN ${CK_PYTHON} -m pip install tensorflow-estimator==1.14.0 --user\nRUN ${CK_PYTHON} -m pip install keras_applications==1.0.6 --no-deps --user\nRUN ${CK_PYTHON} -m pip install keras_preprocessing==1.0.5 --no-deps --user\n# Detect TF CUDA dependencies.\nRUN ck detect soft:compiler.cuda --full_path=/usr/local/cuda-10.1/bin/nvcc \\\n && ck detect soft:lib.cublas --full_path=/usr/lib/x86_64-linux-gnu/libcublas.so \\\n && ck detect soft:lib.cudnn\n# Install TF build dependencies.\nRUN ck install ck-env:package:jdk-8u131-universal\nRUN ck install ck-env:package:tool-bazel-0.25.2-linux\n# Build TF from sources with TensorRT support. Remove the Bazel cache (~16 GB) once done.\nRUN ck install package --tags=lib,tensorflow,vsrc,vcuda,v1.14 --env.CK_TF_NEED_TENSORRT=YES\\\n && rm -rf ~/.cache/bazel\n#-----------------------------------------------------------------------------#\n\n\n#-----------------------------------------------------------------------------#\n# Step 3. Install the COCO 2017 validation dataset (5,000 images).\n#-----------------------------------------------------------------------------#\n# Download the dataset to the default path. Remove all training annotations (~765 MB).\nRUN echo | ck install package --tags=object-detection,dataset,coco.2017,val,original,full\\\n && ck virtual env --tags=object-detection,dataset,coco.2017,val,original,full --shell_cmd=\\\n'rm $CK_ENV_DATASET_COCO_LABELS_DIR/*train2017.json'\n# Install Python COCO API.\nRUN ck install package --tags=lib,python-package,cython\nRUN ck install package --tags=lib,python-package,numpy\nRUN ck install package --tags=lib,python-package,matplotlib\nRUN ck install package --tags=tool,coco,api\n#-----------------------------------------------------------------------------#\n\n\n#-----------------------------------------------------------------------------#\n# Step 4. Install the object detection models.\n#-----------------------------------------------------------------------------#\n# Install TF model API, but remove useless API files to free up space.\nRUN ck detect soft --tags=cmake --full_path=/usr/local/bin/cmake\nRUN ck install package --tags=model,tensorflow,api\\\n && ck virtual env --tags=model,tensorflow,api --shell_cmd=\\\n'cd $CK_ENV_TENSORFLOW_MODELS;\\\n mv object_detection ..;\\\n rm * -r;\\\n mv ../object_detection .;\\\n cd ..;\\\n rm official -rf;\\\n rm samples -rf;\\\n rm tutorials -rf;\\\n rm .git -rf'\n\nRUN ck install package --tags=rcnn,nas,lowproposals,vcoco\\\n && ck install package --tags=rcnn,resnet50,lowproposals\\\n && ck install package --tags=rcnn,resnet101,lowproposals\\\n && ck install package --tags=rcnn,inception-resnet-v2,lowproposals\\\n && ck install package --tags=rcnn,inception-v2\\\n && ck install package --tags=ssd,inception-v2\\\n && ck install package --tags=ssd,mobilenet-v1,non-quantized,mlperf,tf\\\n && ck install package --tags=ssd,mobilenet-v1,quantized,mlperf,tf\\\n && ck install package --tags=ssd,mobilenet-v1,fpn\\\n && ck install package --tags=ssd,resnet50,fpn\\\n && ck install package --tags=ssdlite,mobilenet-v2,vcoco\\\n && ck install package --tags=yolo-v3\n#-----------------------------------------------------------------------------#\n\n\n#-----------------------------------------------------------------------------#\n# Step 5. Make final preparations to run the Object Detection TF-Python program.\n#-----------------------------------------------------------------------------#\n# Install remaining Python dependencies of the program.\n# (Some have already been installed.)\nRUN ck install package --tags=lib,python-package,cv2,opencv-python-headless\n# Allow the program create tmp files when running under an external user.\nRUN chmod -R g+rwx ${CK_REPOS}/ck-tensorflow/program/object-detection-tf-py/\n#-----------------------------------------------------------------------------#\n\n\n#=============================================================================#\n# NB: The above is shared with object-detection-tf-py.tensorrt.ubuntu-18.04\n#=============================================================================#\n\n\n#-----------------------------------------------------------------------------#\n# Step 6. Make final preparations to run the official vision app with CK mods.\n#-----------------------------------------------------------------------------#\n# NB: Apparently, we still need Pillow to run the official vision app.\nRUN ck install package --tags=lib,python-package,pillow\n# NB: While Abseil has already been installed above, we install and register it\n# with CK here as well, as it is needed for LoadGen.\nRUN ck install package --tags=lib,python-package,absl\n# Install LoadGen from the official MLPerf Inference repo.\nRUN ck install package --tags=mlperf,inference,source,upstream.master\nRUN ck install package --tags=lib,python-package,mlperf,loadgen\n# Install the official vision app with CK modifications and make it use\n# the default LoadGen config file.\nRUN ck install package --tags=mlperf,inference,source,dividiti.vision_with_ck\nRUN ck detect  soft    --tags=loadgen,config,from.inference.master\n# Allow the program to create tmp files when running under an external user.\nRUN chmod -R g+rwx `ck find program:mlperf-inference-vision`\n#-----------------------------------------------------------------------------#\n\n\n#-----------------------------------------------------------------------------#\n# Run the official MLPerf Inference vision app\n# in the Accuracy mode and the SingleStream scenario\n# on the first 50 images of the COCO 2017 validation dataset\n# with the TensorFlow CPU backend and the SSD-MobileNet-FPN model.\n#-----------------------------------------------------------------------------#\nCMD [\"ck run program:mlperf-inference-vision --cmd_key=direct \\\n--env.CK_LOADGEN_MODE='--accuracy' \\\n--env.CK_LOADGEN_SCENARIO=SingleStream \\\n--env.CK_LOADGEN_EXTRA_PARAMS='--count 50' \\\n--env.CK_LOADGEN_BACKEND=tensorflow \\\n--dep_add_tags.lib-tensorflow=vcuda --env.CUDA_VISIBLE_DEVICES=-1 \\\n--dep_add_tags.weights=ssd,mobilenet-v1,fpn \\\n--env.CK_LOADGEN_REF_PROFILE=default_tf_object_det_zoo \\\n--env.CK_METRIC_TYPE=COCO \\\n--skip_print_timers\"]\n"
}