{
  "startTime": 1674249065307,
  "endTime": 1674249065971,
  "originalSmells": [
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 23,
        "lineEnd": 23,
        "columnStart": 18,
        "columnEnd": 44
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 23,
        "lineEnd": 23,
        "columnStart": 18,
        "columnEnd": 44
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "# Copyright 2022 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#Refrence Dockerfile for custom image required for Hbase to GCS Dataproc template\n\n# Debian 11 is recommended.\nFROM debian:11-slim\n\n# Suppress interactive prompts\nENV DEBIAN_FRONTEND=noninteractive\n\n# (Required) Install utilities required by Spark scripts.\nRUN apt update && apt install --no-install-recommends -y procps tini && rm -rf /var/lib/apt/lists/*;\n\n# (Optional) Add extra jars.\nENV SPARK_EXTRA_JARS_DIR=/opt/spark/jars/\nENV SPARK_EXTRA_CLASSPATH='/opt/spark/jars/*'\nRUN mkdir -p \"${SPARK_EXTRA_JARS_DIR}\"\nCOPY hbase-site.xml /etc/hbase/conf/\n\n# (Required) Create the 'spark' group/user.\n# The GID and UID must be 1099. Home directory is required.\nRUN groupadd -g 1099 spark\nRUN useradd -u 1099 -g 1099 -d /home/spark -m spark\nUSER spark\n"
}