{
  "startTime": 1674246262170,
  "endTime": 1674246263717,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 12,
        "lineEnd": 12,
        "columnStart": 110,
        "columnEnd": 193
      }
    },
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 13,
        "lineEnd": 13,
        "columnStart": 93,
        "columnEnd": 158
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 7,
        "lineEnd": 7,
        "columnStart": 4,
        "columnEnd": 35
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM python:3.7\n\nWORKDIR /app\n\n# only copy requirements.txt first to leverage Docker cache\nCOPY requirements.txt .\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\n# Downloading the fine tuned models\nRUN mkdir -p /application/models/gector/data/model_files && cd /application/models/gector/data/model_files && curl -f -O https://grammarly-nlp-data-public.s3.amazonaws.com/gector/xlnet_0_gector.th\nRUN mkdir -p /application/models/sentence_reorder cd /application/models/sentence_reorder && curl -f -O http://tts.speech.cs.cmu.edu/sentence_order/nips_bert.tar && tar -xf nips_bert.tar && rm nips_bert.tar && mv nips_bert/ model/\n\n# Instantiating the models once to trigger the download of pretrained models\nRUN python -c \"from application.models.gector import model; model = model.load_model(vocab_path = 'application/models/gector/data/output_vocabulary',model_paths = ['application/models/gector/data/model_files/xlnet_0_gector.th'],model_name = 'xlnet')\"\nRUN python -c \"import application.models.sentence_reorder as sentence_reoder; sentence_reoder.load_model()\"\n\nCMD [\"python\",\"run.py\"]\n\nEXPOSE 80\n"
}