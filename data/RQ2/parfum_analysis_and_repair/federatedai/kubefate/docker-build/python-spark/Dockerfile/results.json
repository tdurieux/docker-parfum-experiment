{
  "startTime": 1674253117402,
  "endTime": 1674253118100,
  "originalSmells": [
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 19,
        "lineEnd": 19,
        "columnStart": 4,
        "columnEnd": 23
      }
    },
    {
      "rule": "yumInstallRmVarCacheYum",
      "position": {
        "lineStart": 6,
        "lineEnd": 6,
        "columnStart": 4,
        "columnEnd": 49
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "ARG SOURCE_PREFIX=federatedai\nARG SOURCE_TAG=1.5.0-release\nFROM ${SOURCE_PREFIX}/python:${SOURCE_TAG}\n\nRUN rpm --rebuilddb && \\\n    rpm --import /etc/pki/rpm-gpg/RPM* && \\\n    yum install -y  which java-1.8.0-openjdk wget && \\\n    yum clean all && \\\n    wget https://archive.apache.org/dist/hadoop/common/hadoop-2.7.4/hadoop-2.7.4.tar.gz && \\\n    tar -xf ./hadoop-2.7.4.tar.gz -C /data/projects/ && rm ./hadoop-2.7.4.tar.gz && rm -rf /var/cache/yum\n\nRUN wget https://archive.apache.org/dist/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz && \\\n    tar -xf ./spark-2.4.1-bin-hadoop2.7.tgz -C /data/projects/ && rm ./spark-2.4.1-bin-hadoop2.7.tgz\n\nENV JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk\nENV SPARK_HOME=/data/projects/spark-2.4.1-bin-hadoop2.7/\nENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/projects/hadoop-2.7.4/lib/native\nENV PATH=$PATH:/data/projects/spark-2.4.1-bin-hadoop2.7/bin:/data/projects/hadoop-2.7.4/bin\n\nRUN pip install --no-cache-dir pyspark"
}