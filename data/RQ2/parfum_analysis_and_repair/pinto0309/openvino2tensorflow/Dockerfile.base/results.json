{
  "startTime": 1674254604976,
  "endTime": 1674254606924,
  "originalSmells": [
    {
      "rule": "curlUseFlagF",
      "position": {
        "lineStart": 105,
        "lineEnd": 105,
        "columnStart": 7,
        "columnEnd": 65
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 39,
        "lineEnd": 39,
        "columnStart": 4,
        "columnEnd": 30
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 40,
        "lineEnd": 40,
        "columnStart": 7,
        "columnEnd": 42
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 41,
        "lineEnd": 41,
        "columnStart": 7,
        "columnEnd": 41
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 42,
        "lineEnd": 42,
        "columnStart": 7,
        "columnEnd": 40
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 43,
        "lineEnd": 43,
        "columnStart": 7,
        "columnEnd": 41
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 44,
        "lineEnd": 44,
        "columnStart": 7,
        "columnEnd": 32
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 45,
        "lineEnd": 45,
        "columnStart": 7,
        "columnEnd": 40
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 46,
        "lineEnd": 46,
        "columnStart": 7,
        "columnEnd": 34
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 47,
        "lineEnd": 47,
        "columnStart": 7,
        "columnEnd": 40
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 48,
        "lineEnd": 48,
        "columnStart": 7,
        "columnEnd": 33
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 49,
        "lineEnd": 49,
        "columnStart": 7,
        "columnEnd": 51
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 50,
        "lineEnd": 50,
        "columnStart": 7,
        "columnEnd": 36
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 51,
        "lineEnd": 51,
        "columnStart": 7,
        "columnEnd": 40
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 52,
        "lineEnd": 52,
        "columnStart": 7,
        "columnEnd": 49
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 53,
        "lineEnd": 53,
        "columnStart": 7,
        "columnEnd": 36
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 54,
        "lineEnd": 54,
        "columnStart": 7,
        "columnEnd": 36
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 55,
        "lineEnd": 55,
        "columnStart": 7,
        "columnEnd": 48
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 56,
        "lineEnd": 56,
        "columnStart": 7,
        "columnEnd": 48
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 57,
        "lineEnd": 57,
        "columnStart": 7,
        "columnEnd": 46
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 58,
        "lineEnd": 58,
        "columnStart": 7,
        "columnEnd": 34
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 59,
        "lineEnd": 59,
        "columnStart": 7,
        "columnEnd": 35
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 60,
        "lineEnd": 60,
        "columnStart": 7,
        "columnEnd": 39
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 61,
        "lineEnd": 61,
        "columnStart": 7,
        "columnEnd": 36
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 62,
        "lineEnd": 62,
        "columnStart": 7,
        "columnEnd": 35
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 63,
        "lineEnd": 63,
        "columnStart": 7,
        "columnEnd": 36
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 64,
        "lineEnd": 64,
        "columnStart": 7,
        "columnEnd": 57
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 65,
        "lineEnd": 65,
        "columnStart": 7,
        "columnEnd": 36
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 66,
        "lineEnd": 66,
        "columnStart": 7,
        "columnEnd": 32
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 67,
        "lineEnd": 67,
        "columnStart": 7,
        "columnEnd": 34
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 68,
        "lineEnd": 68,
        "columnStart": 7,
        "columnEnd": 34
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 69,
        "lineEnd": 69,
        "columnStart": 7,
        "columnEnd": 35
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 70,
        "lineEnd": 70,
        "columnStart": 7,
        "columnEnd": 39
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 71,
        "lineEnd": 71,
        "columnStart": 7,
        "columnEnd": 34
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 72,
        "lineEnd": 72,
        "columnStart": 7,
        "columnEnd": 33
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 73,
        "lineEnd": 73,
        "columnStart": 7,
        "columnEnd": 39
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 74,
        "lineEnd": 74,
        "columnStart": 7,
        "columnEnd": 42
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 76,
        "lineEnd": 76,
        "columnStart": 7,
        "columnEnd": 92
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 80,
        "lineEnd": 80,
        "columnStart": 7,
        "columnEnd": 88
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 81,
        "lineEnd": 81,
        "columnStart": 7,
        "columnEnd": 91
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 82,
        "lineEnd": 82,
        "columnStart": 7,
        "columnEnd": 90
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 86,
        "lineEnd": 86,
        "columnStart": 7,
        "columnEnd": 33
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 87,
        "lineEnd": 87,
        "columnStart": 7,
        "columnEnd": 31
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 88,
        "lineEnd": 88,
        "columnStart": 7,
        "columnEnd": 38
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 89,
        "lineEnd": 89,
        "columnStart": 7,
        "columnEnd": 27
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 90,
        "lineEnd": 90,
        "columnStart": 7,
        "columnEnd": 24
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 99,
        "lineEnd": 99,
        "columnStart": 7,
        "columnEnd": 109
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 128,
        "lineEnd": 128,
        "columnStart": 4,
        "columnEnd": 101
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 163,
        "lineEnd": 163,
        "columnStart": 4,
        "columnEnd": 92
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 164,
        "lineEnd": 164,
        "columnStart": 7,
        "columnEnd": 76
      }
    },
    {
      "rule": "aptGetInstallUseY",
      "position": {
        "lineStart": 108,
        "lineEnd": 108,
        "columnStart": 7,
        "columnEnd": 39
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 21,
        "lineEnd": 33,
        "columnStart": 7,
        "columnEnd": 50
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 108,
        "lineEnd": 108,
        "columnStart": 7,
        "columnEnd": 39
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 117,
        "lineEnd": 119,
        "columnStart": 7,
        "columnEnd": 48
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM nvidia/cuda:11.6.2-cudnn8-devel-ubuntu20.04\n\nENV DEBIAN_FRONTEND=noninteractive\nARG OSVER=ubuntu2004\nARG TENSORFLOWVER=2.9.0\nARG CPVER=cp38\nARG OPENVINOVER=2022.1.0\nARG TENSORRTVER=cuda11.6-trt8.4.0.6-ea-20220212\nARG ONNXRUNTIMEVER=1.12.0\nARG WKDIR=/home/user\n\n# dash -> bash\nRUN echo \"dash dash/sh boolean false\" | debconf-set-selections \\\n    && dpkg-reconfigure -p low dash\nCOPY bashrc ${WKDIR}/.bashrc\nWORKDIR ${WKDIR}\n\nCOPY packages/* ${WKDIR}/\n\n# Install dependencies (1)\nRUN apt-get update \\\n    && apt-get install --no-install-recommends -y \\\n        automake autoconf libpng-dev nano python3-pip \\\n        curl zip unzip libtool swig zlib1g-dev pkg-config \\\n        python3-mock libpython3-dev libpython3-all-dev \\\n        g++ gcc make pciutils cpio gosu wget libmkldnn-dev \\\n        libgtk-3-dev libxtst-dev sudo apt-transport-https \\\n        build-essential gnupg git xz-utils vim libyaml-cpp-dev \\\n        libva-drm2 libva-x11-2 vainfo libva-wayland2 libva-glx2 \\\n        libva-dev libdrm-dev xorg xorg-dev protobuf-compiler \\\n        openbox libx11-dev libgl1-mesa-glx libgl1-mesa-dev \\\n        libtbb2 libtbb-dev libopenblas-dev libopenmpi-dev \\\n        python-is-python3 software-properties-common \\\n        libxcb-xinerama0 patchelf libusb-1.0-0-dev \\\n    && sed -i 's/# set linenumbers/set linenumbers/g' /etc/nanorc \\\n    && apt clean \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install dependencies (2)\nRUN pip3 install --no-cache-dir --upgrade pip \\\n    && pip install --no-cache-dir --upgrade numpy==1.22.4 \\\n    && pip install --no-cache-dir --upgrade tensorflowjs \\\n    && pip install --no-cache-dir --upgrade coremltools \\\n    && pip install --no-cache-dir --upgrade paddlepaddle \\\n    && pip install --no-cache-dir --upgrade lap \\\n    && pip install --no-cache-dir --upgrade pycocotools \\\n    && pip install --no-cache-dir --upgrade scipy \\\n    && pip install --no-cache-dir --upgrade paddle2onnx \\\n    && pip install --no-cache-dir --upgrade onnx \\\n    && pip install --no-cache-dir --upgrade onnxruntime-extensions \\\n    && pip install --no-cache-dir --upgrade onnxsim \\\n    && pip install --no-cache-dir --upgrade onnxmltools \\\n    && pip install --no-cache-dir --upgrade onnxconverter-common \\\n    && pip install --no-cache-dir --upgrade tf2onnx \\\n    && pip install --no-cache-dir --upgrade onnx-tf \\\n    && pip install --no-cache-dir --upgrade tensorflow-datasets \\\n    && pip install --no-cache-dir --upgrade openvino2tensorflow \\\n    && pip install --no-cache-dir --upgrade tflite2tensorflow \\\n    && pip install --no-cache-dir --upgrade gdown \\\n    && pip install --no-cache-dir --upgrade PyYAML \\\n    && pip install --no-cache-dir --upgrade matplotlib \\\n    && pip install --no-cache-dir --upgrade tf_slim \\\n    && pip install --no-cache-dir --upgrade pandas \\\n    && pip install --no-cache-dir --upgrade numexpr \\\n    && pip install --no-cache-dir --upgrade simple-onnx-processing-tools \\\n    && pip install --no-cache-dir --upgrade gluoncv \\\n    && pip install --no-cache-dir --upgrade dgl \\\n    && pip install --no-cache-dir --upgrade cmake \\\n    && pip install --no-cache-dir --upgrade ninja \\\n    && pip install --no-cache-dir --upgrade Cython \\\n    && pip install --no-cache-dir --upgrade setuptools \\\n    && pip install --no-cache-dir --upgrade wheel \\\n    && pip install --no-cache-dir --upgrade pafy \\\n    && pip install --no-cache-dir --upgrade youtube-dl \\\n    && pip install --no-cache-dir --upgrade blobconverter \\\n    && pip uninstall -y onnxruntime onnxruntime-gpu \\\n    && pip install --no-cache-dir ${WKDIR}/onnxruntime_gpu-${ONNXRUNTIMEVER}-${CPVER}-none-linux_x86_64.whl \\\n    && rm ${WKDIR}/onnxruntime_gpu-${ONNXRUNTIMEVER}-${CPVER}-none-linux_x86_64.whl \\\n    && python -m pip install onnx_graphsurgeon \\\n        --index-url https://pypi.ngc.nvidia.com \\\n    && pip install --no-cache-dir ${WKDIR}/torch-1.12.0a0+gite68686b-${CPVER}-${CPVER}-linux_x86_64.whl \\\n    && pip install --no-cache-dir ${WKDIR}/torchvision-0.13.0a0+ecbff88-${CPVER}-${CPVER}-linux_x86_64.whl \\\n    && pip install --no-cache-dir ${WKDIR}/torchaudio-0.12.0a0+a71e3a4-${CPVER}-${CPVER}-linux_x86_64.whl \\\n    && rm ${WKDIR}/torch-1.12.0a0+gite68686b-${CPVER}-${CPVER}-linux_x86_64.whl \\\n    && rm ${WKDIR}/torchvision-0.13.0a0+ecbff88-${CPVER}-${CPVER}-linux_x86_64.whl \\\n    && rm ${WKDIR}/torchaudio-0.12.0a0+a71e3a4-${CPVER}-${CPVER}-linux_x86_64.whl \\\n    && pip install --no-cache-dir pycuda==2021.1 \\\n    && pip install --no-cache-dir scikit-image \\\n    && pip install --no-cache-dir performance-monitor \\\n    && pip install --no-cache-dir graphviz \\\n    && pip install --no-cache-dir pydot \\\n    && ldconfig \\\n    && pip cache purge \\\n    && apt clean \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install custom tflite_runtime (MediaPipe Custom OP, FlexDelegate, XNNPACK enabled), flatc, edgetpu-compiler\n# https://github.com/PINTO0309/TensorflowLite-bin\nRUN chmod +x ${WKDIR}/tflite_runtime-${TENSORFLOWVER}-${CPVER}-none-linux_x86_64.whl \\\n    && pip3 install --no-cache-dir --force-reinstall ${WKDIR}/tflite_runtime-${TENSORFLOWVER}-${CPVER}-none-linux_x86_64.whl \\\n    && rm ${WKDIR}/tflite_runtime-${TENSORFLOWVER}-${CPVER}-none-linux_x86_64.whl \\\n    && tar -zxvf ${WKDIR}/flatc.tar.gz \\\n    && chmod +x ${WKDIR}/flatc \\\n    && rm ${WKDIR}/flatc.tar.gz \\\n    && wget https://github.com/PINTO0309/tflite2tensorflow/raw/main/schema/schema.fbs \\\n    && curl -f https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - \\\n    && echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | tee /etc/apt/sources.list.d/coral-edgetpu.list \\\n    && apt-get update \\\n    && apt-get install -y --no-install-recommends edgetpu-compiler \\\n    && pip cache purge \\\n    && apt clean \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install TensorRT additional package\nRUN dpkg -i ${WKDIR}/nv-tensorrt-repo-${OSVER}-${TENSORRTVER}_1-1_amd64.deb \\\n    && apt-key add /var/nv-tensorrt-repo-${OSVER}-${TENSORRTVER}/7fa2af80.pub \\\n    && apt-get update \\\n    && apt-get install --no-install-recommends -y \\\n        tensorrt uff-converter-tf graphsurgeon-tf \\\n        python3-libnvinfer-dev onnx-graphsurgeon \\\n    && rm ${WKDIR}/nv-tensorrt-repo-${OSVER}-${TENSORRTVER}_1-1_amd64.deb \\\n    && cd /usr/src/tensorrt/samples/trtexec \\\n    && make \\\n    && apt clean \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Custom TensorFlow (MediaPipe Custom OP, FlexDelegate, XNNPACK enabled)\n# https://github.com/PINTO0309/Tensorflow-bin\nRUN pip install --no-cache-dir --force-reinstall ${WKDIR}/tensorflow-${TENSORFLOWVER}-${CPVER}-none-linux_x86_64.whl \\\n    && rm ${WKDIR}/tensorflow-${TENSORFLOWVER}-${CPVER}-none-linux_x86_64.whl \\\n    && pip cache purge \\\n    && apt clean \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install onnx-tensorrt\nRUN git clone --recursive https://github.com/onnx/onnx-tensorrt \\\n    && cd onnx-tensorrt \\\n    && git checkout 4ebfd965edb2737d02c3202749a7bc499d53c585 \\\n    && mkdir build \\\n    && cd build \\\n    && cmake .. -DTENSORRT_ROOT=/usr/src/tensorrt \\\n    && make -j$(nproc) \\\n    && make install\n\n# Install torch2trt\nRUN git clone https://github.com/NVIDIA-AI-IOT/torch2trt \\\n    && cd torch2trt \\\n    && git checkout 458394febf25b879cb6ea2e12f0060ef4beae7a3 \\\n    && python3 setup.py install\n\n# Download the ultra-small sample data set for INT8 calibration\nRUN mkdir sample_npy \\\n    && mv calibration_data_img_sample.npy sample_npy/\n\n# LLVM\nRUN wget https://apt.llvm.org/llvm.sh \\\n    && chmod +x llvm.sh \\\n    && ./llvm.sh 14 \\\n    && apt clean \\\n    && rm -rf /var/lib/apt/lists/*\n\n# OpenVINO\n# https://github.com/PINTO0309/20220228_intel_deeplearning_day_hitnet_demo#4-4-building-openvino--openvino%E3%81%AE%E3%83%93%E3%83%AB%E3%83%89\nRUN pip install --no-cache-dir ${WKDIR}/openvino-${OPENVINOVER}-000-${CPVER}-none-manylinux_2_31_x86_64.whl \\\n    && pip install --no-cache-dir ${WKDIR}/openvino_dev-${OPENVINOVER}-000-py3-none-any.whl \\\n    && rm ${WKDIR}/openvino-${OPENVINOVER}-000-${CPVER}-none-manylinux_2_31_x86_64.whl \\\n    && rm ${WKDIR}/openvino_dev-${OPENVINOVER}-000-py3-none-any.whl \\\n    && pip cache purge\n\n# Clear caches\nRUN apt clean \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Create a user who can sudo in the Docker container\nENV USERNAME=user\nRUN echo \"root:root\" | chpasswd \\\n    && adduser --disabled-password --gecos \"\" \"${USERNAME}\" \\\n    && echo \"${USERNAME}:${USERNAME}\" | chpasswd \\\n    && echo \"%${USERNAME}    ALL=(ALL)   NOPASSWD:    ALL\" >> /etc/sudoers.d/${USERNAME} \\\n    && chmod 0440 /etc/sudoers.d/${USERNAME}\nUSER ${USERNAME}\nRUN sudo chown ${USERNAME}:${USERNAME} ${WKDIR} \\\n    && sudo chmod 777 ${WKDIR}/.bashrc\n\n# OpenCL settings - https://github.com/intel/compute-runtime/releases\nRUN cd ${WKDIR} \\\n    && sudo dpkg -i libigdgmm12_22.1.2_amd64.deb \\\n    && sudo dpkg -i intel-igc-core_1.0.11061_amd64.deb \\\n    && sudo dpkg -i intel-igc-opencl_1.0.11061_amd64.deb \\\n    && sudo dpkg -i intel-level-zero-gpu_1.3.23034_amd64.deb \\\n    && sudo dpkg -i intel-level-zero-gpu-dbgsym_1.3.23034_amd64.deb \\\n    && sudo dpkg --auto-deconfigure --force-all -i intel-opencl-icd_22.17.23034_amd64.deb \\\n    && sudo dpkg -i intel-opencl-icd-dbgsym_22.17.23034_amd64.deb \\\n    && rm intel-igc-core_1.0.11061_amd64.deb \\\n    && rm intel-igc-opencl_1.0.11061_amd64.deb \\\n    && rm intel-level-zero-gpu_1.3.23034_amd64.deb \\\n    && rm intel-level-zero-gpu-dbgsym_1.3.23034_amd64.deb \\\n    && rm intel-opencl-icd_22.17.23034_amd64.deb \\\n    && rm intel-opencl-icd-dbgsym_22.17.23034_amd64.deb \\\n    && rm libigdgmm12_22.1.2_amd64.deb \\\n    && sudo apt clean \\\n    && sudo rm -rf /var/lib/apt/lists/*\n\n# Final processing of onnx-tensorrt install\nRUN echo 'GPU=$(python3 -c \"import torch;print(torch.cuda.is_available())\")' >> ${HOME}/.bashrc \\\n    && echo 'if [ $GPU = \"True\" ]; then' >> ${HOME}/.bashrc \\\n    && echo \"export PATH=${PATH}:/usr/src/tensorrt/bin:/onnx-tensorrt/build\" >> ${HOME}/.bashrc \\\n    && echo \"cd ${HOME}/onnx-tensorrt\" >> ${HOME}/.bashrc \\\n    && echo \"sudo python setup.py install\" >> ${HOME}/.bashrc \\\n    && echo \"fi\" >> ${HOME}/.bashrc \\\n    && echo \"cd ${WKDIR}\" >> ${HOME}/.bashrc \\\n    && echo \"cd ${HOME}/workdir\" >> ${HOME}/.bashrc\n"
}