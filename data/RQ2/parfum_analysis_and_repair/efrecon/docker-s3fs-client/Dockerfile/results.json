{
  "startTime": 1674248127893,
  "endTime": 1674248128868,
  "originalSmells": [
    {
      "rule": "configureShouldUseBuildFlag",
      "position": {
        "lineStart": 21,
        "lineEnd": 21,
        "columnStart": 2,
        "columnEnd": 27
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM alpine:3.15.3 AS build\n\nARG S3FS_VERSION=v1.91\n\nRUN apk --no-cache add \\\n    ca-certificates \\\n    build-base \\\n    git \\\n    alpine-sdk \\\n    libcurl \\\n    automake \\\n    autoconf \\\n    libxml2-dev \\\n    libressl-dev \\\n    mailcap \\\n    fuse-dev \\\n    curl-dev && \\\n  git clone https://github.com/s3fs-fuse/s3fs-fuse.git && \\\n  cd s3fs-fuse && \\\n  git checkout tags/${S3FS_VERSION} && \\\n  ./autogen.sh && \\\n  ./configure --build=\"$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)\" --prefix=/usr && \\\n  make -j && \\\n  make install\n\nFROM alpine:3.15.3\n\n# Metadata\nLABEL MAINTAINER=efrecon+github@gmail.com\nLABEL org.opencontainers.image.title=\"efrecon/s3fs\"\nLABEL org.opencontainers.image.description=\"Mount S3 buckets from within a container and expose them to host/containers\"\nLABEL org.opencontainers.image.authors=\"Emmanuel Fr√©con <efrecon+github@gmail.com>\"\nLABEL org.opencontainers.image.url=\"https://github.com/efrecon/docker-s3fs-client\"\nLABEL org.opencontainers.image.documentation=\"https://github.com/efrecon/docker-s3fs-client/README.md\"\nLABEL org.opencontainers.image.source=\"https://github.com/efrecon/docker-s3fs-client/Dockerfile\"\n\nCOPY --from=build /usr/bin/s3fs /usr/bin/s3fs\n\n# Specify URL and secrets. When using AWS_S3_SECRET_ACCESS_KEY_FILE, the secret\n# key will be read from that file itself, which helps passing further passwords\n# using Docker secrets. You can either specify the path to an authorisation\n# file, set environment variables with the key and the secret.\nENV AWS_S3_URL=https://s3.amazonaws.com\nENV AWS_S3_ACCESS_KEY_ID=\nENV AWS_S3_SECRET_ACCESS_KEY=\nENV AWS_S3_SECRET_ACCESS_KEY_FILE=\nENV AWS_S3_AUTHFILE=\nENV AWS_S3_BUCKET=\n\n# User and group ID of share owner\nENV RUN_AS=\nENV UID=0\nENV GID=0\n\n# Location of directory where to mount the drive into the container.\nENV AWS_S3_MOUNT=/opt/s3fs/bucket\n\n# s3fs tuning\nENV S3FS_DEBUG=0\nENV S3FS_ARGS=\n\nRUN mkdir /opt/s3fs && \\\n    apk --no-cache add \\\n      ca-certificates \\\n      mailcap \\\n      fuse \\\n      libxml2 \\\n      libcurl \\\n      libgcc \\\n      libstdc++ \\\n      tini && \\\n    deluser xfs && \\\n    s3fs --version\n\n# allow access to volume by different user to enable UIDs other than root when using volumes\nRUN echo user_allow_other >> /etc/fuse.conf\n\nCOPY *.sh /usr/local/bin/\n\nWORKDIR /opt/s3fs\n\n# Following should match the AWS_S3_MOUNT environment variable.\nVOLUME [ \"/opt/s3fs/bucket\" ]\n\nHEALTHCHECK \\\n  --interval=15s \\\n  --timeout=5s \\\n  --start-period=15s \\\n  --retries=2 \\\n  CMD [ \"/usr/local/bin/healthcheck.sh\" ]\n\n# The default is to perform all system-level mounting as part of the entrypoint\n# to then have a command that will keep listing the files under the main share.\n# Listing the files will keep the share active and avoid that the remote server\n# closes the connection.\nENTRYPOINT [ \"tini\", \"-g\", \"--\", \"docker-entrypoint.sh\" ]\nCMD [ \"empty.sh\" ]\n"
}