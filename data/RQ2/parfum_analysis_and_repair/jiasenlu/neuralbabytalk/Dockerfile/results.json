{
  "startTime": 1674249999883,
  "endTime": 1674250000963,
  "originalSmells": [
    {
      "rule": "wgetUseHttpsUrl",
      "position": {
        "lineStart": 48,
        "lineEnd": 48,
        "columnStart": 4,
        "columnEnd": 90
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 22,
        "lineEnd": 22,
        "columnStart": 4,
        "columnEnd": 22
      }
    },
    {
      "rule": "pipUseNoCacheDir",
      "position": {
        "lineStart": 22,
        "lineEnd": 31,
        "columnStart": 26,
        "columnEnd": 8
      }
    },
    {
      "rule": "aptGetInstallUseNoRec",
      "position": {
        "lineStart": 9,
        "lineEnd": 16,
        "columnStart": 4,
        "columnEnd": 8
      }
    },
    {
      "rule": "ruleAptGetInstallThenRemoveAptLists",
      "position": {
        "lineStart": 9,
        "lineEnd": 16,
        "columnStart": 4,
        "columnEnd": 8
      }
    }
  ],
  "repairedSmells": [],
  "repairedDockerfile": "FROM pytorch/pytorch:0.4-cuda9-cudnn7-devel\n\nCOPY . /workspace/neuralbabytalk\n\n# ----------------------------------------------------------------------------\n# -- install apt and pip dependencies\n# ----------------------------------------------------------------------------\n\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y \\\n    ant \\\n    ca-certificates-java \\\n    nano \\\n    openjdk-8-jdk \\\n    python2.7 \\\n    unzip \\\n    wget && \\\n    apt-get clean && rm -rf /var/lib/apt/lists/*;\n\nENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64/\nRUN update-ca-certificates -f && export JAVA_HOME\n\nRUN pip install --no-cache-dir Cython && pip install --no-cache-dir h5py \\\n    matplotlib \\\n    nltk \\\n    numpy \\\n    pycocotools \\\n    scikit-image \\\n    stanfordcorenlp \\\n    tensorflow \\\n    torchtext \\\n    tqdm && python -c \"import nltk; nltk.download('punkt')\"\n\n\n# ----------------------------------------------------------------------------\n# -- download pretrained imagenet weights for resnet-101\n# ----------------------------------------------------------------------------\n\nRUN mkdir /workspace/neuralbabytalk/data/imagenet_weights && \\\n    cd /workspace/neuralbabytalk/data/imagenet_weights && \\\n    wget --quiet https://www.dropbox.com/sh/67fc8n6ddo3qp47/AAACkO4QntI0RPvYic5voWHFa/resnet101.pth\n\n\n# ----------------------------------------------------------------------------\n# -- download Karpathy's preprocessed captions datasets and corenlp jar\n# ----------------------------------------------------------------------------\n\nRUN cd /workspace/neuralbabytalk/data && \\\n    wget --quiet https://cs.stanford.edu/people/karpathy/deepimagesent/caption_datasets.zip && \\\n    unzip caption_datasets.zip && \\\n    mv dataset_coco.json coco/ && \\\n    mv dataset_flickr30k.json flickr30k/ && \\\n    rm caption_datasets.zip dataset_flickr8k.json\n\nRUN cd /workspace/neuralbabytalk/prepro && \\\n    wget --quiet https://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip && \\\n    unzip stanford-corenlp-full-2017-06-09.zip && \\\n    rm stanford-corenlp-full-2017-06-09.zip\n\nRUN cd /workspace/neuralbabytalk/tools/coco-caption && \\\n    sh get_stanford_models.sh\n\n# ----------------------------------------------------------------------------\n# -- download preprocessed COCO detection output HDF file and pretrained model\n# ----------------------------------------------------------------------------\n\nRUN cd /workspace/neuralbabytalk/data/coco && \\\n    wget --quiet https://www.dropbox.com/s/2gzo4ops5gbjx5h/coco_detection.h5.tar.gz && \\\n    tar -xzvf coco_detection.h5.tar.gz && \\\n    rm coco_detection.h5.tar.gz\n\nRUN mkdir -p /workspace/neuralbabytalk/save && \\\n    cd /workspace/neuralbabytalk/save && \\\n    wget --quiet https://www.dropbox.com/s/6buajkxm9oed1jp/coco_nbt_1024.tar.gz && \\\n    tar -xzvf coco_nbt_1024.tar.gz && \\\n    rm coco_nbt_1024.tar.gz\n\nWORKDIR /workspace/neuralbabytalk\nRUN python prepro/prepro_dic_coco.py \\\n    --input_json data/coco/dataset_coco.json \\\n    --split normal \\\n    --output_dic_json data/coco/dic_coco.json \\\n    --output_cap_json data/coco/cap_coco.json && \\\n    python prepro/prepro_dic_coco.py \\\n    --input_json data/coco/dataset_coco.json \\\n    --split robust \\\n    --output_dic_json data/robust_coco/dic_coco.json \\\n    --output_cap_json data/robust_coco/cap_coco.json && \\\n    python prepro/prepro_dic_coco.py \\\n    --input_json data/coco/dataset_coco.json \\\n    --split noc \\\n    --output_dic_json data/noc_coco/dic_coco.json \\\n    --output_cap_json data/noc_coco/cap_coco.json\n\nEXPOSE 8888\n"
}