{
  "user": "jwoglom",
  "name": "tconnectsync",
  "namespace": "jwoglom",
  "repository_type": "image",
  "status": 1,
  "status_description": "active",
  "description": "Syncs Tandem t:connect pump data to Nightscout. https://github.com/jwoglom/tconnectsync",
  "is_private": false,
  "is_automated": false,
  "can_edit": false,
  "star_count": 1,
  "pull_count": 534,
  "last_updated": "2023-01-17T01:00:54.76387Z",
  "date_registered": "2021-03-16T02:42:24.94253Z",
  "collaborator_count": 0,
  "affiliation": null,
  "hub_user": "jwoglom",
  "has_starred": false,
  "full_description": "# tconnectsync\n\n![Python Package workflow](https://github.com/jwoglom/tconnectsync/actions/workflows/python-package.yml/badge.svg)\n[![codecov](https://codecov.io/gh/jwoglom/tconnectsync/branch/master/graph/badge.svg)](https://codecov.io/gh/jwoglom/tconnectsync)\n\nTconnectsync synchronizes data one-way from the Tandem Diabetes t:connect web/mobile application to Nightscout.\n\nIf you have a t:slim X2 pump with the companion t:connect mobile Android or iOS app, this will allow your pump bolus and basal data to be uploaded to [Nightscout](https://github.com/nightscout/cgm-remote-monitor) automatically. The t:connect Android app, by default, uploads pump data to Tandem's servers every hour, [but using this tool you can update the frequency to as low as every five minutes](https://github.com/jwoglom/tconnectpatcher)! This allows for nearly real-time (but not instantaneous) pump data updates, almost like your pump uploads data directly to Nightscout!\n\nAt a high level, tconnectsync works by querying Tandem's undocumented APIs to receive basal and bolus data from t:connect, and then uploads that data as treatment objects to Nightscout. It contains features for checking for new Tandem pump data continuously, and updating that data along with the pump's reported IOB value to Nightscout whenever there is new data.\n\n**To get started,** read the setup instructions below and choose whether to run the application via **Pipenv** or **Docker**.\n\n## Tandem APIs\n\nThis application utilizes three separate Tandem APIs for obtaining t:connect data, referenced here by the identifying part of their URLs:\n\n* [**controliq**](https://github.com/jwoglom/tconnectsync/blob/master/tconnectsync/api/controliq.py) - Contains Control:IQ related data, namely a timeline of all Basal events uploaded by the pump, separated by type (temp basals, algorithmically-updated basals, or profile-updated basals).\n* [**android**](https://github.com/jwoglom/tconnectsync/blob/master/tconnectsync/api/android.py) - Used internally by the t:connect Android app, these API endpoints were discovered by reverse-engineering the Android app. Most of the API endpoints are used for uploading pump data, and tconnectsync uses one endpoint which returns the most recent event ID uploaded by the pump, so we know when more data has been uploaded.\n* [**tconnectws2**](https://github.com/jwoglom/tconnectsync/blob/master/tconnectsync/api/ws2.py) - More legacy than the others, this seems to power the bulk of the main t:connect website. It is used to retrieve a CSV export of non-ControlIQ basal data, as well as bolus and IOB data. (I haven't found any mentions of bolus or IOB data in the Control:IQ-specific API.)\n\n## Setup\n\nCreate a file named `.env` containing configuration values inside the checked-out tconnectsync folder (the same folder as `main.py`). You should specify the following parameters:\n\n```bash\n# Your credentials for t:connect\nTCONNECT_EMAIL='email@email.com'\nTCONNECT_PASSWORD='password'\n\n# Your pump's serial number (numeric)\nPUMP_SERIAL_NUMBER=11111111\n\n# URL and API secret for Nightscout\nNS_URL='https://yournightscouturl/'\nNS_SECRET='apisecret'\n\n# Current timezone of the pump\nTIMEZONE_NAME='America/New_York'\n```\n\nThese values can alternatively be specified via environment variables.\n\nThe .env file contains your t:connect username and password, Tandem pump serial number (which is utilized in API calls to t:connect), your Nightscout URL and secret token (for uploading data to Nightscout), and local timezone (the timezone used in t:connect).\n\nI have only tested tconnectsync with a Tandem pump set in the US Eastern timezone. Tandem's (to us, undocumented) APIs are [a bit loose with timezones](https://github.com/jwoglom/tconnectsync/blob/master/tconnectsync/parser.py#L15), so please let me know if you notice any timezone-related bugs.\n\nWhen you run the program with no arguments, it performs a single cycle of the following, and exits after completion:\n\n* Queries for basal information via the t:connect ControlIQ API.\n* Queries for bolus, basal, and IOB data via the t:connect non-ControlIQ API.\n* Merges the basal information received from the two APIs. (If using ControlIQ, then basal information appears only on the ControlIQ API. If not using ControlIQ, it appears only on the legacy API.)\n* Queries Nightscout for the most recently created Temp Basal object by tconnectsync, and uploads all data newer than that.\n* Queries Nightscout for the most recently created Bolus object by tconnectsync, and uploads all data newer than that.\n* Uploads a single Nightscout Activity object representing the current IOB as reported by the pump.\n\nIf run with the `--auto-update` flag, then the application performs the following steps:\n\n* Queries an API endpoint used only by the t:connect mobile app which returns an internal event ID, corresponding to the most recent event published by the mobile app.\n* Whenever the internal event ID changes (denoting that the mobile app uploaded new data to synchronize), perform all of the above mentioned steps to synchronize data.\n\n### Running with Pipenv\n\nYou can run the application using Pipenv. Assuming you have only Python 3 and pip installed, install pipenv with `pip3 install pipenv`. Then install tconnectsync's dependencies with `pipenv install`, and you can launch the program with `pipenv run tconnectsync` (which, through an alias defined in `Pipfile`, runs ``pipenv run python3 main.py`).\n\n```bash\n$ git clone https://github.com/jwoglom/tconnectsync && cd tconnectsync\n$ pip3 install pipenv\n$ pipenv install\n$ pipenv run tconnectsync --help\nusage: main.py [-h] [--pretend] [--start-date START_DATE] [--end-date END_DATE]\n               [--days DAYS] [--auto-update]\n\nSyncs bolus, basal, and IOB data from Tandem Diabetes t:connect to Nightscout.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --pretend             Pretend mode: do not upload any data to Nightscout.\n  --start-date START_DATE\n                        The oldest date to process data from. Must be specified with\n                        --end-date.\n  --end-date END_DATE   The newest date to process data until (inclusive). Must be\n                        specified with --start-date.\n  --days DAYS           The number of days of t:connect data to read in. Cannot be\n                        used with --from-date and --until-date.\n  --auto-update         If set, continuously checks for updates from t:connect and\n                        syncs with Nightscout.\n```\n\nYou can now continue to either the **Running with Cron** or **Running with Supervisord** sections.\n\n### Running with Docker\n\nFirst, [ensure that you have Docker running and installed](https://docs.docker.com/get-started/#download-and-install-docker).\n\nTo download and run the `jwoglom/tconnectsync` prebuilt Docker image from [Docker Hub](https://hub.docker.com/r/jwoglom/tconnectsync):\n\n```bash\n$ docker pull jwoglom/tconnectsync:latest\n$ docker run jwoglom/tconnectsync --help\n```\n\nTo instead build the image locally and launch the project:\n\n```bash\n$ git clone https://github.com/jwoglom/tconnectsync\n$ docker build -t tconnectsync .\n$ docker run tconnectsync --help\n```\n\nYou can now continue to either the **Running with Cron** or **Running with Supervisord** sections.\n\n### Running with Supervisord (recommended)\nTo instead configure tconnectsync to run continuously in the background using its `--auto-update` feature, you can use a tool such as Supervisord. Here is an example `tconnectsync.conf` which you can place inside `/etc/supervisor/conf.d`:\n\n```\n[program:tconnectsync]\ncommand=/path/to/tconnectsync/run.sh\ndirectory=/path/to/tconnectsync/\nstderr_logfile=/path/to/tconnectsync/stderr.log\nstdout_logfile=/path/to/tconnectsync/stdout.log\nuser=tconnectsync\nnumprocs=1\nautostart=true\nautorestart=true\n```\n\nAn example `run.sh` which launches tconnectsync within its pipenv-configured virtual environment:\n\n```bash\n#!/bin/bash\n\nPIPENV=/home/$(whoami)/.local/bin/pipenv\nVENV=$($PIPENV --venv)\n\nsource $VENV/bin/activate\n\ncd /path/to/tconnectsync\nexec python3 -u main.py --auto-update\n```\n\nAn example `run.sh` which uses Docker:\n\n```bash\n#!/bin/bash\n\ndocker build -t tconnectsync\ndocker run tconnectsync --auto-update\n```\n\n### Running with Cron\nTo configure tconnectsync to run at a periodic interval (i.e. every 15 minutes), you can just invoke main.py with no arguments via cron.\n\nIf using Pipenv or a virtualenv, make sure that you either prefix the call to main.py with `pipenv run` or source the `bin/activate` file within the virtualenv, so that the proper dependencies are loaded. If not using any kind of virtualenv, you can instead just install the necessary dependencies as specified inside Pipfile globally.\n\nAn example configuration in `/etc/crontab` which runs every 15 minutes:\n\n```bash\n# m         h  dom mon dow user   command\n0,15,30,45  *  *   *   *   root   /path/to/tconnectsync/run.sh\n```\n\nYou can use one of the same `run.sh` files mentioned above in the Supervisord example, but remove the `--auto-update` flag since you are handling the functionality for running the script periodically yourself.\n\n## Backfilling t:connect Data\n\nTo backfill existing t:connect data in to Nightscout, you can use the `--start-date` and `--end-date` options. For example, the following will upload all t:connect data between January 1st and March 1st, 2020 to Nightscout:\n\n```\npython3 main.py --start-date 2020-01-01 --end-date 2020-03-01\n```\n\nIn order to bulk-import a lot of data, you may need to use shorter intervals, and invoke tconnectsync multiple times. Tandem's API endpoints occasionally return invalid data if you request too large of a data window which causes tconnectsync to error out mid-way through.\n\nOne oddity when backfilling data is that the Control:IQ specific API endpoints return errors if they are queried before you updated your pump to utilize Control:IQ. This is [partially worked around in tconnectsync's code](https://github.com/jwoglom/tconnectsync/blob/d841c3811aeff3671d941a7d3ff4b80cce6a219e/main.py#L238), but you might need to update the logic if you did not switch to a Control:IQ enabled pump immediately after launch.\n",
  "permissions": {
    "read": true,
    "write": false,
    "admin": false
  },
  "media_types": [
    "application/vnd.docker.container.image.v1+json"
  ],
  "content_types": [
    "image"
  ]
}