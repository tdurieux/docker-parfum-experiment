{
  "user": "bchew",
  "name": "dynamodump",
  "namespace": "bchew",
  "repository_type": "image",
  "status": 1,
  "status_description": "active",
  "description": "Simple backup and restore for Amazon DynamoDB using AWS SDK for Python (boto3)",
  "is_private": false,
  "is_automated": true,
  "can_edit": false,
  "star_count": 1,
  "pull_count": 6523,
  "last_updated": "2023-01-01T06:32:24.356153Z",
  "date_registered": "2018-01-28T04:00:58.35483Z",
  "collaborator_count": 0,
  "affiliation": null,
  "hub_user": "bchew",
  "has_starred": false,
  "full_description": "# dynamodump\n\n![Build Status](https://github.com/bchew/dynamodump/actions/workflows/build.yml/badge.svg)\n![CodeQL Status](https://github.com/bchew/dynamodump/actions/workflows/codeql-analysis.yml/badge.svg)\n[![Docker Status](https://github.com/bchew/dynamodump/actions/workflows/docker.yml/badge.svg)](https://hub.docker.com/r/bchew/dynamodump)\n![Linting Status](https://github.com/bchew/dynamodump/actions/workflows/linting.yml/badge.svg)\n![Test Status](https://github.com/bchew/dynamodump/actions/workflows/test.yml/badge.svg)\n[![PyPI version](https://img.shields.io/pypi/v/dynamodump)](https://pypi.org/project/dynamodump)\n[![PyPI pyversions](https://img.shields.io/pypi/pyversions/dynamodump.svg)](https://pypi.org/project/dynamodump)\n![Code Style](https://img.shields.io/badge/code%20style-black-black)\n\nSimple backup and restore script for Amazon DynamoDB using AWS SDK for Python (boto3) to work similarly to mysqldump.\n\nSuitable for DynamoDB usages of smaller data volume which do not warrant the usage of AWS Data Pipeline for backup/restores/empty.\n\ndynamodump supports local DynamoDB instances as well (tested with [DynamoDB Local](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html)).\n\n\n## Table of Contents\n\n- [Installation](#installation)\n- [Usage](#usage)\n- [Script (unattended) usage](#script-unattended-usage)\n- [Docker CLI usage](#docker-cli-usage)\n- [AWS example](#aws-example)\n- [Local example](#local-example)\n- [Development](#development)\n\n## Installation\n\n```\npip install dynamodump\n```\n\n## Usage\n\n```\nusage: dynamodump [-h] [-a {zip,tar}] [-b BUCKET]\n                     [-m {backup,restore,empty}] [-r REGION] [--host HOST]\n                     [--port PORT] [--accessKey ACCESSKEY]\n                     [--secretKey SECRETKEY] [-p PROFILE] [-s SRCTABLE]\n                     [-d DESTTABLE] [--prefixSeparator PREFIXSEPARATOR]\n                     [--noSeparator] [--readCapacity READCAPACITY] [-t TAG]\n                     [--writeCapacity WRITECAPACITY] [--schemaOnly]\n                     [--dataOnly] [--noConfirm] [--skipThroughputUpdate]\n                     [--dumpPath DUMPPATH] [--log LOG]\n\nSimple DynamoDB backup/restore/empty.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -a {zip,tar}, --archive {zip,tar}\n                        Type of compressed archive to create.If unset, don't\n                        create archive\n  -b BUCKET, --bucket BUCKET\n                        S3 bucket in which to store or retrieve backups.[must\n                        already exist]\n  -m {backup,restore,empty}, --mode {backup,restore,empty}\n                        Operation to perform\n  -r REGION, --region REGION\n                        AWS region to use, e.g. 'us-west-1'. Can use\n                        AWS_DEFAULT_REGION for local testing. Use 'local' for\n                        local DynamoDB testing\n  --host HOST           Host of local DynamoDB [required only for local]\n  --port PORT           Port of local DynamoDB [required only for local]\n  --accessKey ACCESSKEY\n                        Access key of local DynamoDB [required only for local]\n  --secretKey SECRETKEY\n                        Secret key of local DynamoDB [required only for local]\n  -p PROFILE, --profile PROFILE\n                        AWS credentials file profile to use. Allows you to use\n                        a profile instead accessKey, secretKey authentication\n  -s SRCTABLE, --srcTable SRCTABLE\n                        Source DynamoDB table name to backup or restore from,\n                        use 'tablename*' for wildcard prefix selection or '*'\n                        for all tables. Mutually exclusive with --tag\n  -d DESTTABLE, --destTable DESTTABLE\n                        Destination DynamoDB table name to backup or restore\n                        to, use 'tablename*' for wildcard prefix selection\n                        (defaults to use '-' separator) [optional, defaults to\n                        source]\n  --prefixSeparator PREFIXSEPARATOR\n                        Specify a different prefix separator, e.g. '.'\n                        [optional]\n  --noSeparator         Overrides the use of a prefix separator for backup\n                        wildcard searches [optional]\n  --readCapacity READCAPACITY\n                        Change the temp read capacity of the DynamoDB table to\n                        backup from [optional]\n  -t TAG, --tag TAG     Tag to use for identifying tables to back up. Mutually\n                        exclusive with srcTable. Provided as KEY=VALUE\n  --writeCapacity WRITECAPACITY\n                        Change the temp write capacity of the DynamoDB table\n                        to restore to [defaults to 25, optional]\n  --schemaOnly          Backup or restore the schema only. Do not\n                        backup/restore data. Can be used with both backup and\n                        restore modes. Cannot be used with the --dataOnly\n                        [optional]\n  --dataOnly            Restore data only. Do not delete/recreate schema\n                        [optional for restore]\n  --noConfirm           Don't ask for confirmation before deleting existing\n                        schemas.\n  --skipThroughputUpdate\n                        Skip updating throughput values across tables\n                        [optional]\n  --dumpPath DUMPPATH   Directory to place and search for DynamoDB table\n                        backups (defaults to use 'dump') [optional]\n  --log LOG             Logging level - DEBUG|INFO|WARNING|ERROR|CRITICAL\n                        [optional]\n```\n\nBackup files are stored in a 'dump' subdirectory, and are restored from there as well by default.\n\n## Script (unattended) usage\n\nAs of v1.2.0, note that `--noConfirm` is required to perform data restores involving deletions without any confirmation.\n\n## Docker CLI usage\n\n```\ndocker run --rm -it bchew/dynamodump -h\n```\n\n## AWS example\n\nSingle table backup/restore:\n\n```\ndynamodump -m backup -r us-west-1 -s testTable\n\ndynamodump -m restore -r us-west-1 -s testTable\n```\n\nMultiple table backup/restore (assumes prefix of 'production-' of table names, use --prefixSeparator to specify a\ndifferent separator):\n\n```\ndynamodump -m backup -r us-west-1 -s production*\n\ndynamodump -m restore -r us-west-1 -s production*\n```\n\nThe above, but between different environments (e.g. production-_ tables to development-_ tables):\n\n```\ndynamodump -m backup -r us-west-1 -s production*\n\ndynamodump -m restore -r us-west-1 -s production* -d development*\n```\n\nBackup all tables and restore only data (will not delete and recreate schema):\n\n```\ndynamodump -m backup -r us-west-1 -s \"*\"\n\ndynamodump -m restore -r us-west-1 -s \"*\" --dataOnly\n```\n\nDump all table schemas and create the schemas (e.g. creating blank tables in a different AWS account):\n\n```\ndynamodump -m backup -r us-west-1 -p source_credentials -s \"*\" --schemaOnly\n\ndynamodump -m restore -r us-west-1 -p destination_credentials -s \"*\" --schemaOnly\n```\n\nBackup all tables based on AWS tag `key=value`\n\n```\ndynamodump -p profile -r us-east-1 -m backup -t KEY=VALUE\n```\n\nBackup all tables based on AWS tag, compress and store in specified S3 bucket.\n\n```\ndynamodump -p profile -r us-east-1 -m backup -a tar -b some_s3_bucket -t TAG_KEY=TAG_VALUE\n\ndynamodump -p profile -r us-east-1 -m backup -a zip -b some_s3_bucket -t TAG_KEY=TAG_VALUE\n```\n\nRestore from S3 bucket to specified destination table\n\n```\n## source_table identifies archive file in S3 bucket from which backup data is restored\ndynamodump -a tar -b some_s3_bucket -m restore -r us-east-1 -p profile -d destination_table -s source_table\n```\n\n## Local example\n\nThe following assumes your local DynamoDB is running on localhost:8000 and is accessible via 'a' as access/secret keys.\n\n```\ndynamodump -m backup -r local -s testTable --host localhost --port 8000 --accessKey a --secretKey a\n\ndynamodump -m restore -r local -s testTable --host localhost --port 8000 --accessKey a --secretKey a\n```\n\nMultiple table backup/restore as stated in the AWS examples are also available for local.\n\n## Development\n\n```\npython3 -m venv env\nsource env/bin/activate\n\n# install dev requirements\npip3 install -r requirements-dev.txt\n\n# one-time install of pre-commit hooks\npre-commit install\n```\n",
  "permissions": {
    "read": true,
    "write": false,
    "admin": false
  },
  "media_types": [
    "application/vnd.docker.distribution.manifest.list.v2+json",
    "application/vnd.docker.container.image.v1+json"
  ],
  "content_types": [
    "image"
  ]
}