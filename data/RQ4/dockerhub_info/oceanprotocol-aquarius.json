{
  "user": "oceanprotocol",
  "name": "aquarius",
  "namespace": "oceanprotocol",
  "repository_type": "image",
  "status": 1,
  "status_description": "active",
  "description": "üêã Ocean Metadata API ",
  "is_private": false,
  "is_automated": true,
  "can_edit": false,
  "star_count": 0,
  "pull_count": 172558,
  "last_updated": "2023-01-06T08:25:38.344011Z",
  "date_registered": "2018-10-24T10:06:17.978457Z",
  "collaborator_count": 0,
  "affiliation": null,
  "hub_user": "oceanprotocol",
  "has_starred": false,
  "full_description": "<!--\nCopyright 2021 Ocean Protocol Foundation\nSPDX-License-Identifier: Apache-2.0\n-->\n[![banner](https://raw.githubusercontent.com/oceanprotocol/art/master/github/repo-banner%402x.png)](https://oceanprotocol.com)\n\n[![Aquarius tests](https://github.com/oceanprotocol/aquarius/actions/workflows/pytest.yml/badge.svg)](https://github.com/oceanprotocol/aquarius/actions/workflows/pytest.yml)\n[![black](https://github.com/oceanprotocol/aquarius/actions/workflows/black.yml/badge.svg)](https://github.com/oceanprotocol/aquarius/actions/workflows/black.yml)\n[![Docker Build Status](https://img.shields.io/docker/cloud/build/oceanprotocol/aquarius.svg)](https://hub.docker.com/r/oceanprotocol/aquarius/)\n[![Maintainability](https://api.codeclimate.com/v1/badges/411b97f9749f9dcac801/maintainability)](https://codeclimate.com/github/oceanprotocol/aquarius/maintainability)\n[![Test Coverage](https://api.codeclimate.com/v1/badges/411b97f9749f9dcac801/test_coverage)](https://codeclimate.com/github/oceanprotocol/aquarius/test_coverage)\n[![PyPI](https://img.shields.io/pypi/v/ocean-aquarius.svg)](https://pypi.org/project/ocean-aquarius/)\n[![GitHub contributors](https://img.shields.io/github/contributors/oceanprotocol/aquarius.svg)](https://github.com/oceanprotocol/aquarius/graphs/contributors)\n\n# Aquarius\n\n* [What is Aquarius?](#what-is-aquarius)\n   * [How is metadata treated?](#how-is-metadata-treated)\n   * [Components and architecture](#components-and-architecture)\n      * [The Aquarius API](#the-aquarius-api)\n      * [The EventsMonitor](#the-eventsmonitor)\n* [Aquarius Setup](#aquarius-setup)\n   * [Running Aquarius for multiple chains](#running-aquarius-for-multiple-chains)\n* [Using Aquarius](#using-aquarius)\n   * [Quickstart](#quickstart)\n   * [Learn about Aquarius API](#learn-about-aquarius-api)\n   * [Running Aquarius locally](#running-aquarius-locally)\n   * [Development](#development)\n* [License](#license)\n\n# What is Aquarius?\n\nAquarius is an off-chain, multi-chain cache for metadata that is published on chain, connected to an Elasticsearch database. Aquarius continually monitors the chains for MetadataCreated and MetadataUpdated events, processes these events and adds them to the database. The Aquarius API offers a convenient way to access the medatata without scanning the chain yourself.\n\nAquarius is part of the [Ocean Protocol](https://oceanprotocol.com) toolset. üåä\n\n## How is metadata treated?\n\nThe metadata is published on-chain as such:\n\n* Metadata is first (optionally) compressed (using lzma) and (strongly recommended) encrypted, then published on-chain\n* The metadata on-chain is not kept in storage, but rather is captured in an event log named `MetadataCreated`\n* Aquarius defers to the Provider for encryption and decryption. Aquarius and Provider support utf-8 encoded strings. You can look into the encrypt/decrypt flows if you want to learn more, but you will generally not need to go in-depth just to use Aquarius.\n\nFor more details on working with OCEAN DIDs check out the [DID concept documentation](https://docs.oceanprotocol.com/core-concepts/did-ddo/).\nThe [DDO Metadata documentation](https://docs.oceanprotocol.com/core-concepts/did-ddo#metadata) goes into more depth regarding metadata structure.\n\n## Components and architecture\n\nAquarius is a simple, lightweight scanner and API. It is built using Python, using the Flask framework.\n\n### The Aquarius API\n\nAquarius provides REST api to fetch the data from off-chain datastore.\nPlease refer to [API.md](API.md) file for details on the API itself.\n\n### The EventsMonitor\n\nThe events monitor runs continuously to retrieve and index the chain Metadata. It saves the results into an Elasticseach database. The monitor reads the events `data` argument, decompresses the metadata json object, then runs schema validation before saving it to the database. The monitor is highly customisable, and it consists of the following components:\n\n- an ElasticsearchInstance, configured through env variables\n- an associated MetadataContract, configured through the `METADATA_CONTRACT_ADDRESS` env variable\n- a Decryptor class that handles decompression and decryption on the chain data, through communication with Provider\n- a set of `ALLOWED_PUBLISHERS`, if such a restriction exists. You can set a limited number of allowed publisher addresses using this env variable.\n- a Purgatory, based on the `ASSET_PURGATORY_URL` and `ACCOUNT_PURGATORY_URL` env variables. These mark some assets as being in purgatory (`\"isInPurgatory\": True`), enabling restrictions for some assets or accounts.\n- a VeAllocate, based on the `VEALLOCATE_URL` and `VEALLOCATE_UPDATE_INTERVAL` env variables. This updates the veAllocation for datasets.\n- start blocks, if such defined using `BFACTORY_BLOCK` and `METADATA_CONTRACT_BLOCK`. These start blocks are coroborated with the last stored blocks per Elasticsearch, to avoid indexing multiple times\n\nThe EventsMonitor processes block chunks as defined using `BLOCKS_CHUNK_SIZE`. For each block, it retrieves all `MetadataCreated` and `MetadataUpdated` events, and these events are processed inside the `MetadataCreatedProcessor` and `MetadataUpdatedProcessor` classes. These processors run the following flow:\n\n- optionally check permissions with the `RBAC_SERVER_URL` and `ALLOWED_PUBLISHERS`\n- decompresses and optionally decrypts the asset metadata\n- checks whether the asset needs to be sent to purgatory\n- creates the JSON record and saves it in Elasticsearch\n- if a `MetadataUpdated` event is detected on an asset that does not exist in Elasticsearch already, then it is treated as a `MetadataCreated` event.\n\n# Aquarius Setup\nThe following environment variables are required for running Aquarius:\n\n```\n# URL of ethereum network.\n# Recommendation: when connecting to an official network, create an Infura project id and set this\n# to use the Infura url including the project id\nEVENTS_RPC\n  examples:\n  \"http://172.15.0.3:8545\", \"wss://rinkeby.infura.io/ws/v3/INFURA_ID\"\n\n# Use this to run the EventsMonitor in a thread from the main Flask app\nEVENTS_ALLOW\n  accepted values:\n    \"0\" to disable\n    \"1\" to enable\n\n# Run the EventsMonitor in a separate process, overrides `EVENTS_ALLOW`.\n# This is only used when running in `docker` container\nRUN_EVENTS_MONITOR\n  accepted values:\n    \"0\" to disable\n    \"1\" to enable\n\n# Start a HTTP server inside the events monitor. This is useful for K8 live probing. You must simply access the root endpoint on port 5001. IE: http://172.0.0.1:5001 which will respond with 200 OK if the events thread is up.  Otherwise, there will be no response\nEVENTS_HTTP\n  accepted values:\n    \"1\" to enable\n```\nAnd these are optional\n```bash\n# Enables the Aquarius API. Default: 1, disable if you only want to use the events monitor, without exposing an API.\nRUN_AQUARIUS_SERVER\n\n# Identify instance of Aquarius to Provider, when decrypting assets. Provider may allow or deny decryption based on this address.\nPRIVATE_KEY\n\n# Path to the `address.json` file or any json file that has the deployed contracts addresses\nADDRESS_FILE\n\n# Specify the network name to use for reading the contracts addresses from the `ADDRESS_FILE`.\n# If not set, the network name is derived from current network id or from the `EVENTS_RPC` value, by splitting out the wss://, http:// or https:// part and the suffixes\nNETWORK_NAME\n\n# Restrict metadata caching to publishers in this list. It is a list of publisher addresses.\nALLOWED_PUBLISHERS\n\n# Metadata contract address. Use it if you want to overwrite values from ocean-contracts\nMETADATA_CONTRACT_ADDRESS\n\n# The block number of `Metadata` contract deployment\nMETADATA_CONTRACT_BLOCK\n\n# Enable the use of poa_middleware if the network is a POA network such as Rinkeby. (no need to set for rinkeby specifically, since that is already treated in the code, but any other POA network should have this flag setup)\nUSE_POA_MIDDLEWARE\n\n# if set to 1, read events from the first Metadata and BFactory block number, or a specific block number (used for debugging)\nIGNORE_LAST_BLOCK\n\n# When scanning for events, limit the chunk size. Infura accepts 10k blocks, but others will take only 1000 (default value)\nBLOCKS_CHUNK_SIZE\n\n# URLs of asset purgatory and account purgatory. If neither exists, the purgatory will not be processed. The list should be formatted as a list of dictionaries containing the address and reason. See https://github.com/oceanprotocol/list-purgatory/blob/main/list-accounts.json for an example\n# IMPORTANT.  If you are running multiple aquarius event monitors (for multiple chains), make sure that only one event-monitor will handle purgatory\nASSET_PURGATORY_URL\nACCOUNT_PURGATORY_URL\n\n# Customise purgatory update (refresh) time (in number of minutes)\nPURGATORY_UPDATE_INTERVAL\n\n# URL for getting the veAllocation list. If not exists, the veAllocate will not be processed. Possible values are: https://df-sql.oceandao.org/nftinfo for mainnet and https://test-df-sql.oceandao.org/nftinfo for goerli, because veOCEAN is deployed only on this networks. All other networks SHOULD NOT HAVE this defined.  The list should be formatted as a list of dictionaries containing chainID,nft_addr and ve_allocated\nVEALLOCATE_URL\n\n# Customise veAllocate update (refresh) time (in number of minutes)\nVEALLOCATE_UPDATE_INTERVAL\n\n# The URL of the RBAC Permissions Server. If set, Aquarius will check permissions with RBAC. Leave empty/unset to skip RBAC permission checks.\nRBAC_SERVER_URL\n\n# Whether to start clean and reindex events on chain id\nEVENTS_CLEAN_START\n\n# Subgraph URLs in the form of a json-dumped string mapping chain_ids to subgraph urls.\nSUBGRAPH_URLS\n\n# Process a queue with failed assets, e.g. retry where temporary network flukes or similar conditions caused a failure\nPROCESS_RETRY_QUEUE\n\n# For how long to retry such an event, before giving up. Defaults to 2 weeks\nPROCESS_RETRY_MAX_HOLD\n\n# Customize sleep time for events monitor between checking for new events. Defaults to 30 seconds\nEVENTS_MONITOR_SLEEP_TIME\n# Customize sleep time for events monitor between queue processing. Defaults to 60 seconds\nEVENTS_PROCESS_QUEUE_SLEEP_TIME\n# Customize sleep time for events monitor between updating ve_allocate. Defaults to 300 seconds\nEVENTS_VE_ALLOCATE_SLEEP_TIME\n# Customize sleep time for events monitor between checking for nft transfers. Defaults to 300 seconds\nEVENTS_NFT_TRANSFER_SLEEP_TIME\n# Customize sleep time for events monitor between checking for purgatory lists. Defaults to 300 seconds\nEVENTS_PURGATORY_SLEEP_TIME\n```\n## Running Aquarius for multiple chains\n\nIf you want to index multiple chains using a single Aquarius instance, that is possible. The OCEAN version of Aquarius uses this exact flow. To enable multi-chain indexing, these are the necessary steps:\n * Run one or more pods, with `RUN_AQUARIUS_SERVER=1` , `RUN_EVENTS_MONITOR=0` and `EVENTS_ALLOW=0`.  This basically enables only the API part of Aquarius.\n * For each chain, start a pod with the following env variables:\n     * Set `RUN_EVENTS_MONITOR=1` and `RUN_AQUARIUS_SERVER=0` (run only the EventsMonitor part of Aquarius)\n     * Set coresponding `EVENTS_RPC`, `NETWORK_NAME`, `BLOCKS_CHUNK_SIZE`, `METADATA_CONTRACT_BLOCK`, `METADATA_CONTRACT_ADDRESS` etc.\n\nA list of deployment values and schematics [can be found here](https://github.com/oceanprotocol/aquarius/tree/main/deployment)\n\nVoil√†! You are now running a multi-chain Aquarius.\n\n# Using Aquarius\n\n## Quickstart\n\nIf you're developing a marketplace, you'll want to run Aquarius and several other components locally. The easiest way to do that is to use Barge. See the instructions in [the Barge repository](https://github.com/oceanprotocol/barge).\n\n## Learn about Aquarius API\n\n[Here](https://docs.oceanprotocol.com/api-references/aquarius-rest-api) is API documentation. You can find more details about the ontology of the metadata in the [Ocean documentation](https://docs.oceanprotocol.com/core-concepts/did-ddo#metadata).\n\nIf you have Aquarius running locally, you can find a Swagger API documentation at [http://localhost:5000/api/docs](http://localhost:5000/api/docs) or maybe [http://0.0.0.0:5000/api/docs](http://0.0.0.0:5000/api/docs).\n\n- Tip 1: If that doesn't work, then try `https`.\n- Tip 2: If your browser shows the Swagger header across the top but says \"Failed to load spec.\" then we found that, in Chrome, if we went to `chrome://flags/#allow-insecure-localhost` and toggled it to Enabled, then relaunched Chrome, it worked.\n\n## Running Aquarius locally\n\nFor testing purposes, running Aquarius from [barge](https://github.com/oceanprotocol/barge/) should suffice, but if you want to run your own version of Aquarius (with any configurations or alterations), you can do that by following the instructions in [the developers documentation](developers.md).\n\n## Development\n\nIf you want to improve or customise Aquarius, you're our favourite kind of person! Go to [the developers flow](developers.md) to learn more about how you can contribute.\n\n# License\n\nCopyright 2022 Ocean Protocol Foundation Ltd.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n",
  "permissions": {
    "read": true,
    "write": false,
    "admin": false
  },
  "media_types": [
    "application/vnd.docker.container.image.v1+json"
  ],
  "content_types": [
    "image"
  ]
}