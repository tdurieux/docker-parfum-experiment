{
  "user": "rackhd",
  "name": "on-taskgraph",
  "namespace": "rackhd",
  "repository_type": "image",
  "status": 1,
  "status_description": "active",
  "description": "Workflow engine for RackHD",
  "is_private": false,
  "is_automated": true,
  "can_edit": false,
  "star_count": 1,
  "pull_count": 1397080,
  "last_updated": "2018-07-12T19:17:14.150526Z",
  "date_registered": "2016-02-05T23:24:07.893124Z",
  "collaborator_count": 0,
  "affiliation": null,
  "hub_user": "rackhd",
  "has_starred": false,
  "full_description": "# on-taskgraph [![Build Status](https://travis-ci.org/RackHD/on-taskgraph.svg?branch=master)](https://travis-ci.org/RackHD/on-taskgraph) [![Code Climate](https://codeclimate.com/github/RackHD/on-taskgraph/badges/gpa.svg)](https://codeclimate.com/github/RackHD/on-taskgraph) [![Coverage Status](https://coveralls.io/repos/RackHD/on-taskgraph/badge.svg?branch=master&service=github)](https://coveralls.io/github/RackHD/on-taskgraph?branch=master)\n\n'on-taskgraph' is the core workflow engine for RackHD, initiating workflows, performing tasks, and responding to ancillary services to enable the RackHD service.\n\nFor more in-depth information about the workflow engine [see our readthedocs page](http://rackhd.readthedocs.org/en/latest/rackhd/graphs.html?workflow-graphs).\n\nCopyright 2015-2016, EMC, Inc.\n\n## installation/setup\n\n    npm install\n\n    # For Linux\n    apt-get install mongodb\n    apt-get install rabbitmq-server\n\n    # If on OSX, see http://brew.sh/ if brew is not installed\n    brew install mongodb26\n    brew install rabbitmq\n\n## running\n\n*NOTE: requires RabbitMQ and Mongo to be running to start and test correctly.*\n\nThis project can be run in one of three possible modes, [scheduler mode](#scheduler-mode), [task runner mode](#task-runner-mode), and [hybrid mode](#hybrid-mode):\n\nIf no mode is specified, it will run in [hybrid mode](#hybrid-mode) by default:\n\n    node index.js\n\nTo run in [scheduler mode](#scheduler-mode):\n\n    node index.js --scheduler\n    # OR\n    node index.js -s\n\nTo run in [task runner mode](#task-runner-mode):\n\n    node index.js --runner\n    # OR\n    node index.js -r\n\nTo run a process within a [domain](#domains):\n\n    node index.js <other args> --domain <domainname>\n    # OR\n    node index.js <other args> -d <domainname>\n\n**Which mode should I run in?**\n\nFirst, read the [descriptions of each mode](#modesconfigurations) below. Here are some guidelines for making this decision:\n\n*If you have no concerns about fault tolerance or high performance. You are a normal user.*\n\n- Run a single process in hybrid mode\n\n*If you want to optimize for performance and speedy processing of a large volume of workflows*\n\n- Run one process in Scheduler mode, and multiple processes in Task Runner mode. Make sure you create mongo indexes as detailed [above](#installationsetup).\n\n*If you want to optimize for high availability*\n\n- Run two processes in Scheduler mode (potentially on different machines) and run multiple processes in Task Runner mode (again distributing across machines if desired).\n- This project achieves high availability by relying on access to highly available mongo database, so mongo must be run in a highly available configuration.\n\n*If you want some degree of fault tolerance but don't care so much about 100% uptime (you can afford a few seconds of downtime on failure)*\n\n- Run one process in Scheduler mode, and one or multiple processes in Task Runner mode. Coordinate these processes with a service manager to quickly restart them when they crash.\n- Run mongo in a redundant configuration for higher degrees of fault tolerance.\n\nTo interact with the system externally, e.g. running graphs against live systems, you need to be running the following RackHD services:\n\n- [on-http](https://github.com/RackHD/on-http/) (mandatory for all)\n- [on-dhcp-proxy](https://github.com/RackHD/on-dhcp-proxy/) (mandatory for node graphs)\n- [on-tftp](https://github.com/RackHD/on-tftp/) (mandatory for node booting graphs)\n\nIn addition, the system requires MongoDB, ISC DHCP, and RabbitMQ to be running and configured appropriately to enable PXE booting. More information is\navailable in the documentation for RackHD at http://rackhd.readthedocs.org\n\n## Overview\n\nThis project provides functionality for running encapsulated jobs/units of work via\ngraph-based control flow mechanisms. For example, a typical graph consists of a list of\ntasks, which themselves are essentially decorated functions. The graph definition specifies\nany context and/or option values that should be handed to these functions, and more importantly,\nit provides a mechanism for specifying when each task should be run. The most simple case is\nsaying a task should be run only after a previous task has succeeded (essentially becoming a\nstate machine). More complex graphs may involve event based task running, or defining\ndata/event channels that should exist between concurrently running tasks.\n\n**Some architectural notes**\n\nThis project is designed to be able to be run with any number of workflow processes active at any time for performance and high availability reasons. \nWorkflow processes can be configured to handle different domains of tasks, and can be machine independent as long as the database and messaging are shared.\n\n*Atomic checkout*: All eligible Task Runners will receive requests to run tasks, but only one will succeed in checking out a lease to handle that request. Somewhat like a leased queue model, leveraging existing database technologies (currently MongoDB).\n\n*Lease heartbeating*: Task Runner instances heartbeat their owned tasks, so that other instances can check them out on timed out heartbeats or process failures.\n\n*Backup mechanisms for dropped events*: The primary mechanism for driving workflow execution is AMQP messaging, but on the case of failures or missed events, there are also database pollers that queue up dropped events for re-evaluation (dropped events can happen under high load throttling and process failure conditons).\n\n*Stateless*: Horizontal scalability is achieved by designing the processes to run in essentially a stateless mode. The last word is from the database.\n\n## Modes/Configurations\n\n### Scheduler mode\n\nIn Scheduler mode the process will only take responsibility for evaluating workflow graphs and queuing tasks to be run by task runners.\n\n### Task Runner mode\n\nIn Task Runner mode the process will listen/poll for queued tasks, and check them out to be run. It is in Task Runner mode that the the actual job code is executed.\n\n### Hybrid mode\n\nHybrid mode runs both the Task Scheduler and Task Runner modes within one process.\n\n### Domains\n\nDomains allow for running a workflow process that only handles a subset of workflows and tasks, i.e. those within its domain. For example, you could run a workflow\non a specific network segment that handles all workflows for a subset of machines:\n\n    node index.js --domain cluster1\n\nIf you then schedule workflows within the cluster1 domain, only this workflow process with network access to the machines will run those workflows.\n\nDomains can also be useful under high load when certain classes of workflows need to be prioritized, such that a process or set of processes can be run\nin a dedicated fashion only for that class of workflows.\n\n## API commands\n\nWhen running the on-http process, these are some common API commands you can send:\n\nNote: Can use `/api/2.0` as well unless there is an explicit 2.0 API example\n\n**Get available graphs**\n\n```\nGET\n/api/1.1/workflows/library\n```\n\n**Run a new graph against a node**\n\nFind the graph definition you would like to use, and copy the top-level *injectableName* attribute\n\n```\nPOST\n/api/1.1/nodes/<id>/workflows\n{\n    name: <graph name>\n}\n```\n\n**Run a new graph not linked to a node**\n\nFind the graph definition you would like to use, and copy the top-level *injectableName* attribute\n\n```\nPOST\n/api/1.1/workflows\n{\n    name: <graph name>\n}\n```\n\n**Run a new graph within a domain**\n\nFind the graph definition you would like to use, and copy the top-level *injectableName* attribute\n\n```\nPOST\n/api/1.1/workflows OR /api/1.1/nodes/<id>/workflows\n{\n    name: <graph name>,\n    domain: <domain name>\n}\n```\n\nThis will return a serialized graph object.\n\n**Query an active graph's state**\n\n```\nGET\n/api/1.1/nodes/<id>/workflows/active\n```\n\n**2.0 API to list active workflow running against the node\n\n```\nGET\n/api/2.0/nodes/<id>/workflows?active=true\n```\n\n**Create a new graph definition**\n\n```\nPUT\n/api/1.1/workflows\n{\n    <json definition of graph>\n}\n```\n\n### Creating new graphs\n\nFor more detailed information, see our [readthedocs page](http://rackhd.readthedocs.org/en/latest/rackhd/graphs.html?workflow-graphs).\n\nGraph definition files must be saved as javascript or json files in `./lib/graphs/` (nested directories are okay), and filenames must match the pattern \n`*-graph.js` or `*-graph.json`. If a graph is saved as a `.js` file, it should export a javascript object conforming to the graph definition schema.\nIf a graph is saved as a `.json` file, it must be valid json.\n\nGraph definitions can alternatively be uploaded through the API as detailed above in [API commands](#api-commands).\n\nGraphs are defined via a JSON definition that conform to this schema:\n\n- friendlyName (string): a human readable name for the graph\n- injectableName (string): a unique name used by the system and the API to refer to the graph\n- tasks (array of objects): a list of task definitions or references to task definitions. For an in-depth explanation\n        of task definitions, see [the on-tasks README](https://hwstashprd01.isus.emc.com:8443/projects/ONRACK/repos/on-tasks/browse/README.md)\n    - tasks.label (string): a unique string to be used as a reference within the graph definition\n    - tasks.\\[taskName\\] (string): the injectableName of a task in the database to run. This or taskDefinition is required.\n    - tasks.\\[taskDefinition\\] (object): an inline definition of a task, instead of one in the database. This or taskName is required.\n    - tasks.\\[ignoreFailure\\] (boolean): ignoreFailure: true will prevent the graph from failing on task failure\n    - tasks.\\[waitOn\\] (object): key, value pairs referencing other task labels to desired states of those tasks to trigger running on.\n                                    Available states are 'succeeded', and 'failed' and 'finished' (run on succeeded or failed). If waitOn\n                                    is not specified, the task will run on graph start.\n- [options]\n    - options.\\[defaults\\] (object): key, value pairs that will be handed to any tasks that have matching option keys\n    - options.\\<label\\> (object): key, value pairs that should all be handed to a specific task\n\n\n## Debugging/Profiling\n\nTo run in debug mode:\n\n    sudo node debug index.js\n\nYou can also set `this.debug = true` in lib/task-scheduler.js and lib/task-runner.js for more verbose logging.\n\nIf you're using Node v4 or greater you can use `node-inspector` to debug and profile from a GUI.\n\n    npm install node-inspector -g\n    node-inspector --preload=false &\n    sudo node --debug-brk index.js\n\nNote: do not use the `node-debug` command it doesn't work as well.\n\n## CI/testing\n\nTo run tests from a developer console:\n\n    npm test\n\nTo run tests and get coverage for CI:\n\n    # verify hint/style\n    ./node_modules/.bin/jshint -c .jshintrc --reporter=checkstyle lib index.js > checkstyle-result.xml || true\n    ./node_modules/.bin/istanbul cover -x \"**/spec/**\" _mocha -- $(find spec -name '*-spec.js') -R xunit-file --require spec/helper.js\n    ./node_modules/.bin/istanbul report cobertura\n    # if you want HTML reports locally\n    ./node_modules/.bin/istanbul report html\n\n## Building\n\nUnversioned packages are built automatically from travis-ci and uploaded to bintray.com. Using\nthis repository is detailed in [the docs](http://rackhd.readthedocs.org/en/latest/rackhd/ubuntu_package_installation.html).\n\nBuild scripts are placed in the `extra/` directory.\n\n  * `.travis.yml` will call the appropriate scripts in `extra/` to build an unversioned package.\n  * `extra/make-sysdeps.sh` can be used to install system level packages in a Ubuntu system.\n  * `extra/make-cicd.sh` will perform all the necessary build steps to generate a version package.\n\nIf you want to build your own versioned packages, you can use the Vagrantfile provided in `extra/`.  Simply perform `vagrant up` and it will run all the necessary steps.\n\n## Licensing\n\nLicensed under the Apache License, Version 2.0 (the “License”); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n\nRackHD is a Trademark of Dell EMC\n",
  "permissions": {
    "read": true,
    "write": false,
    "admin": false
  },
  "media_types": [
    "application/vnd.docker.container.image.v1+json"
  ],
  "content_types": [
    "image"
  ]
}