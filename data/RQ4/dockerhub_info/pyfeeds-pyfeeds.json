{
  "user": "pyfeeds",
  "name": "pyfeeds",
  "namespace": "pyfeeds",
  "repository_type": "image",
  "status": 1,
  "status_description": "active",
  "description": "Automatic builds for PyFeeds",
  "is_private": false,
  "is_automated": false,
  "can_edit": false,
  "star_count": 0,
  "pull_count": 92638,
  "last_updated": "2021-07-12T19:07:52.008715Z",
  "date_registered": "2019-05-12T12:58:42.025745Z",
  "collaborator_count": 0,
  "affiliation": null,
  "hub_user": "pyfeeds",
  "has_starred": false,
  "full_description": "Feeds\n=====\n\n|pypi| |support| |licence|\n\n|readthedocs|\n\n|pyfeedsci|\n\nOnce upon a time every website offered an RSS feed to keep readers updated\nabout new articles/blog posts via the users' feed readers. These times are\nlong gone. The once iconic orange RSS icon has been replaced by \"social share\"\nbuttons.\n\nFeeds aims to bring back the good old reading times. It creates Atom feeds for\nwebsites that don't offer them (anymore). It allows you to read new articles of\nyour favorite websites in your feed reader (e.g. TinyTinyRSS_) even if this is\nnot officially supported by the website.\n\nFurthermore it can also enhance existing feeds by inlining the actual content\ninto the feed entry so it can be read without leaving the feed reader.\n\nFeeds is based on Scrapy_, a framework for extracting data from websites, and\nit's easy to add support for new websites. Just take a look at the existing\nspiders_ and feel free to open a `pull request`_!\n\nDocumentation\n-------------\nFeeds comes with extensive documentation. It is available at\n`https://pyfeeds.readthedocs.io <https://pyfeeds.readthedocs.io/en/latest/>`_.\n\nSupported Websites\n------------------\n\nFeeds is currently able to create full text Atom feeds for various sites. The\ncomplete list of `supported websites is available in the documentation\n<https://pyfeeds.readthedocs.io/en/latest/spiders.html>`_.\n\nContent behind paywalls\n~~~~~~~~~~~~~~~~~~~~~~~\n\nSome sites (Falter_, Konsument_, LWN_, `Oberösterreichische Nachrichten`_,\nÜbermedien_) offer articles only behind a paywall. If you have a paid\nsubscription, you can configure your username and password in ``feeds.cfg`` and\nalso read paywalled articles from within your feed reader. For the less\nfortunate who don't have a subscription, paywalled articles are tagged with\n``paywalled`` so they can be filtered, if desired.\n\nAll feeds contain the articles in full text so you never have to leave your\nfeed reader while reading.\n\nInstallation\n------------\n\nFeeds is meant to be installed on your server and run periodically in a cron\njob or similar job scheduler. We recommend to install Feeds inside a virtual\nenvironment.\n\nFeeds can be installed from PyPI using ``pip``:\n\n.. code-block:: bash\n\n   $ pip install PyFeeds\n\nYou may also install the current development version. The master branch is\nconsidered stable enough for daily use:\n\n.. code-block:: bash\n\n   $ pip install https://github.com/pyfeeds/pyfeeds/archive/master.tar.gz\n\nAfter installation ``feeds`` is available in your virtual environment.\n\nFeeds supports Python 3.7+.\n\nQuickstart\n----------\n\n* List all available spiders::\n\n  $ feeds list\n\n* Feeds allows to crawl one or more spiders without configuration, e.g.::\n\n  $ feeds crawl tvthek.orf.at\n\n* A configuration file is supported too. Simply copy the template configuration\n  and adjust it. Enable the spiders you are interested in and adjust the output\n  path where Feeds stores the scraped Atom feeds::\n\n  $ cp feeds.cfg.dist feeds.cfg\n  $ $EDITOR feeds.cfg\n  $ feeds --config feeds.cfg crawl\n\n* Point your feed reader to the generated Atom feeds and start reading. Feeds\n  works best when run periodically in a cron job.\n* Run ``feeds --help`` or ``feeds <subcommand> --help`` for help and usage\n  details.\n\nCaching\n-------\n\nFeeds caches HTTP responses by default to save bandwidth. Entries are cached\nfor 90 days by default (this can be overwritten in the config file). Outdated\nentries are purged from cache automatically after a crawl. It's also possible\nto explicitly purge the cache from outdated entries::\n\n  $ feeds --config feeds.cfg cleanup\n\nRelated work\n------------\n\n* `morss <https://github.com/pictuga/morss>`_ creates feeds, similar to Feeds\n  but in \"real-time\", i.e. on (HTTP) request.\n* `Full-Text RSS <https://bitbucket.org/fivefilters/full-text-rss>`_ converts\n  feeds to contain the full article and not only a teaser based on heuristics\n  and rules. Feeds are converted in \"real-time\", i.e. on request basis.\n* `f43.me <https://github.com/j0k3r/f43.me>`_ converts feeds to contain the\n  full article and also improves articles by adding links to the comment\n  sections of Hacker News and Reddit. Feeds are converted periodically.\n* `python-ftr <https://github.com/1flow/python-ftr>`_ is a library to extract\n  content from pages. A partial reimplementation of Full-Text RSS.\n\nHow to contribute\n-----------------\n\nIssues\n~~~~~~\n\n* Search the existing issues in the `issue tracker`_.\n* File a `new issue`_ in case the issue is undocumented.\n\nPull requests\n~~~~~~~~~~~~~\n\n* Fork the project to your private repository.\n* Create a topic branch and make your desired changes.\n* Open a pull request. Make sure the GitHub CI checks are passing.\n\nAuthors\n-------\nFeeds is written and maintained by `Florian Preinstorfer <https://nblock.org>`_\nand `Lukas Anzinger <https://www.notinventedhere.org>`_.\n\nLicense\n-------\n\nAGPL3, see https://pyfeeds.readthedocs.io/en/latest/license.html for details.\n\n.. _issue tracker: https://github.com/pyfeeds/pyfeeds/issues\n.. _new issue: https://github.com/pyfeeds/pyfeeds/issues/new\n.. _Scrapy: https://www.scrapy.org\n.. _TinyTinyRSS: https://tt-rss.org\n.. _pull request: https://pyfeeds.readthedocs.io/en/latest/contribute.html\n.. _spiders: https://github.com/PyFeeds/PyFeeds/tree/master/feeds/spiders\n.. _Falter: https://pyfeeds.readthedocs.io/en/latest/spiders/falter.at.html\n.. _Konsument: https://pyfeeds.readthedocs.io/en/latest/spiders/konsument.at.html\n.. _LWN: https://pyfeeds.readthedocs.io/en/latest/spiders/lwn.net.html\n.. _Oberösterreichische Nachrichten: https://pyfeeds.readthedocs.io/en/latest/spiders/nachrichten.at.html\n.. _Übermedien: https://pyfeeds.readthedocs.io/en/latest/spiders/uebermedien.de.html\n\n.. |pypi| image:: https://img.shields.io/pypi/v/pyfeeds.svg?style=flat-square\n    :target: https://pypi.org/project/pyfeeds/\n    :alt: pypi version\n\n.. |support| image:: https://img.shields.io/pypi/pyversions/pyfeeds.svg?style=flat-square\n    :target: https://pypi.org/project/pyfeeds/\n    :alt: supported Python version\n\n.. |licence| image:: https://img.shields.io/pypi/l/pyfeeds.svg?style=flat-square\n    :target: https://pypi.org/project/pyfeeds/\n    :alt: licence\n\n.. |readthedocs| image:: https://img.shields.io/readthedocs/pyfeeds/latest.svg?style=flat-square&label=Read%20the%20Docs\n   :alt: Read the documentation at https://pyfeeds.readthedocs.io/en/latest/\n   :target: https://pyfeeds.readthedocs.io/en/latest/\n\n.. |pyfeedsci| image:: https://github.com/PyFeeds/PyFeeds/workflows/PyFeeds%20CI/badge.svg\n    :target: https://github.com/PyFeeds/PyFeeds/actions?query=workflow%3A%22PyFeeds+CI%22\n    :alt: GitHub PyFeeds CI\n",
  "permissions": {
    "read": true,
    "write": false,
    "admin": false
  },
  "media_types": [
    "application/vnd.docker.container.image.v1+json"
  ],
  "content_types": [
    "image"
  ]
}