{
  "user": "alash3al",
  "name": "redix",
  "namespace": "alash3al",
  "repository_type": "image",
  "status": 1,
  "status_description": "active",
  "description": "A high-concurrency standalone NoSQL datastore supports multiple backends/engines.",
  "is_private": false,
  "is_automated": false,
  "can_edit": false,
  "star_count": 0,
  "pull_count": 257,
  "last_updated": "2019-01-08T08:14:16.713119Z",
  "date_registered": "2018-12-23T20:13:46.382716Z",
  "collaborator_count": 0,
  "affiliation": null,
  "hub_user": "alash3al",
  "has_starred": false,
  "full_description": "<p align=\"center\"> \n      <img src=\"https://via.placeholder.com/800x200/fff/000/?text=RedixDB\" />\n</p>\n\n<p align=\"center\">\n      <a style=\"display: inline-block\" align=\"center\" href=\"https://travis-ci.com/alash3al/redix\"><img alt=\"Build Status\" src=\"https://travis-ci.com/alash3al/redix.svg?branch=master\" /></a>\n      <a style=\"display: inline-block\" align=\"center\" href=\"https://github.com/alash3al/redix/blob/master/LICENSE\"><img alt=\"License\" src=\"https://img.shields.io/hexpm/l/plug.svg\" /></a>\n      <a style=\"display: inline-block\" align=\"center\" href=\"https://cloud.docker.com/u/alash3al/repository/docker/alash3al/redix\"><img alt=\"Docker\" src=\"https://img.shields.io/docker/pulls/alash3al/redix.svg\" /></a>\n      <a style=\"display: inline-block\" align=\"center\" href=\"https://github.com/alash3al/redix/graphs/contributors\"><img alt=\"Contributors\" src=\"https://img.shields.io/github/contributors/alash3al/redix.svg\" /></a>\n</p>\n\n<blockquote align=\"center\">\n\na fast NoSQL DB, that uses the same <a href=\"https://redis.io/topics/protocol\">RESP</a> protocol and capable to store terabytes of data, also it integrates with your mobile/web apps to add real-time features, soon you can use it as a document store cause it should become a multi-model db. `Redix` is used in production, you can use it in your apps with no worries.\n\n</blockquote>\n\nFeatures\n=========\n- Core data structure: `KV`, `List`, `Hashmap` with advanced implementations.\n- Advanced Publish/Subscribe using webhook and websocket!\n- Pluggable Storage Engine (`badgerdb`, `boltdb`, `leveldb`, `null`, `sqlite`)\n- Very compatible with any `redis client` including `redis-cli`\n- Standalone with no external dependencies\n- Helpers commands for `Time`, `Encode <hex|md5|sha1|sha256|sha512> <payload>`, `RANDINT`, `RANDSTR`\n- Implements `RATELIMIT` helpers natively.\n\nWhy\n===\n> I started this software to learn more about data modeling, data structures and how to map any data to pure key value, I don't need to build a redis clone, but I need to build something with my own concepts in my own style. I decided to use RESP (redis protocol) so you can use `Redix` with any redis client out there.\n\nInstall\n=======\n- Using Homebrew:\n  - Add Homebrew Tap `brew tap alash3al/redix https://github.com/alash3al/redix`\n  - Install Redix `brew install alash3al/redix/redix`\n- From Binaries: go [there](https://github.com/alash3al/redix/releases) and choose your platform based binary, then download and execute from the command line with `-h` flag to see the help text.\n- Using Docker: `docker run -P -v /path/to/redix-data:/root/redix-data alash3al/redix`\n- From Source: `go get github.com/alash3al/redix`.\n\nConfigurations\n============\n> It is so easy to configure `Redix`, there is no configuration files, it is all about running `./redix` after you download it from the [releases](https://github.com/alash3al/redix/releases), if you downloaded i.e 'redix_linux_amd64' and unziped it.\n\n```bash\n$ ./redix_linux_amd64 -h\n\n  -engine string\n        the storage engine to be used, available (default \"badger\")\n  -http-addr string\n        the address of the http server (default \":7090\")\n  -resp-addr string\n        the address of resp server (default \":6380\")\n  -storage string\n        the storage directory (default \"./redix-data\")\n  -verbose\n        verbose or not\n  -workers int\n        the default workers number (default ...)\n```\n\nExamples\n=========\n\n```bash\n\n# i.e: $mykey1 = \"this is my value\"\n$ redis-cli -p 6380 set mykey1 \"this is my value\"\n\n# i.e: $mykey1 = \"this is my value\" and expire it after 10 seconds\n$ redis-cli -p 6380 set mykey1 \"this is my value\" 10000\n\n# i.e: echo $mykey1\n$ redis-cli -p 6380 get mykey1\n\n# i.e: $mymap1[x] = y\n$ redis-cli -p 6380 hset mymap1 x y\n\n# i.e: $mymap1[x] = y and expires it after 10 seconds\n$ redis-cli -p 6380 hset mymap1 x y 10000\n\n# i.e: sha512 of \"test\"\n$ redis-cli -p 6380 encode sha512 test\n\n# you want to notify an endpoint i.e: \"http://localhost:800/new-data\" that there is new data available, in other words, you want to subscribe a webhook to channel updates.\n$ redis-cli -p 6380 webhookset testchan http://localhost:800/new-data\n\n# add data to a list\n# i.e: [].push(....)\n$ redis-cli -p 6380 lpush mylist1 \"I'm Mohammed\" \"I like to Go using Go\" \"I love coding\"\n\n# search in the list\n$ redis-cli -p 6380 lsrch mylist1 \"mo(.*)\"\n\n```\n\nDB Engines\n===========\n- `Redix` supports two engines called `badger` and `bolt`\n- `badger` is the default, it is inspired by Facebook [`RocksDB`](https://rocksdb.org/), it meant to be fast on-disk engine, [read more](https://github.com/dgraph-io/badger)\n- `bolt` is our alternate engine, it is inspired by [`LMDB`](http://symas.com/mdb/), [read more](https://github.com/etcd-io/bbolt)\n\nSupported Commands\n===================\n> `Redix` doesn't implement all redis commands, but instead it supports the core concepts that will help you to build any type of data models on top of it, there are more commands and features in all next releases.\n\n## # Basic\n- `PING`\n- `QUIT`\n- `SELECT`\n\n## # Strings\n- `SET <key> <value> [<TTL \"millisecond\">]`\n- `MSET <key1> <value1> [<key2> <value2> ...]`\n- `GET <key> [<default value>]`\n- `MGET <key1> [<key2> ...]`\n- `DEL <key1> [<key2> ...]`\n- `EXISTS <key>`\n- `INCR <key> [<by>]`\n- `TTL <key>` returns `-1` if key will never expire, `-2` if it doesn't exists (expired), otherwise will returns the `seconds` remain before the key will expire.\n- `KEYS [<regexp-pattern>]`\n\n\n## # HASHES\n> I enhanced the HASH MAP implementation and added some features like TTL per nested key,\n> also you can check whether the hash map itself exists or not using `HEXISTS <hashmapname>` or a nested key \n> exists using `HEXISTS <hashmapname> <keyname>`.  \n\n- `HSET <HASHMAP> <KEY> <VALUE> [<TTL \"millesecond\">]`\n- `HMSET <HASHMAP> <key1> <value1> [<key2> <value2> ...]`\n- `HGET <HASHMAP> <KEY>`\n- `HDEL <HASHMAP> [<key1> <key2> ...]` (deletes the map itself or keys in the map)\n- `HGETALL <HASHMAP>`\n- `HMSET <HASHMAP> <key1> <val1> [<key2> <val2> ...]`\n- `HEXISTS <HASHMAP> [<key>]`.\n- `HINCR <HASHMAP> <key> [<by>]`\n- `HTTL <HASHMAP> <key>`, the same as `TTL` but for `HASHMAP`\n- `HKEYS <HASHMAP>`\n- `HLEN <HASHMAP>`\n\n## # LIST\n> I applied a new concept, you can push or push-unique values into the list,\n>  based on that I don't need to implement two different data structures, \n> as well as, you can quickly iterate over a list in a high performance way,\n> every push will return the internal offset of the value, also, the iterator `lrange`\n> will tell you the next offset you can start from.  \n\n- `LPUSH <LIST> <val1> [<val2> ...]` (push the item into the list \"it doesn't check for uniqueness, it will append anyway (duplicate)\")\n- `LPUSHU <LIST> <val1> [<val2> ...]` (push the item into the list only if it isn't exists)\n- `LRANGE <LIST> [<offset> <size>]`\n- `LREM <LIST> [<val1> <val2> <val3> ...]` (deletes the list itself or values in the list)\n- `LCOUNT <LIST>` (get the list members count)\n- `LCARD <LIST>` (alias of `LCOUNT`)\n- `LSUM <LIST>` (sum the members of the list \"in case they were numbers\")\n- `LAVG <LIST>` (get the avg of the members of the list \"in case they were numbers\")\n- `LMIN <LIST>` (get the minimum of the members of the list \"in case they were numbers\")\n- `LMAX <LIST>` (get the maximum of the members of the list \"in case they were numbers\")\n- `LSRCH <LIST> <NEEDLE>` (text-search using (string search or regex) in the list)\n- `LSRCHCOUNT <LIST> <NEEDLE>` (size of text-search result using (string search or regex) in the list)\n\n## # SET\n- `SADD <LIST> <val1> [<val2> ...]` (alias of `LUPUSH`)\n- `SMEMBERS <LIST> [<offset> <size>]` (alias of `LRANGE`)\n- `SSCAN <LIST> [<offset> <size>]` (alias of `LRANGE`)\n- `SCARD <LIST>` (aliad of `LCOUNT`)\n- `SREM <LIST> [<val1> <val2> <val3> ...]` (alias of `LREM`)\n\n## # Pub/Sub\n> `Redix` has very simple pub/sub functionality, you can subscribe to internal logs on the `*` channel or any custom defined channel, and publish to any custom channel.\n\n- `SUBSCRIBE [<channel1> <channel2>]`, if there is no channel specified, it will be set to `*`\n- `PUBLISH <channel> <payload>`\n- `WEBHOOKSET <channel> <httpurl>`, register a http endpoint so it can be notified through `JSON POST` request with the channel updates, this command will return a reference ID so you can manage it later.\n- `WEBHOOKDEL <ID>`, stops listening on a channel using the above reference ID.\n- `WEBSOCKETOPEN <channel>`, opens a websocket endpoint and returns its id, so you can receive updates through `ws://server.address:port/stream/ws/{generated_id_here}`\n- `WEBSOCKETCLOSE <ID>`, closes the specified websocket endpoint using the above generated id. \n\n## # Ratelimit\n- `RATELIMITSET <bucket> <limit> <seconds>`, create a new `$bucket` that accepts num of `$limit` of actions per the specified num of `$seconds`, it will returns `1` for success.\n- `RATELIMITTAKE <bucket>`, do an action in the specified `bucket` and take an item from it, it will return `-1` if the bucket not exists or it has unlimited actions `$limit < 1`, `0` if there are no more actions to be done right now, `reminder` of actions on success.\n- `RATELIMITGET <bucket>`, returns array [`$limit`, `$seconds`, `$remaining_time`, `$counter`] information for the specified bucket\n\n## # Utils\n> some useful utils that you can use within your app to remove some hassle from it.\n\n- `ENCODE <method> <payload>`, encode the specified `<payload>` using the specified `<method>` (`md5`, `sha1`, `sha256`, `sha512`, `hex`)\n- `UUIDV4`, generates a uuid-v4 string, i.e `0b98aa17-eb06-42b8-b39f-fd7ba6aba7cd`.\n- `UNIQID`, generates a unique string.\n- `RANDSTR [<size>, default size is 10]`, generates a random string using the specified length. \n- `RANDINT <min> <max>`, generates a random string between the specified `<min>` and `<max>`.\n- `TIME`, returns the current time in `utc`, `seconds` and `nanoseconds`\n- `DBSIZE`, returns the database size in bytes.\n- `GC`, runs the Garbage Collector.\n- `ECHO [<arg1> <arg2> ...]`\n- `INFO`\n\nTODO\n=====\n- [x] Basic Commands\n- [x] Strings Commands\n- [x] Hashmap Commands\n- [x] List Commands\n- [x] PubSub Commands\n- [x] Utils Commands\n- [x] Adding BoltDB engine\n- [x] Adding LevelDB engine\n- [x] Adding Null engine\n- [x] Adding SQLite engine\n- [ ] Adding TiKV engine\n- [ ] Adding RAM engine\n",
  "permissions": {
    "read": true,
    "write": false,
    "admin": false
  },
  "media_types": [
    "application/vnd.docker.container.image.v1+json"
  ],
  "content_types": [
    "image"
  ]
}